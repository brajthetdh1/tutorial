<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AWS Tutorial & Interview Guide</title>
  <meta name="description" content="Learn AWS step by step: setup EC2, S3, Lambda, RDS, and review interview questions.">
  <meta name="keywords" content="AWS, EC2, S3, Lambda, RDS, AWS tutorial, AWS interview questions, cloud computing">
  <meta name="author" content="Your Name">
  <link rel="icon" href="favicon.ico">
  <script src="https://cdn.tailwindcss.com"></script>
</head>
<body class="bg-gray-50 font-sans text-gray-800">

  <!-- Header -->
<header class="bg-indigo-600 text-white fixed top-0 w-full z-50 shadow">
  <div class="container mx-auto flex justify-between items-center p-4">
    <!-- Logo / Title -->
    <h1 class="text-2xl font-bold">My Tutorials</h1>

    <!-- Desktop Navigation -->
    <nav class="hidden md:flex md:space-x-6 items-center">
      <a href="../index.html" class="hover:underline whitespace-nowrap">Home</a>
      <a href="../aws.html" class="hover:underline whitespace-nowrap">AWS</a>
    </nav>

    <!-- Mobile Hamburger -->
    <div class="md:hidden">
      <button id="menu-btn" class="focus:outline-none">
        <svg class="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24"
          xmlns="http://www.w3.org/2000/svg">
          <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2"
            d="M4 6h16M4 12h16M4 18h16"></path>
        </svg>
      </button>
    </div>
  </div>

  <!-- Mobile Navigation -->
  <nav id="menu" class="hidden md:hidden bg-indigo-500">
    <div class="flex flex-col px-4 py-2 space-y-2">
      <a href="../index.html" class="hover:underline">Home</a>
      <a href="../aws.html" class="hover:underline">AWS</a>
    </div>
  </nav>

  <!-- Script for mobile toggle -->
  <script>
    const btn = document.getElementById('menu-btn');
    const menu = document.getElementById('menu');

    btn.addEventListener('click', () => {
      menu.classList.toggle('hidden');
    });
  </script>
</header>

  <!-- Main Content -->
  <main class="container mx-auto mt-24 p-4 space-y-10">



    <section id="aws-programmatic-interaction" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      How do you interact with AWS programmatically? (CLI, SDKs, APIs)
    </h2>

    <p class="text-gray-700 mb-6">
      AWS provides multiple ways to interact with its services programmatically, enabling automation, 
      scripting, and integration into applications:
    </p>

    <!-- Methods -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">1. AWS CLI (Command Line Interface)</h3>
      <p class="text-gray-700 mb-2">
        The AWS CLI allows you to manage AWS services from your terminal or scripts using commands.
      </p>
      <ul class="list-disc list-inside text-gray-700 space-y-1 mb-4">
        <li>Supports almost all AWS services.</li>
        <li>Ideal for automation, CI/CD pipelines, and one-off tasks.</li>
        <li>Example: <code>aws s3 ls s3://my-bucket</code></li>
      </ul>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code># List all objects in an S3 bucket
aws s3api list-objects-v2 --bucket my-bucket</code></pre>
    </div>

    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">2. AWS SDKs (Software Development Kits)</h3>
      <p class="text-gray-700 mb-2">
        SDKs allow your applications to interact with AWS services programmatically using native programming languages.
      </p>
      <ul class="list-disc list-inside text-gray-700 space-y-1 mb-4">
        <li>Supported languages include Python (Boto3), Java, JavaScript/Node.js, C#, Go, Ruby, PHP, etc.</li>
        <li>Handles authentication, retries, and serialization for you.</li>
        <li>Example: Upload a file to S3 using Python:</li>
      </ul>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>import boto3

s3 = boto3.client('s3')
s3.upload_file('localfile.txt', 'my-bucket', 'remote-file.txt')</code></pre>
    </div>

    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">3. AWS REST APIs</h3>
      <p class="text-gray-700 mb-2">
        AWS services expose RESTful HTTP APIs, allowing direct HTTP requests with proper signing (AWS Signature Version 4).
      </p>
      <ul class="list-disc list-inside text-gray-700 space-y-1 mb-4">
        <li>Useful when SDKs are not available.</li>
        <li>Requires signing requests with AWS credentials.</li>
        <li>Example: Direct S3 GET request with Authorization header.</li>
      </ul>
    </div>

    <!-- Best Practices -->
    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Best Practices</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>Use IAM roles or temporary credentials for programmatic access instead of root account keys.</li>
        <li>Prefer SDKs over direct API calls for easier error handling and retries.</li>
        <li>Use CLI for scripting, automation, and bulk operations.</li>
        <li>Always secure your credentials using AWS Secrets Manager or environment variables.</li>
      </ul>
    </div>
  </div>
</section>



    <section id="aws-cli" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      AWS CLI (Command Line Interface)
    </h2>

    <p class="text-gray-700 mb-6">
      The <strong>AWS Command Line Interface (CLI)</strong> is a unified tool to manage 
      AWS services directly from your terminal. It allows developers, system administrators, 
      and DevOps engineers to automate tasks, script operations, and perform bulk actions 
      efficiently.
    </p>

    <!-- Key Features -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Key Features</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-2">
        <li>Supports almost all AWS services and their API operations.</li>
        <li>Enables scripting, automation, and integration with CI/CD pipelines.</li>
        <li>Handles authentication via AWS credentials and IAM roles.</li>
        <li>Supports paginated results, JSON/YAML/TSV output formats.</li>
        <li>Can perform bulk operations, e.g., copying, syncing, and deleting files in S3.</li>
        <li>Integrates with AWS profiles for managing multiple accounts.</li>
      </ul>
    </div>

    <!-- Installation -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Installation</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-2">
        <li><strong>Windows:</strong> Use the MSI installer from AWS official site.</li>
        <li><strong>macOS:</strong> Use Homebrew: <code>brew install awscli</code></li>
        <li><strong>Linux:</strong> Use package manager or pip: <code>pip install awscli --upgrade --user</code></li>
      </ul>
    </div>

    <!-- Configuration -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Configuration</h3>
      <p class="text-gray-700 mb-2">
        Configure AWS CLI with your credentials and default region:
      </p>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>aws configure
# Prompts:
# AWS Access Key ID [None]: &lt;your-access-key-id&gt;
# AWS Secret Access Key [None]: &lt;your-secret-access-key&gt;
# Default region name [None]: us-east-1
# Default output format [None]: json</code></pre>
      <p class="text-gray-700">
        You can also manage multiple accounts using <code>aws configure --profile &lt;profile-name&gt;</code>.
      </p>
    </div>

    <!-- Common Usage -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Common Commands</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-2">
        <li><strong>S3 Operations:</strong> Upload/download files, sync directories, manage buckets.</li>
        <li><strong>EC2:</strong> Launch, stop, or describe instances.</li>
        <li><strong>IAM:</strong> Manage users, roles, and policies.</li>
        <li><strong>CloudFormation:</strong> Deploy, update, and delete stacks.</li>
        <li><strong>CloudWatch:</strong> View logs and metrics.</li>
      </ul>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code># Example: List all S3 buckets
aws s3 ls

# Example: Copy file to S3
aws s3 cp localfile.txt s3://my-bucket/

# Example: Sync local folder with S3 bucket
aws s3 sync ./local-folder s3://my-bucket/</code></pre>
    </div>

    <!-- Advanced Features -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Advanced Features</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-2">
        <li>Use <strong>pagination and filters</strong> to handle large datasets.</li>
        <li>Generate <strong>pre-signed URLs</strong> for secure temporary access.</li>
        <li>Integrate with <strong>scripts, cron jobs, and CI/CD pipelines</strong> for automation.</li>
        <li>Enable <strong>debugging</strong> with <code>--debug</code> flag to inspect requests and responses.</li>
      </ul>
    </div>

    <!-- Best Practices -->
    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Best Practices</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>Use IAM roles and temporary credentials instead of hardcoding access keys.</li>
        <li>Always use <strong>profiles</strong> to manage multiple AWS accounts safely.</li>
        <li>Combine CLI with <strong>scripts and automation tools</strong> for repeatable workflows.</li>
        <li>Enable <strong>logging and monitoring</strong> for audit trails.</li>
        <li>Test commands with <code>--dry-run</code> where possible to prevent accidental changes.</li>
      </ul>
    </div>
  </div>
</section>



    <section id="aws-cli-installation" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      How do you install AWS CLI on your local machine?
    </h2>

    <p class="text-gray-700 mb-6">
      The AWS Command Line Interface (CLI) allows you to interact with AWS services directly from your terminal or command prompt. Installation differs based on your operating system.
    </p>

    <!-- Installation Methods -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Windows</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-2 mb-4">
        <li>Download the MSI installer from the <a href="https://aws.amazon.com/cli/" target="_blank" class="text-blue-600 underline">AWS CLI official site</a>.</li>
        <li>Run the installer and follow the prompts.</li>
        <li>Verify installation:</li>
      </ul>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>aws --version</code></pre>
    </div>

    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">2. macOS</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-2 mb-4">
        <li>Install via Homebrew:</li>
      </ul>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>brew install awscli</code></pre>
      <ul class="list-disc list-inside text-gray-700 space-y-2 mb-4">
        <li>Verify installation:</li>
      </ul>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>aws --version</code></pre>
    </div>

    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">3. Linux</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-2 mb-4">
        <li>Install using pip:</li>
      </ul>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>pip install --upgrade --user awscli</code></pre>
      <ul class="list-disc list-inside text-gray-700 space-y-2 mb-4">
        <li>Or use your Linux distribution package manager (e.g., apt, yum).</li>
        <li>Verify installation:</li>
      </ul>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>aws --version</code></pre>
    </div>

    <!-- Post-install Configuration -->
    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Post-install Configuration</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>Configure AWS CLI with your credentials:</li>
      </ul>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>aws configure
# Enter your AWS Access Key ID
# Enter your AWS Secret Access Key
# Default region (e.g., us-east-1)
# Default output format (json, table, text)</code></pre>
      <ul class="list-disc list-inside text-gray-700 space-y-1 mt-2">
        <li>Use multiple profiles for managing multiple AWS accounts: <code>aws configure --profile &lt;profile-name&gt;</code></li>
        <li>Verify configuration by listing S3 buckets: <code>aws s3 ls</code></li>
      </ul>
    </div>
  </div>
</section>



<section id="aws-cli-configuration" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      How do you configure AWS CLI with credentials and default region?
    </h2>

    <p class="text-gray-700 mb-6">
      After installing the AWS CLI, you need to configure it with your AWS credentials and default region to interact with AWS services.
    </p>

    <!-- Configuration Steps -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Basic Configuration</h3>
      <p class="text-gray-700 mb-2">Run the following command:</p>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>aws configure</code></pre>
      <p class="text-gray-700 mb-2">You will be prompted to enter:</p>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li><strong>AWS Access Key ID:</strong> Your IAM access key ID.</li>
        <li><strong>AWS Secret Access Key:</strong> Your IAM secret key.</li>
        <li><strong>Default region name:</strong> e.g., <code>us-east-1</code>, <code>eu-west-1</code>.</li>
        <li><strong>Default output format:</strong> <code>json</code>, <code>table</code>, or <code>text</code>.</li>
      </ul>
    </div>

    <!-- Example -->
    <div class="p-6 bg-gray-100 rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Example</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>$ aws configure
AWS Access Key ID [None]: AKIAxxxxxxxxxxxx
AWS Secret Access Key [None]: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
Default region name [None]: us-east-1
Default output format [None]: json</code></pre>
    </div>

    <!-- Profiles for Multiple Accounts -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">2. Using Profiles for Multiple Accounts</h3>
      <p class="text-gray-700 mb-2">
        You can maintain multiple configurations using named profiles:
      </p>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>aws configure --profile dev
aws configure --profile prod</code></pre>
      <p class="text-gray-700">
        To use a profile for a command:
      </p>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>aws s3 ls --profile dev</code></pre>
    </div>

    <!-- Verification -->
    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">3. Verify Configuration</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>Check configured credentials and region:</li>
        <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>aws configure list</code></pre>
        <li>Test access to a service (e.g., list S3 buckets):</li>
        <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>aws s3 ls</code></pre>
      </ul>
    </div>

    <!-- Best Practices -->
    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Best Practices</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>Use IAM roles or temporary credentials instead of root account keys.</li>
        <li>Use profiles for managing multiple AWS accounts safely.</li>
        <li>Store credentials securely (avoid committing to code repositories).</li>
        <li>Regularly rotate access keys and secret keys.</li>
      </ul>
    </div>
  </div>
</section>



<section id="aws-cli-v1-v2" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      Difference between AWS CLI v1 and v2
    </h2>

    <p class="text-gray-700 mb-6">
      AWS CLI has two major versions: <strong>v1</strong> and <strong>v2</strong>. 
      While both provide command-line access to AWS services, v2 includes several improvements and new features.
    </p>

    <!-- Comparison Table -->
    <div class="overflow-x-auto mb-6">
      <table class="min-w-full bg-white border border-gray-200 rounded-lg shadow-sm">
        <thead class="bg-gray-100">
          <tr>
            <th class="px-6 py-3 text-left text-gray-900 font-semibold border-b">Feature</th>
            <th class="px-6 py-3 text-left text-gray-900 font-semibold border-b">AWS CLI v1</th>
            <th class="px-6 py-3 text-left text-gray-900 font-semibold border-b">AWS CLI v2</th>
          </tr>
        </thead>
        <tbody class="text-gray-700">
          <tr class="border-b">
            <td class="px-6 py-3">Installation</td>
            <td class="px-6 py-3">Separate dependencies; requires Python to be installed.</td>
            <td class="px-6 py-3">Bundled installer with embedded Python; easier to install on multiple OS.</td>
          </tr>
          <tr class="border-b">
            <td class="px-6 py-3">SSO Support</td>
            <td class="px-6 py-3">Not supported natively.</td>
            <td class="px-6 py-3">Supports AWS Single Sign-On (SSO) natively.</td>
          </tr>
          <tr class="border-b">
            <td class="px-6 py-3">New Features</td>
            <td class="px-6 py-3">Older features, fewer enhancements.</td>
            <td class="px-6 py-3">Includes new features like improved prompts, auto-paging, and default credential process.</td>
          </tr>
          <tr class="border-b">
            <td class="px-6 py-3">Command Output</td>
            <td class="px-6 py-3">Basic JSON, table, text.</td>
            <td class="px-6 py-3">Same formats plus improved handling for paginated output and auto-paging.</td>
          </tr>
          <tr class="border-b">
            <td class="px-6 py-3">Compatibility</td>
            <td class="px-6 py-3">Compatible with older scripts, Python 2.x and 3.x.</td>
            <td class="px-6 py-3">Backward compatible with v1 commands; uses embedded Python 3.7+.</td>
          </tr>
          <tr>
            <td class="px-6 py-3">Security</td>
            <td class="px-6 py-3">Depends on system Python SSL libraries.</td>
            <td class="px-6 py-3">Improved SSL/TLS handling with embedded libraries.</td>
          </tr>
        </tbody>
      </table>
    </div>

    <!-- Summary -->
    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Summary</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li><strong>v2</strong> is the recommended version for new installations.</li>
        <li>v2 simplifies installation with embedded Python and improves security.</li>
        <li>v2 supports AWS SSO natively and provides better handling of pagination and credentials.</li>
        <li>Scripts written for v1 usually work with v2, making migration straightforward.</li>
      </ul>
    </div>
  </div>
</section>





<section id="aws-cli-commands" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      Common AWS CLI Commands
    </h2>

    <p class="text-gray-700 mb-6">
      AWS CLI provides commands for almost all AWS services. Here are some commonly used commands for frequently accessed services:
    </p>

    <!-- S3 Commands -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">S3 Commands</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-2">
        <li>List all buckets: <code>aws s3 ls</code></li>
        <li>List objects in a bucket: <code>aws s3 ls s3://my-bucket</code></li>
        <li>Upload a file: <code>aws s3 cp localfile.txt s3://my-bucket/</code></li>
        <li>Sync folder: <code>aws s3 sync ./local-folder s3://my-bucket/</code></li>
        <li>Download a file: <code>aws s3 cp s3://my-bucket/file.txt ./</code></li>
        <li>Delete a file: <code>aws s3 rm s3://my-bucket/file.txt</code></li>
      </ul>
    </div>

    <!-- EC2 Commands -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">EC2 Commands</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-2">
        <li>Describe instances: <code>aws ec2 describe-instances</code></li>
        <li>Start an instance: <code>aws ec2 start-instances --instance-ids i-0123456789abcdef0</code></li>
        <li>Stop an instance: <code>aws ec2 stop-instances --instance-ids i-0123456789abcdef0</code></li>
        <li>Terminate an instance: <code>aws ec2 terminate-instances --instance-ids i-0123456789abcdef0</code></li>
      </ul>
    </div>

    <!-- IAM Commands -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">IAM Commands</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-2">
        <li>List users: <code>aws iam list-users</code></li>
        <li>Create user: <code>aws iam create-user --user-name my-user</code></li>
        <li>Attach policy to user: <code>aws iam attach-user-policy --user-name my-user --policy-arn arn:aws:iam::aws:policy/AdministratorAccess</code></li>
        <li>List roles: <code>aws iam list-roles</code></li>
      </ul>
    </div>

    <!-- CloudFormation Commands -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">CloudFormation Commands</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-2">
        <li>Create stack: <code>aws cloudformation create-stack --stack-name my-stack --template-body file://template.yaml</code></li>
        <li>Update stack: <code>aws cloudformation update-stack --stack-name my-stack --template-body file://template.yaml</code></li>
        <li>Delete stack: <code>aws cloudformation delete-stack --stack-name my-stack</code></li>
        <li>List stacks: <code>aws cloudformation list-stacks</code></li>
      </ul>
    </div>

    <!-- General Commands -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">General Commands</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-2">
        <li>Check CLI version: <code>aws --version</code></li>
        <li>List configured profiles: <code>aws configure list-profiles</code></li>
        <li>View current configuration: <code>aws configure list</code></li>
        <li>Use a profile for a command: <code>aws s3 ls --profile dev</code></li>
      </ul>
    </div>

    <!-- Best Practices -->
    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Best Practices</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>Use profiles for multiple accounts to avoid confusion.</li>
        <li>Combine CLI commands with scripts for automation and repeatable workflows.</li>
        <li>Use <code>--dry-run</code> where possible to prevent accidental destructive actions.</li>
        <li>Secure credentials using IAM roles, temporary tokens, or AWS Secrets Manager.</li>
      </ul>
    </div>
  </div>
</section>




<section id="aws-sdk" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      AWS SDK (Software Development Kit)
    </h2>

    <p class="text-gray-700 mb-6">
      The <strong>AWS SDK</strong> is a set of language-specific libraries that allow developers 
      to interact with AWS services programmatically from applications. SDKs simplify the process 
      of integrating AWS services by handling authentication, request signing, retries, and data serialization.
    </p>

    <!-- Supported Languages -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Supported Languages</h3>
      <p class="text-gray-700 mb-2">AWS SDKs are available for multiple programming languages:</p>
      <ul class="list-disc list-inside text-gray-700 space-y-2">
        <li><strong>Python:</strong> Boto3</li>
        <li><strong>Java:</strong> AWS SDK for Java</li>
        <li><strong>JavaScript/Node.js:</strong> AWS SDK for JavaScript</li>
        <li><strong>C#/.NET:</strong> AWS SDK for .NET</li>
        <li><strong>Go:</strong> AWS SDK for Go</li>
        <li><strong>Ruby:</strong> AWS SDK for Ruby</li>
        <li><strong>PHP:</strong> AWS SDK for PHP</li>
      </ul>
    </div>

    <!-- Key Features -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Key Features</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-2">
        <li>Provides a native interface to AWS services in your chosen programming language.</li>
        <li>Handles authentication using IAM roles, access keys, or temporary credentials.</li>
        <li>Automatically signs requests using AWS Signature Version 4.</li>
        <li>Supports retries and exponential backoff for failed requests.</li>
        <li>Serializes and deserializes JSON, XML, and other data formats.</li>
        <li>Integrates with AWS services such as S3, EC2, DynamoDB, Lambda, and more.</li>
      </ul>
    </div>

    <!-- Installation -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Installation Examples</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-2 mb-4">
        <li><strong>Python (Boto3):</strong> <code>pip install boto3</code></li>
        <li><strong>Node.js:</strong> <code>npm install aws-sdk</code></li>
        <li><strong>Java (Maven):</strong> Add dependency in <code>pom.xml</code>:
          <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-2 overflow-x-auto"><code>&lt;dependency&gt;
  &lt;groupId&gt;software.amazon.awssdk&lt;/groupId&gt;
  &lt;artifactId&gt;s3&lt;/artifactId&gt;
  &lt;version&gt;2.x.x&lt;/version&gt;
&lt;/dependency&gt;</code></pre>
        </li>
      </ul>
    </div>

    <!-- Example Usage -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Example: Uploading a File to S3</h3>

      <p class="text-gray-700 mb-2"><strong>Python (Boto3):</strong></p>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>import boto3

s3 = boto3.client('s3')
s3.upload_file('localfile.txt', 'my-bucket', 'remote-file.txt')</code></pre>

      <p class="text-gray-700 mb-2"><strong>Node.js:</strong></p>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>const AWS = require('aws-sdk');
const fs = require('fs');

const s3 = new AWS.S3();
const fileStream = fs.createReadStream('localfile.txt');

s3.upload({
  Bucket: 'my-bucket',
  Key: 'remote-file.txt',
  Body: fileStream
}, (err, data) =&gt; {
  if (err) console.log(err);
  else console.log('Upload successful:', data.Location);
});</code></pre>
    </div>

    <!-- Best Practices -->
    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Best Practices</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>Use IAM roles with least privilege for applications running on EC2, Lambda, or ECS.</li>
        <li>Use environment variables or configuration files to store credentials securely.</li>
        <li>Handle exceptions and implement retries with exponential backoff for network errors.</li>
        <li>Use high-level abstractions provided by SDKs (like S3 resource objects in Boto3) for simpler code.</li>
        <li>Keep SDKs up to date to leverage new AWS service features and security improvements.</li>
      </ul>
    </div>
  </div>
</section>



<section id="aws-sdk-languages" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      Programming Languages with Official AWS SDKs
    </h2>

    <p class="text-gray-700 mb-6">
      AWS provides official SDKs for multiple programming languages, allowing developers to interact with AWS services in a native and idiomatic way.
    </p>

    <!-- SDK Table -->
    <div class="overflow-x-auto mb-6">
      <table class="min-w-full bg-white border border-gray-200 rounded-lg shadow-sm">
        <thead class="bg-gray-100">
          <tr>
            <th class="px-6 py-3 text-left text-gray-900 font-semibold border-b">Programming Language</th>
            <th class="px-6 py-3 text-left text-gray-900 font-semibold border-b">Official SDK</th>
            <th class="px-6 py-3 text-left text-gray-900 font-semibold border-b">Maturity / Status</th>
          </tr>
        </thead>
        <tbody class="text-gray-700">
          <tr class="border-b">
            <td class="px-6 py-3">Java</td>
            <td class="px-6 py-3">AWS SDK for Java v2</td>
            <td class="px-6 py-3">GA</td>
          </tr>
          <tr class="border-b">
            <td class="px-6 py-3">Python</td>
            <td class="px-6 py-3">Boto3</td>
            <td class="px-6 py-3">GA</td>
          </tr>
          <tr class="border-b">
            <td class="px-6 py-3">JavaScript / TypeScript</td>
            <td class="px-6 py-3">AWS SDK for JavaScript</td>
            <td class="px-6 py-3">GA</td>
          </tr>
          <tr class="border-b">
            <td class="px-6 py-3">C# / .NET</td>
            <td class="px-6 py-3">AWS SDK for .NET</td>
            <td class="px-6 py-3">GA</td>
          </tr>
          <tr class="border-b">
            <td class="px-6 py-3">Go</td>
            <td class="px-6 py-3">AWS SDK for Go v2</td>
            <td class="px-6 py-3">GA</td>
          </tr>
          <tr class="border-b">
            <td class="px-6 py-3">Ruby</td>
            <td class="px-6 py-3">AWS SDK for Ruby</td>
            <td class="px-6 py-3">GA</td>
          </tr>
          <tr class="border-b">
            <td class="px-6 py-3">PHP</td>
            <td class="px-6 py-3">AWS SDK for PHP</td>
            <td class="px-6 py-3">GA</td>
          </tr>
          <tr class="border-b">
            <td class="px-6 py-3">C++</td>
            <td class="px-6 py-3">AWS SDK for C++</td>
            <td class="px-6 py-3">GA</td>
          </tr>
          <tr class="border-b">
            <td class="px-6 py-3">Kotlin</td>
            <td class="px-6 py-3">AWS SDK for Kotlin</td>
            <td class="px-6 py-3">Preview</td>
          </tr>
          <tr class="border-b">
            <td class="px-6 py-3">Rust</td>
            <td class="px-6 py-3">AWS SDK for Rust</td>
            <td class="px-6 py-3">Developer Preview</td>
          </tr>
          <tr>
            <td class="px-6 py-3">Swift</td>
            <td class="px-6 py-3">AWS SDK for Swift</td>
            <td class="px-6 py-3">Developer Preview</td>
          </tr>
        </tbody>
      </table>
    </div>

    <!-- Notes -->
    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Notes</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>All SDKs support authentication, request signing, retries, and native service objects.</li>
        <li>Mobile SDKs are also available for <strong>Android</strong> and <strong>iOS</strong>.</li>
        <li>IoT/embedded SDKs are provided for resource-constrained devices.</li>
        <li>GA = Generally Available; Preview = limited release; Developer Preview = early access.</li>
      </ul>
    </div>
  </div>
</section>



<section id="aws-sdk-authentication" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      How AWS SDKs Handle Authentication
    </h2>

    <p class="text-gray-700 mb-6">
      AWS SDKs provide secure, programmatic access to AWS services by handling authentication automatically. They support multiple authentication methods and integrate with IAM policies to control access.
    </p>

    <!-- Authentication Methods -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Access Keys</h3>
      <p class="text-gray-700 mb-2">
        The most common method uses AWS Access Key ID and Secret Access Key. SDKs automatically sign requests using these credentials.
      </p>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code># Example in Python (Boto3)
import boto3

session = boto3.Session(
    aws_access_key_id='YOUR_ACCESS_KEY',
    aws_secret_access_key='YOUR_SECRET_KEY',
    region_name='us-east-1'
)
s3 = session.client('s3')</code></pre>
    </div>

    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">2. IAM Roles (for EC2, Lambda, ECS)</h3>
      <p class="text-gray-700 mb-2">
        SDKs automatically retrieve temporary credentials from the instance or container metadata when using IAM roles. No keys are stored in code.
      </p>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code># Example in Python (Boto3)
import boto3
s3 = boto3.client('s3')  # Uses IAM role credentials automatically</code></pre>
    </div>

    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">3. Environment Variables</h3>
      <p class="text-gray-700 mb-2">
        SDKs can read <code>AWS_ACCESS_KEY_ID</code> and <code>AWS_SECRET_ACCESS_KEY</code> from environment variables for non-production scripts or local development.
      </p>
    </div>

    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">4. Shared Credentials File</h3>
      <p class="text-gray-700 mb-2">
        Credentials can be stored in <code>~/.aws/credentials</code> and referenced by SDKs automatically or via named profiles.
      </p>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>[default]
aws_access_key_id = YOUR_ACCESS_KEY
aws_secret_access_key = YOUR_SECRET_KEY

[dev]
aws_access_key_id = DEV_KEY
aws_secret_access_key = DEV_SECRET</code></pre>
    </div>

    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">5. AWS Single Sign-On (SSO)</h3>
      <p class="text-gray-700 mb-2">
        SDKs support AWS SSO to authenticate users via corporate identity providers without using long-lived access keys.
      </p>
    </div>

    <!-- Best Practices -->
    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Best Practices</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>Prefer IAM roles over static access keys for applications running on AWS resources.</li>
        <li>Use environment variables or shared credentials file for local development.</li>
        <li>Rotate credentials regularly if using long-lived keys.</li>
        <li>Do not hardcode credentials in source code.</li>
        <li>Enable MFA for sensitive operations when possible.</li>
      </ul>
    </div>
  </div>
</section>




<section id="aws-sdk-credentials" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      How to Configure AWS SDK Credentials in Your Application
    </h2>

    <p class="text-gray-700 mb-6">
      To use AWS SDKs in your application, you must provide credentials so the SDK can authenticate requests to AWS services. There are multiple ways to configure credentials securely.
    </p>

    <!-- Methods -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Using Environment Variables</h3>
      <p class="text-gray-700 mb-2">
        Set environment variables <code>AWS_ACCESS_KEY_ID</code> and <code>AWS_SECRET_ACCESS_KEY</code> before running your application.
      </p>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code># Linux / macOS
export AWS_ACCESS_KEY_ID=YOUR_ACCESS_KEY
export AWS_SECRET_ACCESS_KEY=YOUR_SECRET_KEY
export AWS_DEFAULT_REGION=us-east-1

# Windows PowerShell
setx AWS_ACCESS_KEY_ID "YOUR_ACCESS_KEY"
setx AWS_SECRET_ACCESS_KEY "YOUR_SECRET_KEY"
setx AWS_DEFAULT_REGION "us-east-1"</code></pre>
    </div>

    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">2. Using Shared Credentials File (~/.aws/credentials)</h3>
      <p class="text-gray-700 mb-2">
        Create a credentials file with multiple profiles and reference them in your application.
      </p>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>[default]
aws_access_key_id = YOUR_ACCESS_KEY
aws_secret_access_key = YOUR_SECRET_KEY

[dev]
aws_access_key_id = DEV_ACCESS_KEY
aws_secret_access_key = DEV_SECRET_KEY</code></pre>
      <p class="text-gray-700">
        Then specify the profile in your SDK code or configuration:
      </p>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>import boto3

session = boto3.Session(profile_name='dev')
s3 = session.client('s3')</code></pre>
    </div>

    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">3. Using IAM Roles (EC2, Lambda, ECS)</h3>
      <p class="text-gray-700 mb-2">
        Attach an IAM role with the necessary permissions to your AWS resource. The SDK automatically retrieves temporary credentials from the metadata service.
      </p>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>import boto3
s3 = boto3.client('s3')  # Uses IAM role credentials automatically</code></pre>
    </div>

    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">4. Using AWS SSO</h3>
      <p class="text-gray-700 mb-2">
        For organizations using AWS Single Sign-On, you can configure SDKs to authenticate via SSO. Run:
      </p>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>aws configure sso</code></pre>
      <p class="text-gray-700">
        Then reference the SSO profile in your SDK code.
      </p>
    </div>

    <!-- Best Practices -->
    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Best Practices</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>Avoid hardcoding credentials in your application.</li>
        <li>Use IAM roles for AWS resources whenever possible.</li>
        <li>Use environment variables or shared credentials for local development.</li>
        <li>Rotate credentials regularly.</li>
        <li>Use AWS SSO for centralized identity management in large organizations.</li>
      </ul>
    </div>
  </div>
</section>



<section id="aws-sdk-access-keys-vs-roles" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      Difference Between Using Access Keys and IAM Roles with AWS SDK
    </h2>

    <p class="text-gray-700 mb-6">
      AWS SDKs can authenticate using either long-lived <strong>Access Keys</strong> or temporary credentials provided by <strong>IAM Roles</strong>. Choosing between them affects security, convenience, and automation.
    </p>

    <!-- Comparison Table -->
    <div class="overflow-x-auto mb-6">
      <table class="min-w-full bg-white border border-gray-200 rounded-lg shadow-sm">
        <thead class="bg-gray-100">
          <tr>
            <th class="px-6 py-3 text-left text-gray-900 font-semibold border-b">Aspect</th>
            <th class="px-6 py-3 text-left text-gray-900 font-semibold border-b">Access Keys</th>
            <th class="px-6 py-3 text-left text-gray-900 font-semibold border-b">IAM Roles</th>
          </tr>
        </thead>
        <tbody class="text-gray-700">
          <tr class="border-b">
            <td class="px-6 py-3">Credentials Type</td>
            <td class="px-6 py-3">Long-lived AWS Access Key ID and Secret Access Key.</td>
            <td class="px-6 py-3">Temporary credentials automatically issued by AWS (via STS).</td>
          </tr>
          <tr class="border-b">
            <td class="px-6 py-3">Security</td>
            <td class="px-6 py-3">Higher risk if keys are exposed or checked into source code.</td>
            <td class="px-6 py-3">Safer; no keys are stored in code. Automatically rotated.</td>
          </tr>
          <tr class="border-b">
            <td class="px-6 py-3">Use Case</td>
            <td class="px-6 py-3">Local development, scripts, or CI/CD pipelines where roles are not available.</td>
            <td class="px-6 py-3">AWS resources like EC2, Lambda, ECS, and other services running inside AWS.</td>
          </tr>
          <tr class="border-b">
            <td class="px-6 py-3">Credential Rotation</td>
            <td class="px-6 py-3">Manual rotation required.</td>
            <td class="px-6 py-3">Automatic rotation by AWS; SDK refreshes temporary credentials seamlessly.</td>
          </tr>
          <tr class="border-b">
            <td class="px-6 py-3">Setup Complexity</td>
            <td class="px-6 py-3">Simple to configure via environment variables or shared credentials file.</td>
            <td class="px-6 py-3">Requires attaching IAM roles to AWS resources or assuming roles via STS.</td>
          </tr>
          <tr>
            <td class="px-6 py-3">Best Practice</td>
            <td class="px-6 py-3">Avoid embedding in code; use only when necessary.</td>
            <td class="px-6 py-3">Preferred method for AWS-hosted applications for enhanced security and automation.</td>
          </tr>
        </tbody>
      </table>
    </div>

    <!-- Summary -->
    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Summary</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>Access Keys are static and suitable for local development or external scripts.</li>
        <li>IAM Roles provide temporary credentials automatically and are recommended for AWS-hosted resources.</li>
        <li>Using IAM Roles reduces risk of key leakage and simplifies credential management.</li>
      </ul>
    </div>
  </div>
</section>



<section id="aws-sdk-list-buckets" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      How to List All Buckets Using AWS SDK
    </h2>

    <p class="text-gray-700 mb-6">
      AWS SDKs provide APIs to programmatically list all S3 buckets in your account. Below are examples in different programming languages.
    </p>

    <!-- Python Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Python (Boto3)</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>import boto3

# Create S3 client
s3 = boto3.client('s3')

# List buckets
response = s3.list_buckets()
for bucket in response['Buckets']:
    print(bucket['Name'])</code></pre>
    </div>

    <!-- Node.js Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Node.js</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>const AWS = require('aws-sdk');
const s3 = new AWS.S3();

s3.listBuckets((err, data) =&gt; {
  if (err) console.log('Error', err);
  else {
    data.Buckets.forEach(bucket =&gt; console.log(bucket.Name));
  }
});</code></pre>
    </div>

    <!-- Java Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Java</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>import software.amazon.awssdk.services.s3.S3Client;
import software.amazon.awssdk.services.s3.model.ListBucketsResponse;

S3Client s3 = S3Client.create();
ListBucketsResponse response = s3.listBuckets();

response.buckets().forEach(b -&gt; System.out.println(b.name()));</code></pre>
    </div>

    <!-- Best Practices -->
    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Best Practices</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>Handle exceptions or errors for network issues or insufficient permissions.</li>
        <li>Use IAM policies with least privilege (list-only access if you don’t need write permissions).</li>
        <li>For applications with multiple regions or accounts, consider caching bucket lists for performance.</li>
      </ul>
    </div>
  </div>
</section>



<section id="aws-sdk-create-bucket" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      How to Create a New S3 Bucket Programmatically
    </h2>

    <p class="text-gray-700 mb-6">
      You can create S3 buckets using AWS SDKs in different programming languages. Buckets must have a unique name globally and can specify region, access policies, and other settings.
    </p>

    <!-- Python Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Python (Boto3)</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>import boto3

s3 = boto3.client('s3', region_name='us-east-1')

# Create a new bucket
s3.create_bucket(
    Bucket='my-unique-bucket-name',
    CreateBucketConfiguration={'LocationConstraint': 'us-east-1'}
)
print("Bucket created successfully")</code></pre>
    </div>

    <!-- Node.js Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Node.js</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>const AWS = require('aws-sdk');
const s3 = new AWS.S3({ region: 'us-east-1' });

s3.createBucket({ Bucket: 'my-unique-bucket-name' }, (err, data) =&gt; {
  if (err) console.log('Error', err);
  else console.log('Bucket created successfully', data.Location);
});</code></pre>
    </div>

    <!-- Java Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Java</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>import software.amazon.awssdk.services.s3.S3Client;
import software.amazon.awssdk.services.s3.model.CreateBucketRequest;

S3Client s3 = S3Client.create();

CreateBucketRequest request = CreateBucketRequest.builder()
    .bucket("my-unique-bucket-name")
    .build();

s3.createBucket(request);
System.out.println("Bucket created successfully");</code></pre>
    </div>

    <!-- Best Practices -->
    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Best Practices</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>Bucket names must be globally unique across all AWS accounts.</li>
        <li>Specify the region explicitly to reduce latency and data transfer costs.</li>
        <li>Use IAM roles for applications running in AWS to avoid hardcoding credentials.</li>
        <li>Optionally configure bucket policies, versioning, and encryption at creation time.</li>
      </ul>
    </div>
  </div>
</section>



<section id="aws-sdk-upload-file" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      How to Upload a File to an S3 Bucket Using AWS SDK
    </h2>

    <p class="text-gray-700 mb-6">
      AWS SDKs provide APIs to upload files to S3 programmatically. You can upload small or large files using simple or multipart upload methods.
    </p>

    <!-- Python Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Python (Boto3)</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>import boto3

s3 = boto3.client('s3')
bucket_name = 'my-bucket'
file_path = 'localfile.txt'
key_name = 'uploaded-file.txt'

s3.upload_file(file_path, bucket_name, key_name)
print("File uploaded successfully")</code></pre>
    </div>

    <!-- Node.js Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Node.js</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>const AWS = require('aws-sdk');
const fs = require('fs');

const s3 = new AWS.S3();
const fileStream = fs.createReadStream('localfile.txt');

s3.upload({
  Bucket: 'my-bucket',
  Key: 'uploaded-file.txt',
  Body: fileStream
}, (err, data) =&gt; {
  if (err) console.log('Error', err);
  else console.log('File uploaded successfully:', data.Location);
});</code></pre>
    </div>

    <!-- Java Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Java</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>import software.amazon.awssdk.services.s3.S3Client;
import software.amazon.awssdk.services.s3.model.PutObjectRequest;
import java.nio.file.Paths;

S3Client s3 = S3Client.create();

s3.putObject(
    PutObjectRequest.builder()
        .bucket("my-bucket")
        .key("uploaded-file.txt")
        .build(),
    Paths.get("localfile.txt")
);

System.out.println("File uploaded successfully");</code></pre>
    </div>

    <!-- Best Practices -->
    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Best Practices</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>Use IAM roles for AWS-hosted applications instead of hardcoding credentials.</li>
        <li>For files larger than 5 GB, use multipart upload to improve reliability and performance.</li>
        <li>Enable server-side encryption if the data is sensitive.</li>
        <li>Handle exceptions and implement retries for network errors or throttling.</li>
        <li>Consider using content-type metadata to make files downloadable or previewable correctly.</li>
      </ul>
    </div>
  </div>
</section>



<section id="aws-sdk-delete-object" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      How to Delete an Object in S3 via AWS SDK
    </h2>

    <p class="text-gray-700 mb-6">
      You can programmatically delete objects from an S3 bucket using AWS SDKs. This can be done for individual files or multiple files at once.
    </p>

    <!-- Python Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Python (Boto3)</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>import boto3

s3 = boto3.client('s3')
bucket_name = 'my-bucket'
key_name = 'file-to-delete.txt'

s3.delete_object(Bucket=bucket_name, Key=key_name)
print("Object deleted successfully")</code></pre>
    </div>

    <!-- Node.js Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Node.js</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>const AWS = require('aws-sdk');
const s3 = new AWS.S3();

s3.deleteObject({
  Bucket: 'my-bucket',
  Key: 'file-to-delete.txt'
}, (err, data) =&gt; {
  if (err) console.log('Error', err);
  else console.log('Object deleted successfully');
});</code></pre>
    </div>

    <!-- Java Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Java</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>import software.amazon.awssdk.services.s3.S3Client;
import software.amazon.awssdk.services.s3.model.DeleteObjectRequest;

S3Client s3 = S3Client.create();

DeleteObjectRequest request = DeleteObjectRequest.builder()
    .bucket("my-bucket")
    .key("file-to-delete.txt")
    .build();

s3.deleteObject(request);
System.out.println("Object deleted successfully");</code></pre>
    </div>

    <!-- Best Practices -->
    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Best Practices</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>Ensure the user or role has proper <code>s3:DeleteObject</code> permissions.</li>
        <li>Be cautious with deletion in versioned buckets; consider using <strong>MFA Delete</strong> to prevent accidental removal.</li>
        <li>For bulk deletion, use <code>delete_objects</code> (Python) or <code>DeleteObjectsRequest</code> (Java) to remove multiple files efficiently.</li>
        <li>Log deletion operations for auditing and recovery purposes.</li>
      </ul>
    </div>
  </div>
</section>



<section id="aws-sdk-versioning-encryption" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      How to Enable Versioning and Encryption on an S3 Bucket Programmatically
    </h2>

    <p class="text-gray-700 mb-6">
      You can configure versioning and server-side encryption (SSE) on an S3 bucket programmatically using AWS SDKs. Versioning helps recover deleted or overwritten objects, while encryption protects data at rest.
    </p>

    <!-- Enable Versioning -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Enable Versioning</h3>

      <!-- Python Example -->
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>import boto3

s3 = boto3.client('s3')
bucket_name = 'my-versioned-bucket'

s3.put_bucket_versioning(
    Bucket=bucket_name,
    VersioningConfiguration={'Status': 'Enabled'}
)
print("Versioning enabled successfully")</code></pre>

      <!-- Node.js Example -->
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mt-2"><code>const AWS = require('aws-sdk');
const s3 = new AWS.S3();

s3.putBucketVersioning({
  Bucket: 'my-versioned-bucket',
  VersioningConfiguration: { Status: 'Enabled' }
}, (err, data) =&gt; {
  if (err) console.log('Error', err);
  else console.log('Versioning enabled successfully');
});</code></pre>

      <!-- Java Example -->
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mt-2"><code>import software.amazon.awssdk.services.s3.S3Client;
import software.amazon.awssdk.services.s3.model.PutBucketVersioningRequest;
import software.amazon.awssdk.services.s3.model.VersioningConfiguration;

S3Client s3 = S3Client.create();

s3.putBucketVersioning(PutBucketVersioningRequest.builder()
    .bucket("my-versioned-bucket")
    .versioningConfiguration(VersioningConfiguration.builder()
        .status("Enabled")
        .build())
    .build());

System.out.println("Versioning enabled successfully");</code></pre>
    </div>

    <!-- Enable Encryption -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Enable Server-Side Encryption (SSE)</h3>

      <!-- Python Example -->
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>s3.put_bucket_encryption(
    Bucket=bucket_name,
    ServerSideEncryptionConfiguration={
        'Rules': [
            {'ApplyServerSideEncryptionByDefault': {'SSEAlgorithm': 'AES256'}}
        ]
    }
)
print("SSE enabled successfully")</code></pre>

      <!-- Node.js Example -->
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mt-2"><code>s3.putBucketEncryption({
  Bucket: 'my-encrypted-bucket',
  ServerSideEncryptionConfiguration: {
    Rules: [{ ApplyServerSideEncryptionByDefault: { SSEAlgorithm: 'AES256' } }]
  }
}, (err, data) =&gt; {
  if (err) console.log('Error', err);
  else console.log('SSE enabled successfully');
});</code></pre>

      <!-- Java Example -->
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mt-2"><code>import software.amazon.awssdk.services.s3.model.PutBucketEncryptionRequest;
import software.amazon.awssdk.services.s3.model.ServerSideEncryptionByDefault;
import software.amazon.awssdk.services.s3.model.ServerSideEncryptionRule;
import software.amazon.awssdk.services.s3.model.ServerSideEncryptionConfiguration;

s3.putBucketEncryption(PutBucketEncryptionRequest.builder()
    .bucket("my-encrypted-bucket")
    .serverSideEncryptionConfiguration(
        ServerSideEncryptionConfiguration.builder()
            .rules(ServerSideEncryptionRule.builder()
                .applyServerSideEncryptionByDefault(
                    ServerSideEncryptionByDefault.builder()
                        .sseAlgorithm("AES256")
                        .build())
                .build())
            .build())
    .build());

System.out.println("SSE enabled successfully");</code></pre>
    </div>

    <!-- Best Practices -->
    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Best Practices</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>Enable versioning to protect against accidental deletion or overwrites.</li>
        <li>Use SSE-KMS for sensitive data to leverage key management and auditing features.</li>
        <li>Combine versioning with lifecycle rules to manage old versions efficiently.</li>
        <li>Ensure IAM policies allow <code>s3:PutBucketVersioning</code> and <code>s3:PutEncryptionConfiguration</code> actions.</li>
      </ul>
    </div>
  </div>
</section>



<section id="aws-sdk-presigned-url" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      How to Generate a Pre-Signed URL Using AWS SDK
    </h2>

    <p class="text-gray-700 mb-6">
      Pre-signed URLs allow you to grant temporary access to an S3 object without exposing your credentials. The URL expires after a specified time and can be used for download or upload operations.
    </p>

    <!-- Python Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Python (Boto3)</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>import boto3
from botocore.client import Config

s3 = boto3.client('s3', config=Config(signature_version='s3v4'))
bucket_name = 'my-bucket'
object_name = 'file.txt'

# Generate pre-signed URL valid for 1 hour
url = s3.generate_presigned_url(
    ClientMethod='get_object',
    Params={'Bucket': bucket_name, 'Key': object_name},
    ExpiresIn=3600
)

print("Pre-signed URL:", url)</code></pre>
    </div>

    <!-- Node.js Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Node.js</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>const AWS = require('aws-sdk');
const s3 = new AWS.S3({ signatureVersion: 'v4' });

const params = {
  Bucket: 'my-bucket',
  Key: 'file.txt',
  Expires: 3600 // 1 hour
};

const url = s3.getSignedUrl('getObject', params);
console.log('Pre-signed URL:', url);</code></pre>
    </div>

    <!-- Java Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Java</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>import software.amazon.awssdk.services.s3.S3Client;
import software.amazon.awssdk.services.s3.presigner.S3Presigner;
import software.amazon.awssdk.services.s3.presigner.model.GetObjectPresignRequest;
import software.amazon.awssdk.services.s3.model.GetObjectRequest;
import java.time.Duration;

S3Presigner presigner = S3Presigner.create();

GetObjectRequest getRequest = GetObjectRequest.builder()
    .bucket("my-bucket")
    .key("file.txt")
    .build();

GetObjectPresignRequest presignRequest = GetObjectPresignRequest.builder()
    .signatureDuration(Duration.ofHours(1))
    .getObjectRequest(getRequest)
    .build();

String url = presigner.presignGetObject(presignRequest).url().toString();
System.out.println("Pre-signed URL: " + url);</code></pre>
    </div>

    <!-- Best Practices -->
    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Best Practices</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>Set an appropriate expiration time for temporary access.</li>
        <li>Use HTTPS URLs to secure the data in transit.</li>
        <li>Limit access via pre-signed URLs to only the required operation (GET or PUT).</li>
        <li>Monitor usage and consider revoking URLs by updating object permissions if needed.</li>
      </ul>
    </div>
  </div>
</section>



<section id="aws-sdk-list-ec2-instances" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      How to List All EC2 Instances in a Region Using AWS SDK
    </h2>

    <p class="text-gray-700 mb-6">
      AWS SDKs allow you to programmatically retrieve details of all EC2 instances in a specific region. You can filter instances by state, tags, or other attributes.
    </p>

    <!-- Python Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Python (Boto3)</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>import boto3

ec2 = boto3.client('ec2', region_name='us-east-1')
response = ec2.describe_instances()

for reservation in response['Reservations']:
    for instance in reservation['Instances']:
        print(instance['InstanceId'], instance['State']['Name'])</code></pre>
    </div>

    <!-- Node.js Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Node.js</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>const AWS = require('aws-sdk');
const ec2 = new AWS.EC2({ region: 'us-east-1' });

ec2.describeInstances({}, (err, data) =&gt; {
  if (err) console.log('Error', err);
  else {
    data.Reservations.forEach(reservation =&gt; {
      reservation.Instances.forEach(instance =&gt; {
        console.log(instance.InstanceId, instance.State.Name);
      });
    });
  }
});</code></pre>
    </div>

    <!-- Java Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Java</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>import software.amazon.awssdk.services.ec2.Ec2Client;
import software.amazon.awssdk.services.ec2.model.DescribeInstancesResponse;
import software.amazon.awssdk.services.ec2.model.Reservation;
import software.amazon.awssdk.services.ec2.model.Instance;

Ec2Client ec2 = Ec2Client.create();

DescribeInstancesResponse response = ec2.describeInstances();

for (Reservation reservation : response.reservations()) {
    for (Instance instance : reservation.instances()) {
        System.out.println(instance.instanceId() + " " + instance.state().name());
    }
}</code></pre>
    </div>

    <!-- Best Practices -->
    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Best Practices</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>Use filters to reduce the amount of data returned if you have many instances.</li>
        <li>Ensure your IAM role or user has <code>ec2:DescribeInstances</code> permissions.</li>
        <li>Handle pagination for large number of instances using <code>NextToken</code> (Node.js/Python) or paginators (Java SDK).</li>
        <li>Consider caching instance information if accessed frequently to reduce API calls.</li>
      </ul>
    </div>
  </div>
</section>



<section id="aws-sdk-ec2-start-stop-terminate" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      How to Start, Stop, or Terminate an EC2 Instance Programmatically
    </h2>

    <p class="text-gray-700 mb-6">
      AWS SDKs provide APIs to manage the lifecycle of EC2 instances. You can start, stop, or terminate instances by specifying their instance IDs.
    </p>

    <!-- Python Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Python (Boto3)</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>import boto3

ec2 = boto3.client('ec2', region_name='us-east-1')
instance_id = 'i-0123456789abcdef0'

# Start instance
ec2.start_instances(InstanceIds=[instance_id])
print("Instance started")

# Stop instance
ec2.stop_instances(InstanceIds=[instance_id])
print("Instance stopped")

# Terminate instance
ec2.terminate_instances(InstanceIds=[instance_id])
print("Instance terminated")</code></pre>
    </div>

    <!-- Node.js Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Node.js</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>const AWS = require('aws-sdk');
const ec2 = new AWS.EC2({ region: 'us-east-1' });
const instanceId = 'i-0123456789abcdef0';

// Start instance
ec2.startInstances({ InstanceIds: [instanceId] }, (err, data) =&gt; {
  if (err) console.log(err);
  else console.log('Instance started');
});

// Stop instance
ec2.stopInstances({ InstanceIds: [instanceId] }, (err, data) =&gt; {
  if (err) console.log(err);
  else console.log('Instance stopped');
});

// Terminate instance
ec2.terminateInstances({ InstanceIds: [instanceId] }, (err, data) =&gt; {
  if (err) console.log(err);
  else console.log('Instance terminated');
});</code></pre>
    </div>

    <!-- Java Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Java</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>import software.amazon.awssdk.services.ec2.Ec2Client;
import software.amazon.awssdk.services.ec2.model.StartInstancesRequest;
import software.amazon.awssdk.services.ec2.model.StopInstancesRequest;
import software.amazon.awssdk.services.ec2.model.TerminateInstancesRequest;

Ec2Client ec2 = Ec2Client.create();
String instanceId = "i-0123456789abcdef0";

// Start
ec2.startInstances(StartInstancesRequest.builder().instanceIds(instanceId).build());
System.out.println("Instance started");

// Stop
ec2.stopInstances(StopInstancesRequest.builder().instanceIds(instanceId).build());
System.out.println("Instance stopped");

// Terminate
ec2.terminateInstances(TerminateInstancesRequest.builder().instanceIds(instanceId).build());
System.out.println("Instance terminated");</code></pre>
    </div>

    <!-- Best Practices -->
    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Best Practices</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>Ensure your IAM role or user has the required permissions: <code>ec2:StartInstances</code>, <code>ec2:StopInstances</code>, <code>ec2:TerminateInstances</code>.</li>
        <li>Double-check instance IDs before termination to avoid accidental deletion.</li>
        <li>Consider tagging instances for easier management when performing batch operations.</li>
        <li>Handle exceptions and API throttling for production environments.</li>
      </ul>
    </div>
  </div>
</section>




<section id="aws-sdk-describe-ec2-instance" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      How to Describe Details of a Specific EC2 Instance Using AWS SDK
    </h2>

    <p class="text-gray-700 mb-6">
      You can retrieve detailed information about a specific EC2 instance, including its state, type, public/private IP addresses, and tags, by using AWS SDKs.
    </p>

    <!-- Python Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Python (Boto3)</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>import boto3

ec2 = boto3.client('ec2', region_name='us-east-1')
instance_id = 'i-0123456789abcdef0'

response = ec2.describe_instances(InstanceIds=[instance_id])
instance = response['Reservations'][0]['Instances'][0]

print("Instance ID:", instance['InstanceId'])
print("State:", instance['State']['Name'])
print("Instance Type:", instance['InstanceType'])
print("Public IP:", instance.get('PublicIpAddress'))
print("Private IP:", instance['PrivateIpAddress'])
print("Tags:", instance.get('Tags'))</code></pre>
    </div>

    <!-- Node.js Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Node.js</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>const AWS = require('aws-sdk');
const ec2 = new AWS.EC2({ region: 'us-east-1' });
const instanceId = 'i-0123456789abcdef0';

ec2.describeInstances({ InstanceIds: [instanceId] }, (err, data) =&gt; {
  if (err) console.log(err);
  else {
    const instance = data.Reservations[0].Instances[0];
    console.log('Instance ID:', instance.InstanceId);
    console.log('State:', instance.State.Name);
    console.log('Type:', instance.InstanceType);
    console.log('Public IP:', instance.PublicIpAddress);
    console.log('Private IP:', instance.PrivateIpAddress);
    console.log('Tags:', instance.Tags);
  }
});</code></pre>
    </div>

    <!-- Java Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Java</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>import software.amazon.awssdk.services.ec2.Ec2Client;
import software.amazon.awssdk.services.ec2.model.DescribeInstancesRequest;
import software.amazon.awssdk.services.ec2.model.DescribeInstancesResponse;
import software.amazon.awssdk.services.ec2.model.Reservation;
import software.amazon.awssdk.services.ec2.model.Instance;

Ec2Client ec2 = Ec2Client.create();
String instanceId = "i-0123456789abcdef0";

DescribeInstancesResponse response = ec2.describeInstances(
    DescribeInstancesRequest.builder().instanceIds(instanceId).build()
);

Instance instance = response.reservations().get(0).instances().get(0);
System.out.println("Instance ID: " + instance.instanceId());
System.out.println("State: " + instance.state().name());
System.out.println("Type: " + instance.instanceType());
System.out.println("Public IP: " + instance.publicIpAddress());
System.out.println("Private IP: " + instance.privateIpAddress());
System.out.println("Tags: " + instance.tags());</code></pre>
    </div>

    <!-- Best Practices -->
    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Best Practices</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>Ensure the IAM role or user has <code>ec2:DescribeInstances</code> permissions.</li>
        <li>Handle cases where the instance ID does not exist or has been terminated.</li>
        <li>Use filters to narrow down instances when querying multiple IDs.</li>
        <li>Consider caching frequently accessed instance details to reduce API calls.</li>
      </ul>
    </div>
  </div>
</section>



<section id="aws-sdk-attach-iam-role-ec2" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      How to Attach an IAM Role to an EC2 Instance via AWS SDK
    </h2>

    <p class="text-gray-700 mb-6">
      You can attach an IAM role to an existing EC2 instance to grant it temporary credentials for accessing AWS services without embedding credentials. This is done by associating an IAM instance profile with the EC2 instance.
    </p>

    <!-- Python Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Python (Boto3)</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>import boto3

ec2 = boto3.client('ec2', region_name='us-east-1')
instance_id = 'i-0123456789abcdef0'
iam_instance_profile = {'Name': 'MyEC2RoleProfile'}

ec2.associate_iam_instance_profile(
    IamInstanceProfile=iam_instance_profile,
    InstanceId=instance_id
)

print("IAM role attached successfully")</code></pre>
    </div>

    <!-- Node.js Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Node.js</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>const AWS = require('aws-sdk');
const ec2 = new AWS.EC2({ region: 'us-east-1' });

const params = {
  IamInstanceProfile: { Name: 'MyEC2RoleProfile' },
  InstanceId: 'i-0123456789abcdef0'
};

ec2.associateIamInstanceProfile(params, (err, data) =&gt; {
  if (err) console.log(err);
  else console.log('IAM role attached successfully');
});</code></pre>
    </div>

    <!-- Java Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Java</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>import software.amazon.awssdk.services.ec2.Ec2Client;
import software.amazon.awssdk.services.ec2.model.AssociateIamInstanceProfileRequest;
import software.amazon.awssdk.services.ec2.model.IamInstanceProfileSpecification;

Ec2Client ec2 = Ec2Client.create();

IamInstanceProfileSpecification profileSpec = IamInstanceProfileSpecification.builder()
    .name("MyEC2RoleProfile")
    .build();

AssociateIamInstanceProfileRequest request = AssociateIamInstanceProfileRequest.builder()
    .instanceId("i-0123456789abcdef0")
    .iamInstanceProfile(profileSpec)
    .build();

ec2.associateIamInstanceProfile(request);
System.out.println("IAM role attached successfully");</code></pre>
    </div>

    <!-- Best Practices -->
    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Best Practices</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>Ensure the IAM role has the necessary policies for the tasks your EC2 instance will perform.</li>
        <li>Use instance profiles instead of directly embedding access keys.</li>
        <li>You can attach only one IAM instance profile at a time to an EC2 instance.</li>
        <li>Detach or replace IAM roles carefully to avoid interruptions for running applications.</li>
      </ul>
    </div>
  </div>
</section>



<section id="aws-sdk-attach-policy-iam-user" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      How to Attach a Policy to an IAM User Programmatically
    </h2>

    <p class="text-gray-700 mb-6">
      AWS SDKs allow you to attach managed or inline policies to an IAM user programmatically. Managed policies are reusable and maintained by AWS or your account, while inline policies are embedded directly in the user.
    </p>

    <!-- Python Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Python (Boto3)</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>import boto3

iam = boto3.client('iam')
user_name = 'MyUser'
policy_arn = 'arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess'

# Attach managed policy
iam.attach_user_policy(UserName=user_name, PolicyArn=policy_arn)
print("Policy attached successfully")</code></pre>
    </div>

    <!-- Node.js Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Node.js</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>const AWS = require('aws-sdk');
const iam = new AWS.IAM();

const params = {
  UserName: 'MyUser',
  PolicyArn: 'arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess'
};

iam.attachUserPolicy(params, (err, data) =&gt; {
  if (err) console.log(err);
  else console.log('Policy attached successfully');
});</code></pre>
    </div>

    <!-- Java Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Java</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>import software.amazon.awssdk.services.iam.IamClient;
import software.amazon.awssdk.services.iam.model.AttachUserPolicyRequest;

IamClient iam = IamClient.create();

AttachUserPolicyRequest request = AttachUserPolicyRequest.builder()
    .userName("MyUser")
    .policyArn("arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess")
    .build();

iam.attachUserPolicy(request);
System.out.println("Policy attached successfully");</code></pre>
    </div>

    <!-- Best Practices -->
    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Best Practices</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>Prefer attaching managed policies over inline policies for better reuse and maintenance.</li>
        <li>Follow the principle of least privilege – grant only the permissions required.</li>
        <li>Audit attached policies regularly to ensure compliance with security standards.</li>
        <li>Use IAM roles for applications running on AWS services instead of IAM users wherever possible.</li>
      </ul>
    </div>
  </div>
</section>



<section id="aws-sdk-create-dynamodb-table" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      How to Create a DynamoDB Table Using AWS SDK
    </h2>

    <p class="text-gray-700 mb-6">
      AWS SDKs allow you to create DynamoDB tables programmatically. You define the table name, primary key schema, attribute types, and provisioned throughput (or use on-demand mode) when creating the table.
    </p>

    <!-- Python Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Python (Boto3)</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>import boto3

dynamodb = boto3.client('dynamodb', region_name='us-east-1')

table_name = 'UsersTable'

response = dynamodb.create_table(
    TableName=table_name,
    KeySchema=[
        {'AttributeName': 'UserId', 'KeyType': 'HASH'}  # Partition key
    ],
    AttributeDefinitions=[
        {'AttributeName': 'UserId', 'AttributeType': 'S'}
    ],
    BillingMode='PAY_PER_REQUEST'  # On-demand
)

print(f"Table {table_name} creation initiated")
print("Status:", response['TableDescription']['TableStatus'])</code></pre>
    </div>

    <!-- Node.js Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Node.js</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>const AWS = require('aws-sdk');
const dynamodb = new AWS.DynamoDB({ region: 'us-east-1' });

const params = {
  TableName: 'UsersTable',
  KeySchema: [{ AttributeName: 'UserId', KeyType: 'HASH' }],
  AttributeDefinitions: [{ AttributeName: 'UserId', AttributeType: 'S' }],
  BillingMode: 'PAY_PER_REQUEST'
};

dynamodb.createTable(params, (err, data) =&gt; {
  if (err) console.log(err);
  else console.log('Table creation initiated:', data.TableDescription.TableStatus);
});</code></pre>
    </div>

    <!-- Java Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Java</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>import software.amazon.awssdk.services.dynamodb.DynamoDbClient;
import software.amazon.awssdk.services.dynamodb.model.*;

DynamoDbClient dynamoDb = DynamoDbClient.create();

CreateTableRequest request = CreateTableRequest.builder()
    .tableName("UsersTable")
    .keySchema(KeySchemaElement.builder()
        .attributeName("UserId")
        .keyType(KeyType.HASH)
        .build())
    .attributeDefinitions(AttributeDefinition.builder()
        .attributeName("UserId")
        .attributeType(ScalarAttributeType.S)
        .build())
    .billingMode(BillingMode.PAY_PER_REQUEST)
    .build();

CreateTableResponse response = dynamoDb.createTable(request);
System.out.println("Table creation initiated, status: " + response.tableDescription().tableStatus());</code></pre>
    </div>

    <!-- Best Practices -->
    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Best Practices</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>Use on-demand billing for unpredictable workloads to avoid provisioning errors.</li>
        <li>Choose meaningful partition and sort keys for efficient querying.</li>
        <li>Consider adding secondary indexes if you need alternate query patterns.</li>
        <li>Enable encryption at rest and point-in-time recovery for production tables.</li>
      </ul>
    </div>
  </div>
</section>




<section id="aws-sdk-insert-dynamodb-item" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      How to Insert an Item into a DynamoDB Table Using AWS SDK
    </h2>

    <p class="text-gray-700 mb-6">
      You can add a new item to a DynamoDB table programmatically using the <code>PutItem</code> operation. Each item must include the primary key attributes defined for the table.
    </p>

    <!-- Python Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Python (Boto3)</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>import boto3

dynamodb = boto3.resource('dynamodb', region_name='us-east-1')
table = dynamodb.Table('UsersTable')

item = {
    'UserId': '123',
    'Name': 'Alice',
    'Email': 'alice@example.com'
}

table.put_item(Item=item)
print("Item inserted successfully")</code></pre>
    </div>

    <!-- Node.js Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Node.js</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>const AWS = require('aws-sdk');
const docClient = new AWS.DynamoDB.DocumentClient({ region: 'us-east-1' });

const params = {
  TableName: 'UsersTable',
  Item: {
    UserId: '123',
    Name: 'Alice',
    Email: 'alice@example.com'
  }
};

docClient.put(params, (err, data) =&gt; {
  if (err) console.log(err);
  else console.log('Item inserted successfully');
});</code></pre>
    </div>

    <!-- Java Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Java</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>import software.amazon.awssdk.services.dynamodb.DynamoDbClient;
import software.amazon.awssdk.services.dynamodb.model.PutItemRequest;
import software.amazon.awssdk.services.dynamodb.model.AttributeValue;
import java.util.HashMap;
import java.util.Map;

DynamoDbClient dynamoDb = DynamoDbClient.create();

Map<String, AttributeValue> item = new HashMap<>();
item.put("UserId", AttributeValue.builder().s("123").build());
item.put("Name", AttributeValue.builder().s("Alice").build());
item.put("Email", AttributeValue.builder().s("alice@example.com").build());

PutItemRequest request = PutItemRequest.builder()
    .tableName("UsersTable")
    .item(item)
    .build();

dynamoDb.putItem(request);
System.out.println("Item inserted successfully");</code></pre>
    </div>

    <!-- Best Practices -->
    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Best Practices</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>Always include the primary key attributes to avoid conditional errors.</li>
        <li>Use <code>ConditionExpression</code> to prevent overwriting existing items if needed.</li>
        <li>Batch writes can be used to insert multiple items efficiently.</li>
        <li>Validate data types (S, N, BOOL, etc.) according to your table schema.</li>
      </ul>
    </div>
  </div>
</section>



<section id="aws-sdk-get-dynamodb-item" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      How to Retrieve an Item by Key from DynamoDB Using AWS SDK
    </h2>

    <p class="text-gray-700 mb-6">
      You can fetch a specific item from a DynamoDB table using its primary key with the <code>GetItem</code> operation. This retrieves only the item that matches the specified key.
    </p>

    <!-- Python Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Python (Boto3)</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>import boto3

dynamodb = boto3.resource('dynamodb', region_name='us-east-1')
table = dynamodb.Table('UsersTable')

response = table.get_item(Key={'UserId': '123'})
item = response.get('Item')

if item:
    print("Item retrieved:", item)
else:
    print("Item not found")</code></pre>
    </div>

    <!-- Node.js Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Node.js</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>const AWS = require('aws-sdk');
const docClient = new AWS.DynamoDB.DocumentClient({ region: 'us-east-1' });

const params = {
  TableName: 'UsersTable',
  Key: { UserId: '123' }
};

docClient.get(params, (err, data) =&gt; {
  if (err) console.log(err);
  else if (data.Item) console.log('Item retrieved:', data.Item);
  else console.log('Item not found');
});</code></pre>
    </div>

    <!-- Java Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Java</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>import software.amazon.awssdk.services.dynamodb.DynamoDbClient;
import software.amazon.awssdk.services.dynamodb.model.GetItemRequest;
import software.amazon.awssdk.services.dynamodb.model.AttributeValue;
import java.util.HashMap;
import java.util.Map;

DynamoDbClient dynamoDb = DynamoDbClient.create();

Map<String, AttributeValue> key = new HashMap<>();
key.put("UserId", AttributeValue.builder().s("123").build());

GetItemRequest request = GetItemRequest.builder()
    .tableName("UsersTable")
    .key(key)
    .build();

var response = dynamoDb.getItem(request);
if (response.hasItem()) System.out.println("Item retrieved: " + response.item());
else System.out.println("Item not found");</code></pre>
    </div>

    <!-- Best Practices -->
    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Best Practices</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>Always specify the primary key to ensure efficient retrieval.</li>
        <li>Handle the case where the item may not exist to prevent errors.</li>
        <li>Use <code>ProjectionExpression</code> to fetch only required attributes and reduce read throughput.</li>
        <li>For multiple items, consider <code>BatchGetItem</code> to optimize API calls.</li>
      </ul>
    </div>
  </div>
</section>

   

<section id="aws-sdk-update-delete-dynamodb-item" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      How to Update or Delete an Item in DynamoDB Programmatically
    </h2>

    <p class="text-gray-700 mb-6">
      AWS SDKs allow you to update attributes of an existing item using <code>UpdateItem</code> and remove an item completely using <code>DeleteItem</code>. Both operations require specifying the primary key of the item.
    </p>

    <!-- Python Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Python (Boto3)</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>import boto3

dynamodb = boto3.resource('dynamodb', region_name='us-east-1')
table = dynamodb.Table('UsersTable')

# Update item
table.update_item(
    Key={'UserId': '123'},
    UpdateExpression='SET Email = :email',
    ExpressionAttributeValues={':email': 'newalice@example.com'}
)
print("Item updated successfully")

# Delete item
table.delete_item(Key={'UserId': '123'})
print("Item deleted successfully")</code></pre>
    </div>

    <!-- Node.js Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Node.js</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>const AWS = require('aws-sdk');
const docClient = new AWS.DynamoDB.DocumentClient({ region: 'us-east-1' });

const updateParams = {
  TableName: 'UsersTable',
  Key: { UserId: '123' },
  UpdateExpression: 'SET Email = :email',
  ExpressionAttributeValues: { ':email': 'newalice@example.com' }
};

docClient.update(updateParams, (err, data) =&gt; {
  if (err) console.log(err);
  else console.log('Item updated successfully');
});

const deleteParams = {
  TableName: 'UsersTable',
  Key: { UserId: '123' }
};

docClient.delete(deleteParams, (err, data) =&gt; {
  if (err) console.log(err);
  else console.log('Item deleted successfully');
});</code></pre>
    </div>

    <!-- Java Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Java</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>import software.amazon.awssdk.services.dynamodb.DynamoDbClient;
import software.amazon.awssdk.services.dynamodb.model.*;

import java.util.HashMap;
import java.util.Map;

DynamoDbClient dynamoDb = DynamoDbClient.create();

// Update item
Map<String, AttributeValue> key = new HashMap<>();
key.put("UserId", AttributeValue.builder().s("123").build());

Map<String, AttributeValue> expressionValues = new HashMap<>();
expressionValues.put(":email", AttributeValue.builder().s("newalice@example.com").build());

UpdateItemRequest updateRequest = UpdateItemRequest.builder()
    .tableName("UsersTable")
    .key(key)
    .updateExpression("SET Email = :email")
    .expressionAttributeValues(expressionValues)
    .build();

dynamoDb.updateItem(updateRequest);
System.out.println("Item updated successfully");

// Delete item
DeleteItemRequest deleteRequest = DeleteItemRequest.builder()
    .tableName("UsersTable")
    .key(key)
    .build();

dynamoDb.deleteItem(deleteRequest);
System.out.println("Item deleted successfully");</code></pre>
    </div>

    <!-- Best Practices -->
    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Best Practices</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>Use <code>ConditionExpression</code> to prevent unintended updates or deletions.</li>
        <li>Always specify the primary key when updating or deleting items.</li>
        <li>For bulk operations, consider <code>BatchWriteItem</code> to improve efficiency.</li>
        <li>Validate data types and attribute names to avoid runtime errors.</li>
      </ul>
    </div>
  </div>
</section>




<section id="aws-sdk-scan-query-dynamodb" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      How to Scan or Query a DynamoDB Table Using AWS SDK
    </h2>

    <p class="text-gray-700 mb-6">
      You can retrieve multiple items from a DynamoDB table using either <code>Scan</code> or <code>Query</code> operations. <code>Query</code> is more efficient when filtering by primary key or secondary index, while <code>Scan</code> reads the entire table.
    </p>

    <!-- Python Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Python (Boto3)</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>import boto3

dynamodb = boto3.resource('dynamodb', region_name='us-east-1')
table = dynamodb.Table('UsersTable')

# Query example: get users with UserId starting with '123'
response = table.query(
    KeyConditionExpression=boto3.dynamodb.conditions.Key('UserId').eq('123')
)
items = response['Items']
print("Query results:", items)

# Scan example: get all users
scan_response = table.scan()
all_items = scan_response['Items']
print("Scan results:", all_items)</code></pre>
    </div>

    <!-- Node.js Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Node.js</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>const AWS = require('aws-sdk');
const docClient = new AWS.DynamoDB.DocumentClient({ region: 'us-east-1' });

// Query example
docClient.query({
  TableName: 'UsersTable',
  KeyConditionExpression: 'UserId = :uid',
  ExpressionAttributeValues: { ':uid': '123' }
}, (err, data) =&gt; {
  if (err) console.log(err);
  else console.log('Query results:', data.Items);
});

// Scan example
docClient.scan({ TableName: 'UsersTable' }, (err, data) =&gt; {
  if (err) console.log(err);
  else console.log('Scan results:', data.Items);
});</code></pre>
    </div>

    <!-- Java Example -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6">
      <h3 class="text-xl font-semibold text-gray-900 mb-4">Java</h3>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto"><code>import software.amazon.awssdk.services.dynamodb.DynamoDbClient;
import software.amazon.awssdk.services.dynamodb.model.*;

import java.util.HashMap;
import java.util.Map;

DynamoDbClient dynamoDb = DynamoDbClient.create();

// Query example
Map<String, AttributeValue> keyValues = new HashMap<>();
keyValues.put(":uid", AttributeValue.builder().s("123").build());

QueryRequest queryRequest = QueryRequest.builder()
    .tableName("UsersTable")
    .keyConditionExpression("UserId = :uid")
    .expressionAttributeValues(keyValues)
    .build();

QueryResponse queryResponse = dynamoDb.query(queryRequest);
System.out.println("Query results: " + queryResponse.items());

// Scan example
ScanRequest scanRequest = ScanRequest.builder()
    .tableName("UsersTable")
    .build();

ScanResponse scanResponse = dynamoDb.scan(scanRequest);
System.out.println("Scan results: " + scanResponse.items());</code></pre>
    </div>

    <!-- Best Practices -->
    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Best Practices</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>Use <code>Query</code> whenever possible, as it is faster and consumes fewer read capacity units.</li>
        <li>Apply <code>FilterExpression</code> to limit returned items without extra queries.</li>
        <li>Use pagination for large result sets to avoid memory issues.</li>
        <li>For scans on huge tables, consider using parallel scans or moving rarely accessed data to S3 for analytics.</li>
      </ul>
    </div>
  </div>
</section>




<section id="aws-api-vs-cli-sdk" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      What is AWS API, and How Does It Differ from AWS CLI and SDK?
    </h2>

    <p class="text-gray-700 mb-6">
      An <strong>AWS API</strong> is a set of HTTP-based endpoints provided by AWS services that allow you to interact programmatically with AWS. You send requests (like GET, POST, PUT, DELETE) to perform actions such as creating an S3 bucket, launching an EC2 instance, or querying DynamoDB.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">Differences from CLI and SDK</h3>
    <ul class="list-disc list-inside text-gray-700 space-y-2 mb-6">
      <li>
        <strong>AWS CLI:</strong> A command-line tool built on top of AWS APIs that lets you execute AWS commands in your terminal. It abstracts HTTP requests and handles authentication automatically.
      </li>
      <li>
        <strong>AWS SDK:</strong> Language-specific libraries (Python, Java, Node.js, etc.) that wrap AWS APIs, providing higher-level functions, type checking, and easier integration within applications.
      </li>
      <li>
        <strong>AWS API:</strong> The raw interface for all AWS services. SDKs and CLI internally make API calls, so you could interact directly with APIs using HTTP requests, but SDKs/CLI make it simpler and safer.
      </li>
    </ul>

    <!-- Example Illustration -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6 text-gray-700">
      <p>
        <strong>Example:</strong> To create an S3 bucket:
      </p>
      <ul class="list-inside list-disc mt-2">
        <li><strong>API call:</strong> Send a PUT request to <code>https://s3.amazonaws.com/mybucket</code> with proper authentication headers.</li>
        <li><strong>CLI:</strong> <code>aws s3 mb s3://mybucket</code></li>
        <li><strong>SDK (Python Boto3):</strong> <code>boto3.client('s3').create_bucket(Bucket='mybucket')</code></li>
      </ul>
    </div>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Key Takeaways</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>API is the fundamental interface; SDKs and CLI are built on top of it.</li>
        <li>SDKs provide language-specific abstractions for easier development.</li>
        <li>CLI is ideal for quick command-line operations and scripting.</li>
        <li>Direct API usage offers full control but requires handling requests, authentication, and parsing responses manually.</li>
      </ul>
    </div>
  </div>
</section>



<section id="aws-api-authentication-authorization" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      How AWS APIs Handle Authentication and Authorization
    </h2>

    <p class="text-gray-700 mb-6">
      AWS APIs require secure authentication and authorization to ensure that only permitted users or applications can access resources. This is typically done using AWS credentials (access keys, secret keys) and IAM policies.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">Authentication</h3>
    <p class="text-gray-700 mb-4">
      AWS authenticates API requests using a signature-based system called <strong>Signature Version 4 (SigV4)</strong>. Each request must include:
    </p>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>An <strong>AWS Access Key ID</strong> identifying the caller.</li>
      <li>A <strong>Secret Access Key</strong> used to sign the request.</li>
      <li>A timestamp to prevent replay attacks.</li>
      <li>Optionally, a session token for temporary credentials.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">Authorization</h3>
    <p class="text-gray-700 mb-4">
      After authenticating the request, AWS checks whether the caller has permission to perform the requested action using IAM policies, resource-based policies, or service control policies.
    </p>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li><strong>IAM Policies:</strong> Define what actions a user, group, or role can perform on which resources.</li>
      <li><strong>Resource Policies:</strong> Policies attached to resources like S3 buckets or Lambda functions to control access.</li>
      <li><strong>Service Control Policies (SCPs):</strong> Organizational policies that restrict permissions across accounts.</li>
    </ul>

    <!-- Example Illustration -->
    <div class="p-6 bg-white rounded-2xl border shadow-sm mb-6 text-gray-700">
      <p>
        <strong>Example:</strong> When calling S3 API to get an object:
      </p>
      <ul class="list-inside list-disc mt-2">
        <li>The request is signed with your access key and secret key (SigV4).</li>
        <li>AWS checks IAM policies attached to your user/role to see if <code>s3:GetObject</code> is allowed on the target bucket.</li>
        <li>If allowed, the object is returned; otherwise, an <code>AccessDenied</code> error is returned.</li>
      </ul>
    </div>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Best Practices</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>Use IAM roles for applications running on AWS services instead of storing access keys locally.</li>
        <li>Rotate access keys regularly if used outside of IAM roles.</li>
        <li>Grant least privilege – only allow the minimum required actions.</li>
        <li>Use temporary credentials (STS) for cross-account or short-lived access.</li>
      </ul>
    </div>
  </div>
</section>



<section id="aws-api-endpoints" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      What Are AWS API Endpoints, and How Are They Structured?
    </h2>

    <p class="text-gray-700 mb-6">
      AWS API endpoints are URLs that serve as the entry points for making API requests to AWS services. Each endpoint is specific to a service and often to a region, enabling you to interact with AWS programmatically.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">Endpoint Structure</h3>
    <p class="text-gray-700 mb-4">
      A typical AWS API endpoint URL follows this format:
    </p>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>https://{service}.{region}.amazonaws.com/{api-version}/{resource}</code></pre>

    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li><strong>service:</strong> The AWS service, e.g., <code>s3</code>, <code>ec2</code>, <code>dynamodb</code>.</li>
      <li><strong>region:</strong> AWS region, e.g., <code>us-east-1</code>, <code>eu-west-1</code>.</li>
      <li><strong>api-version:</strong> Optional version of the API (depends on service).</li>
      <li><strong>resource:</strong> Specific resource or operation, e.g., <code>/tables/UsersTable</code>.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">Example Endpoints</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li><strong>S3 (region-specific):</strong> <code>https://s3.us-east-1.amazonaws.com/mybucket/myobject</code></li>
      <li><strong>DynamoDB (API version):</strong> <code>https://dynamodb.us-east-1.amazonaws.com/</code></li>
      <li><strong>EC2:</strong> <code>https://ec2.us-west-2.amazonaws.com/?Action=DescribeInstances</code></li>
    </ul>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Key Points</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>Endpoints determine the AWS service and region your request interacts with.</li>
        <li>Some services, like S3, also support global endpoints (<code>s3.amazonaws.com</code>).</li>
        <li>Using the correct endpoint ensures low latency and proper regional data handling.</li>
        <li>CLI and SDKs automatically select appropriate endpoints, but you can override them if needed.</li>
      </ul>
    </div>
  </div>
</section>



<section id="aws-rest-vs-query-api" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      Difference Between REST API and Query API in AWS
    </h2>

    <p class="text-gray-700 mb-6">
      AWS services expose two main types of APIs: <strong>REST APIs</strong> and <strong>Query APIs</strong>. They differ in how requests are structured, sent, and processed.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">REST API</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Uses standard HTTP methods: <code>GET</code>, <code>POST</code>, <code>PUT</code>, <code>DELETE</code>.</li>
      <li>Resource-oriented: URL paths represent resources (e.g., <code>/users/123</code>).</li>
      <li>Supports JSON payloads for requests and responses.</li>
      <li>Commonly used by services like Amazon S3, API Gateway, and Lambda.</li>
      <li>Example: <code>GET https://s3.us-east-1.amazonaws.com/mybucket/myobject</code></li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">Query API</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Uses HTTP GET or POST but encodes the action and parameters in the query string or request body.</li>
      <li>Action-oriented: specifies <code>Action</code> and <code>Version</code> parameters instead of resource paths.</li>
      <li>Responses are often XML or JSON.</li>
      <li>Commonly used by older AWS services like EC2, RDS, and IAM.</li>
      <li>Example: <code>https://ec2.us-east-1.amazonaws.com/?Action=DescribeInstances&amp;Version=2016-11-15</code></li>
    </ul>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Key Differences</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>REST APIs are resource-based, while Query APIs are action-based.</li>
        <li>REST APIs typically use JSON; Query APIs often use URL-encoded parameters and XML responses.</li>
        <li>REST APIs are easier to integrate with modern web applications.</li>
        <li>Query APIs require specifying an action explicitly, which may be less intuitive for developers.</li>
      </ul>
    </div>
  </div>
</section>



<section id="aws-api-request-postman-curl" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      How to Make an AWS API Request Using Postman or cURL
    </h2>

    <p class="text-gray-700 mb-6">
      You can interact directly with AWS APIs using tools like <strong>Postman</strong> or <strong>cURL</strong>. Each request must be properly authenticated using AWS Signature Version 4 (SigV4).
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">Steps for Making API Requests</h3>
    <ol class="list-decimal list-inside text-gray-700 mb-6 space-y-2">
      <li>Obtain your <strong>AWS Access Key ID</strong> and <strong>Secret Access Key</strong>.</li>
      <li>Determine the correct API endpoint and HTTP method for the AWS service and action.</li>
      <li>Generate a SigV4 signed request, including required headers and a timestamp.</li>
      <li>Send the request using Postman or cURL.</li>
      <li>Parse the response (usually JSON or XML) to process results.</li>
    </ol>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">Example: Using cURL with S3</h3>
    <p class="text-gray-700 mb-4">Direct cURL calls require SigV4 signing, which is complex. Using AWS CLI to generate the signed request is easier:</p>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code># Generate a signed URL with AWS CLI
aws s3 presign s3://mybucket/myobject --expires-in 3600

# Use cURL to download the object
curl "https://mybucket.s3.amazonaws.com/myobject?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=...&X-Amz-Signature=..." -o myobject</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">Example: Using Postman</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Set the request method (GET, POST, PUT, DELETE).</li>
      <li>Enter the API endpoint URL.</li>
      <li>In the "Authorization" tab, select <strong>AWS Signature</strong> and provide Access Key, Secret Key, AWS region, and service name.</li>
      <li>Send the request and view the response.</li>
    </ul>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Best Practices</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>Use temporary credentials (IAM roles or STS tokens) instead of long-lived access keys.</li>
        <li>Prefer SDKs or CLI for generating signed requests automatically.</li>
        <li>Ensure your system clock is accurate; SigV4 signatures are time-sensitive.</li>
        <li>Validate permissions with IAM policies to avoid AccessDenied errors.</li>
      </ul>
    </div>
  </div>
</section>



<section id="aws-api-secure-requests" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      How to Secure AWS API Requests Without Exposing Access Keys
    </h2>

    <p class="text-gray-700 mb-6">
      Exposing AWS access keys in applications or public repositories is a serious security risk. There are several best practices to secure API requests without directly embedding access keys.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Use IAM Roles</h3>
    <p class="text-gray-700 mb-4">
      Assign IAM roles to AWS resources like EC2, Lambda, or ECS. Applications running on these resources automatically receive temporary credentials via the metadata service.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. Use AWS STS (Temporary Security Credentials)</h3>
    <p class="text-gray-700 mb-4">
      AWS Security Token Service (STS) allows you to generate temporary credentials with limited permissions and expiry times, reducing the risk if credentials are compromised.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. Use AWS Cognito or Identity Federation</h3>
    <p class="text-gray-700 mb-4">
      For web or mobile applications, use Amazon Cognito or federated identities to provide temporary, scoped credentials to users without exposing long-term keys.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">4. Use Pre-Signed URLs or Signed Requests</h3>
    <p class="text-gray-700 mb-6">
      For services like S3, generate pre-signed URLs that allow temporary access to specific resources. The application never needs to expose credentials to end users.
    </p>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Best Practices</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>Never hardcode AWS access keys in code or commit them to source control.</li>
        <li>Use least privilege IAM policies when generating temporary credentials.</li>
        <li>Rotate credentials regularly and monitor usage with AWS CloudTrail.</li>
        <li>Prefer SDKs that automatically fetch temporary credentials from IAM roles or Cognito.</li>
      </ul>
    </div>
  </div>
</section>



<section id="aws-api-construct-request" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      How to Construct an AWS API Request for Services like S3 or EC2
    </h2>

    <p class="text-gray-700 mb-6">
      Constructing an AWS API request involves specifying the service endpoint, HTTP method, headers, authentication, and request parameters. This ensures AWS can process your request correctly and securely.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">Step 1: Identify the Service Endpoint</h3>
    <p class="text-gray-700 mb-4">
      Each AWS service has region-specific endpoints. For example:
    </p>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>S3: <code>https://s3.us-east-1.amazonaws.com/mybucket/myobject</code></li>
      <li>EC2: <code>https://ec2.us-east-1.amazonaws.com</code></li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">Step 2: Choose HTTP Method</h3>
    <p class="text-gray-700 mb-6">
      AWS APIs typically use standard HTTP methods:
      <ul class="list-disc list-inside text-gray-700 mt-2">
        <li><code>GET</code> – retrieve resources</li>
        <li><code>POST</code> – create resources or perform actions</li>
        <li><code>PUT</code> – update or upload resources</li>
        <li><code>DELETE</code> – remove resources</li>
      </ul>
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">Step 3: Add Required Headers</h3>
    <p class="text-gray-700 mb-4">
      Required headers often include:
    </p>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li><code>Host</code> – service endpoint host</li>
      <li><code>X-Amz-Date</code> – timestamp in ISO8601 format</li>
      <li><code>Authorization</code> – AWS Signature Version 4</li>
      <li><code>Content-Type</code> – if sending a payload</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">Step 4: Include Request Parameters or Body</h3>
    <p class="text-gray-700 mb-4">
      Parameters vary by service and operation:
    </p>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>S3: query string for object actions or XML body for batch operations</li>
      <li>EC2: <code>Action</code> and <code>Version</code> query parameters, e.g., <code>Action=DescribeInstances&amp;Version=2016-11-15</code></li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">Step 5: Sign the Request</h3>
    <p class="text-gray-700 mb-6">
      All AWS API requests must be signed using Signature Version 4 (SigV4), which involves:
      <ul class="list-disc list-inside text-gray-700 mt-2">
        <li>Creating a canonical request</li>
        <li>Generating a string to sign</li>
        <li>Deriving a signing key using your secret access key</li>
        <li>Adding the <code>Authorization</code> header with the signature</li>
      </ul>
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">Example: Describe EC2 Instances via API</h3>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>GET https://ec2.us-east-1.amazonaws.com/
?Action=DescribeInstances
&amp;Version=2016-11-15
&amp;X-Amz-Date=20250824T120000Z
&amp;Authorization=AWS4-HMAC-SHA256 ...</code></pre>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Key Points</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>Use SDKs or CLI to automatically construct and sign requests.</li>
        <li>Ensure you use the correct region-specific endpoint.</li>
        <li>Always follow the principle of least privilege when generating credentials.</li>
        <li>Check API documentation for required parameters for each action.</li>
      </ul>
    </div>
  </div>
</section>




<section id="aws-api-http-methods" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      Common HTTP Methods Used in AWS APIs
    </h2>

    <p class="text-gray-700 mb-6">
      AWS APIs use standard HTTP methods to perform actions on resources. Understanding these methods is essential for constructing requests correctly.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. GET</h3>
    <p class="text-gray-700 mb-4">
      Retrieves information about a resource without modifying it.
    </p>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Examples: <code>GET /mybucket/myobject</code> (S3), <code>DescribeInstances</code> (EC2)</li>
      <li>Safe and idempotent – does not change server state.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. POST</h3>
    <p class="text-gray-700 mb-4">
      Creates a new resource or triggers an action on the server.
    </p>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Examples: <code>POST /mybucket</code> (create S3 bucket), <code>RunInstances</code> (EC2)</li>
      <li>May not be idempotent – repeated calls could create multiple resources.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. PUT</h3>
    <p class="text-gray-700 mb-4">
      Updates or replaces an existing resource with new data.
    </p>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Examples: <code>PUT /mybucket/myobject</code> (upload S3 object)</li>
      <li>Idempotent – sending the same data multiple times has the same effect as sending it once.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">4. DELETE</h3>
    <p class="text-gray-700 mb-4">
      Removes a resource from AWS.
    </p>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Examples: <code>DELETE /mybucket/myobject</code> (S3 object), <code>TerminateInstances</code> (EC2)</li>
      <li>Idempotent – deleting an already-deleted resource does not cause an error.</li>
    </ul>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Key Takeaways</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>GET is for retrieving data, POST for creating, PUT for updating, and DELETE for removing resources.</li>
        <li>Understanding idempotency helps prevent unintended effects when retrying requests.</li>
        <li>These methods are consistent across most AWS services, but always check service-specific documentation.</li>
      </ul>
    </div>
  </div>
</section>




<section id="aws-api-query-headers" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      How to Include Query Parameters and Request Headers in AWS API Calls
    </h2>

    <p class="text-gray-700 mb-6">
      When making AWS API requests, query parameters and request headers provide additional information to control the action, filter results, and authenticate the request.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Query Parameters</h3>
    <p class="text-gray-700 mb-4">
      Query parameters are appended to the URL in GET or POST requests to specify actions or filters.
    </p>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Format: <code>?key1=value1&amp;key2=value2</code></li>
      <li>Used extensively in <strong>Query APIs</strong>, e.g., EC2:</li>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-4"><code>https://ec2.us-east-1.amazonaws.com/?Action=DescribeInstances&amp;Version=2016-11-15</code></pre>
      <li>For S3 REST API, query parameters can specify actions like <code>?uploads</code> for initiating multipart uploads.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. Request Headers</h3>
    <p class="text-gray-700 mb-4">
      Headers provide metadata, authentication info, or control instructions for AWS services.
    </p>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li><strong>Host:</strong> Specifies the service endpoint.</li>
      <li><strong>X-Amz-Date:</strong> Timestamp for request signing.</li>
      <li><strong>Authorization:</strong> SigV4 signature containing access key and signature.</li>
      <li><strong>Content-Type:</strong> Indicates request payload type, e.g., <code>application/json</code> or <code>application/xml</code>.</li>
      <li>Additional service-specific headers like <code>x-amz-storage-class</code> for S3 object uploads.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">Example: S3 GET Object with Query and Headers</h3>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>GET /mybucket/myobject?versionId=abcd1234 HTTP/1.1
Host: mybucket.s3.us-east-1.amazonaws.com
X-Amz-Date: 20250824T120000Z
Authorization: AWS4-HMAC-SHA256 Credential=AKIA.../20250824/us-east-1/s3/aws4_request, SignedHeaders=host;x-amz-date, Signature=...</code></pre>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Best Practices</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>Always sign headers required by SigV4; missing headers will cause authentication errors.</li>
        <li>Use query parameters to filter results or control API behavior without altering headers.</li>
        <li>SDKs automatically manage headers and query parameters for most services, reducing manual errors.</li>
        <li>Validate endpoint, parameters, and headers with service documentation before making requests.</li>
      </ul>
    </div>
  </div>
</section>



<section id="aws-api-parse-response" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      How to Parse the Response from AWS API Calls (JSON/XML)
    </h2>

    <p class="text-gray-700 mb-6">
      AWS API responses are usually returned in <strong>JSON</strong> or <strong>XML</strong> format. Proper parsing is essential to extract the required data for your application.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. JSON Responses</h3>
    <p class="text-gray-700 mb-4">
      Many AWS services like DynamoDB, Lambda, and S3 (when using SDKs or REST API with JSON format) return responses in JSON.
    </p>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>JSON responses can be parsed using standard JSON libraries in your programming language (e.g., <code>json</code> in Python, <code>Jackson</code> in Java, <code>JSON.parse()</code> in JavaScript).</li>
      <li>Example (Python boto3 S3 list objects):</li>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-4"><code>import boto3

s3 = boto3.client('s3')
response = s3.list_objects_v2(Bucket='mybucket')
for obj in response['Contents']:
    print(obj['Key'])</code></pre>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. XML Responses</h3>
    <p class="text-gray-700 mb-4">
      Some AWS services, like older EC2 Query APIs or S3 REST API, return XML responses.
    </p>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>XML can be parsed using libraries like <code>ElementTree</code> in Python, <code>javax.xml</code> in Java, or <code>xml2js</code> in Node.js.</li>
      <li>Example (Python parsing S3 XML response):</li>
      <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-4"><code>import xml.etree.ElementTree as ET
import requests

url = 'https://mybucket.s3.amazonaws.com/?list-type=2'
r = requests.get(url)
root = ET.fromstring(r.content)
for contents in root.findall('{http://s3.amazonaws.com/doc/2006-03-01/}Contents'):
    key = contents.find('{http://s3.amazonaws.com/doc/2006-03-01/}Key').text
    print(key)</code></pre>
    </ul>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Best Practices</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>Always check the <code>Content-Type</code> header to determine the response format.</li>
        <li>Use SDKs whenever possible, as they automatically parse JSON/XML responses into native data structures.</li>
        <li>Handle errors gracefully; AWS APIs return error codes and messages in the response body.</li>
        <li>Validate the parsed data to ensure it matches expected structures, especially when iterating over large datasets.</li>
      </ul>
    </div>
  </div>
</section>



<section id="aws-s3-list-buckets" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      How to List All Buckets Using AWS S3 REST API
    </h2>

    <p class="text-gray-700 mb-6">
      You can retrieve a list of all S3 buckets in your account using the <strong>ListBuckets</strong> operation of the S3 REST API. This requires proper authentication using AWS Signature Version 4 (SigV4).
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Endpoint</h3>
    <p class="text-gray-700 mb-6">
      The endpoint for listing buckets is the global S3 endpoint:
      <br>
      <code>https://s3.amazonaws.com/</code>
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. HTTP Method</h3>
    <p class="text-gray-700 mb-6">
      Use the <strong>GET</strong> method without any query parameters:
      <br>
      <code>GET https://s3.amazonaws.com/</code>
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. Required Headers</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li><code>Host</code>: <code>s3.amazonaws.com</code></li>
      <li><code>X-Amz-Date</code>: Timestamp in ISO8601 format</li>
      <li><code>Authorization</code>: SigV4 signed header</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">4. Example Using cURL with Pre-Signed URL</h3>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code># Generate pre-signed URL via AWS CLI
aws s3 presign s3:// --expires-in 60

# Use cURL to list buckets
curl "https://s3.amazonaws.com/?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=...&amp;X-Amz-Signature=..."</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">5. Response</h3>
    <p class="text-gray-700 mb-6">
      The response is an XML document containing all buckets in the account:
    </p>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>&lt;ListAllMyBucketsResult&gt;
  &lt;Owner&gt;
    &lt;ID&gt;owner-id&lt;/ID&gt;
    &lt;DisplayName&gt;owner-name&lt;/DisplayName&gt;
  &lt;/Owner&gt;
  &lt;Buckets&gt;
    &lt;Bucket&gt;
      &lt;Name&gt;bucket1&lt;/Name&gt;
      &lt;CreationDate&gt;2025-08-24T12:00:00.000Z&lt;/CreationDate&gt;
    &lt;/Bucket&gt;
    &lt;Bucket&gt;
      &lt;Name&gt;bucket2&lt;/Name&gt;
      &lt;CreationDate&gt;2025-07-10T08:30:00.000Z&lt;/CreationDate&gt;
    &lt;/Bucket&gt;
  &lt;/Buckets&gt;
&lt;/ListAllMyBucketsResult&gt;</code></pre>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Best Practices</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>Use SDKs or AWS CLI to handle signing automatically instead of manually constructing requests.</li>
        <li>Ensure IAM permissions include <code>s3:ListAllMyBuckets</code> for the user or role.</li>
        <li>Parse the XML response to extract bucket names and creation dates programmatically.</li>
      </ul>
    </div>
  </div>
</section>


<section id="aws-iam-introduction" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      What is AWS IAM and Why It’s Important for Developers
    </h2>

    <p class="text-gray-700 mb-6">
      AWS Identity and Access Management (IAM) is a service that helps you securely control access to AWS resources. It allows developers to manage users, groups, roles, and permissions to ensure that only authorized entities can perform actions in your AWS account.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">Key Components of IAM</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li><strong>Users:</strong> Individual identities that can authenticate and access AWS resources.</li>
      <li><strong>Groups:</strong> Collections of users with shared permissions.</li>
      <li><strong>Roles:</strong> Temporary credentials that can be assumed by users, applications, or AWS services.</li>
      <li><strong>Policies:</strong> JSON documents defining permissions, attached to users, groups, or roles.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">Why IAM is Important for Developers</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Provides <strong>fine-grained access control</strong> to AWS services and resources.</li>
      <li>Enables <strong>least privilege principle</strong> – users or applications only get permissions they need.</li>
      <li>Supports <strong>temporary credentials</strong> for applications running on EC2, Lambda, or other AWS services, eliminating hard-coded access keys.</li>
      <li>Enhances <strong>security and compliance</strong> by centralizing identity and access management.</li>
      <li>Facilitates <strong>cross-account access</strong> and federated authentication for enterprise applications.</li>
    </ul>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Best Practices for Developers</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>Never hardcode AWS access keys; use IAM roles for applications.</li>
        <li>Grant the minimum required permissions to each user or role.</li>
        <li>Enable multi-factor authentication (MFA) for sensitive operations.</li>
        <li>Regularly review and audit IAM policies and access logs via CloudTrail.</li>
      </ul>
    </div>
  </div>
</section>



<section id="aws-s3-create-bucket" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      How to Create a New S3 Bucket via AWS API
    </h2>

    <p class="text-gray-700 mb-6">
      You can create an Amazon S3 bucket programmatically using the S3 REST API. This requires sending a properly authenticated <code>PUT</code> request to the S3 endpoint with the desired bucket name.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Endpoint</h3>
    <p class="text-gray-700 mb-6">
      For region-specific bucket creation, the endpoint is:
      <br>
      <code>https://s3.&lt;region&gt;.amazonaws.com/&lt;bucket-name&gt;</code>
      <br>
      Example: <code>https://s3.us-east-1.amazonaws.com/my-new-bucket</code>
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. HTTP Method</h3>
    <p class="text-gray-700 mb-6">
      Use the <strong>PUT</strong> method to create a bucket.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. Required Headers</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li><code>Host</code>: service endpoint</li>
      <li><code>X-Amz-Date</code>: timestamp in ISO8601 format</li>
      <li><code>Authorization</code>: AWS Signature Version 4 (SigV4)</li>
      <li><code>Content-Length</code>: 0 (if no body)</li>
      <li>Optional: <code>x-amz-acl</code> to set access control (e.g., private, public-read)</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">4. Optional Request Body</h3>
    <p class="text-gray-700 mb-6">
      To create a bucket in a specific region, include an XML body specifying the location constraint:
    </p>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>&lt;CreateBucketConfiguration xmlns="http://s3.amazonaws.com/doc/2006-03-01/"&gt;
    &lt;LocationConstraint&gt;us-west-2&lt;/LocationConstraint&gt;
&lt;/CreateBucketConfiguration&gt;</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">5. Example: cURL Request</h3>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>curl -X PUT "https://s3.us-west-2.amazonaws.com/my-new-bucket" \
-H "Host: my-new-bucket.s3.us-west-2.amazonaws.com" \
-H "X-Amz-Date: 20250824T120000Z" \
-H "Authorization: AWS4-HMAC-SHA256 Credential=AKIA.../20250824/us-west-2/s3/aws4_request, SignedHeaders=host;x-amz-date, Signature=..." \
-H "Content-Type: application/xml" \
-d '&lt;CreateBucketConfiguration xmlns="http://s3.amazonaws.com/doc/2006-03-01/"&gt;&lt;LocationConstraint&gt;us-west-2&lt;/LocationConstraint&gt;&lt;/CreateBucketConfiguration&gt;'</code></pre>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Best Practices</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>Ensure the bucket name is globally unique.</li>
        <li>Use IAM roles or temporary credentials instead of hard-coded access keys.</li>
        <li>Set appropriate ACLs or bucket policies to control access.</li>
        <li>Always specify the region to avoid unexpected location defaults.</li>
      </ul>
    </div>
  </div>
</section>



<section id="aws-s3-object-api" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      How to Upload, Download, and Delete Objects Using AWS S3 API
    </h2>

    <p class="text-gray-700 mb-6">
      Amazon S3 allows you to manage objects programmatically using REST API requests. The key operations are <strong>PUT</strong> (upload), <strong>GET</strong> (download), and <strong>DELETE</strong> (remove objects).
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Upload an Object (PUT)</h3>
    <p class="text-gray-700 mb-4">
      To upload a file, send a <code>PUT</code> request to the bucket with the object key.
    </p>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>PUT /myobject.txt HTTP/1.1
Host: mybucket.s3.amazonaws.com
Content-Length: 1024
X-Amz-Date: 20250824T120000Z
Authorization: AWS4-HMAC-SHA256 ...
[Body with file data]</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. Download an Object (GET)</h3>
    <p class="text-gray-700 mb-4">
      To retrieve an object, send a <code>GET</code> request with the bucket and object key.
    </p>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>GET /myobject.txt HTTP/1.1
Host: mybucket.s3.amazonaws.com
X-Amz-Date: 20250824T120000Z
Authorization: AWS4-HMAC-SHA256 ...</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. Delete an Object (DELETE)</h3>
    <p class="text-gray-700 mb-4">
      To remove an object, send a <code>DELETE</code> request with the object key.
    </p>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>DELETE /myobject.txt HTTP/1.1
Host: mybucket.s3.amazonaws.com
X-Amz-Date: 20250824T120000Z
Authorization: AWS4-HMAC-SHA256 ...</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">4. Notes & Best Practices</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Always sign your requests using AWS Signature Version 4 for authentication.</li>
      <li>For large objects (>5 GB), use multipart upload to improve reliability and speed.</li>
      <li>Use proper <code>Content-Type</code> headers for file uploads.</li>
      <li>Consider using pre-signed URLs to securely allow temporary access to objects.</li>
      <li>SDKs handle signing, retries, and errors automatically, reducing manual work.</li>
    </ul>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Summary</h3>
      <p class="text-gray-700">
        Using <code>PUT</code>, <code>GET</code>, and <code>DELETE</code> requests, you can fully manage objects in S3 via API. Always authenticate, handle errors, and optimize large file uploads for best performance.
      </p>
    </div>
  </div>
</section>



<section id="aws-s3-presigned-url-api" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      How to Generate a Pre-Signed URL Using AWS S3 API
    </h2>

    <p class="text-gray-700 mb-6">
      A pre-signed URL allows temporary, secure access to an S3 object without sharing AWS credentials. It is valid for a specified duration and can be generated via the S3 API.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Purpose</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Grant temporary access to download or upload objects.</li>
      <li>Useful for sharing objects securely with clients or third-party applications.</li>
      <li>Expires automatically after the defined duration.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. Required Parameters</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li><strong>Bucket Name</strong> – The S3 bucket containing the object.</li>
      <li><strong>Object Key</strong> – The name of the object.</li>
      <li><strong>HTTP Method</strong> – Either <code>GET</code> (download) or <code>PUT</code> (upload).</li>
      <li><strong>Expiration</strong> – Time in seconds until the URL expires.</li>
      <li><strong>Authentication</strong> – Use AWS Signature Version 4 (access key + secret key).</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. Example: cURL Using Pre-Signed URL</h3>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code># Generate pre-signed URL (via SDK or manually signing)
curl "https://mybucket.s3.amazonaws.com/myobject.txt?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIA...&amp;X-Amz-Signature=...&amp;X-Amz-Expires=3600" -O</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">4. Generating Pre-Signed URLs Programmatically</h3>
    <p class="text-gray-700 mb-4">
      Although the REST API allows manual signing, it is recommended to use SDKs for easier generation:
    </p>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code># Example: Python boto3
import boto3
s3 = boto3.client('s3')
url = s3.generate_presigned_url('get_object',
                                Params={'Bucket':'mybucket','Key':'myobject.txt'},
                                ExpiresIn=3600)
print(url)</code></pre>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Best Practices</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>Use the shortest expiration time necessary for security.</li>
        <li>Restrict permissions via bucket policies if sharing publicly.</li>
        <li>Prefer SDKs over manual signing to reduce complexity and avoid errors.</li>
        <li>Pre-signed URLs are ideal for temporary access to private objects without exposing AWS credentials.</li>
      </ul>
    </div>
  </div>
</section>



<section id="aws-ec2-describe-instances" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      How to Describe EC2 Instances Using AWS API Calls
    </h2>

    <p class="text-gray-700 mb-6">
      The <strong>DescribeInstances</strong> API call in EC2 lets you retrieve detailed information about one or more EC2 instances, including state, type, tags, and networking information.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Endpoint</h3>
    <p class="text-gray-700 mb-6">
      Each AWS region has a specific EC2 endpoint:
      <br>
      <code>https://ec2.&lt;region&gt;.amazonaws.com/</code>
      <br>
      Example: <code>https://ec2.us-east-1.amazonaws.com/</code>
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. HTTP Method</h3>
    <p class="text-gray-700 mb-6">
      Use the <strong>POST</strong> or <strong>GET</strong> method to call the API.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. Required Parameters</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li><code>Action=DescribeInstances</code></li>
      <li><code>Version=2016-11-15</code> (EC2 API version)</li>
      <li>Optional filters: <code>InstanceIds</code>, <code>Filters</code> to narrow down results.</li>
      <li>Authentication using <strong>AWS Signature Version 4</strong>.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">4. Example: cURL Request</h3>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>curl -X POST "https://ec2.us-east-1.amazonaws.com/" \
-H "Content-Type: application/x-www-form-urlencoded; charset=utf-8" \
-d "Action=DescribeInstances&amp;Version=2016-11-15&amp;InstanceIds.1=i-0123456789abcdef0" \
-H "X-Amz-Date: 20250824T120000Z" \
-H "Authorization: AWS4-HMAC-SHA256 ..."</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">5. Response</h3>
    <p class="text-gray-700 mb-6">
      The response is in XML format and includes information about each instance, such as:
    </p>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Instance ID and state (running, stopped, etc.)</li>
      <li>Instance type and launch time</li>
      <li>Public and private IP addresses</li>
      <li>Associated security groups and tags</li>
    </ul>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Best Practices</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>Use SDKs (e.g., boto3, AWS SDK for JavaScript) to automatically handle signing and response parsing.</li>
        <li>Apply filters or specify instance IDs to reduce large responses.</li>
        <li>Handle pagination if your account has many instances.</li>
        <li>Log <code>RequestId</code> for debugging and AWS support.</li>
      </ul>
    </div>
  </div>
</section>



<section id="aws-ec2-control-api" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      How to Start, Stop, or Terminate an EC2 Instance via API
    </h2>

    <p class="text-gray-700 mb-6">
      AWS EC2 provides API actions to manage the lifecycle of instances: <strong>StartInstances</strong>, <strong>StopInstances</strong>, and <strong>TerminateInstances</strong>. These operations require proper authentication using AWS Signature Version 4.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Endpoint</h3>
    <p class="text-gray-700 mb-6">
      Each AWS region has its own EC2 endpoint:
      <br>
      <code>https://ec2.&lt;region&gt;.amazonaws.com/</code>
      <br>
      Example: <code>https://ec2.us-east-1.amazonaws.com/</code>
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. HTTP Method</h3>
    <p class="text-gray-700 mb-6">
      Use <strong>POST</strong> or <strong>GET</strong> for the API request.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. Required Parameters</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li><code>Action</code>: <code>StartInstances</code>, <code>StopInstances</code>, or <code>TerminateInstances</code></li>
      <li><code>Version</code>: API version, e.g., <code>2016-11-15</code></li>
      <li><code>InstanceIds.N</code>: One or more instance IDs to manage (e.g., <code>i-0123456789abcdef0</code>)</li>
      <li>Authentication via AWS Signature Version 4</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">4. Example: cURL Requests</h3>

    <p class="text-gray-700 mb-2"><strong>Start an Instance:</strong></p>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>curl -X POST "https://ec2.us-east-1.amazonaws.com/" \
-H "Content-Type: application/x-www-form-urlencoded; charset=utf-8" \
-d "Action=StartInstances&amp;Version=2016-11-15&amp;InstanceIds.1=i-0123456789abcdef0" \
-H "X-Amz-Date: 20250824T120000Z" \
-H "Authorization: AWS4-HMAC-SHA256 ..."</code></pre>

    <p class="text-gray-700 mb-2"><strong>Stop an Instance:</strong></p>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>curl -X POST "https://ec2.us-east-1.amazonaws.com/" \
-d "Action=StopInstances&amp;Version=2016-11-15&amp;InstanceIds.1=i-0123456789abcdef0" \
-H "X-Amz-Date: 20250824T120000Z" \
-H "Authorization: AWS4-HMAC-SHA256 ..."</code></pre>

    <p class="text-gray-700 mb-2"><strong>Terminate an Instance:</strong></p>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>curl -X POST "https://ec2.us-east-1.amazonaws.com/" \
-d "Action=TerminateInstances&amp;Version=2016-11-15&amp;InstanceIds.1=i-0123456789abcdef0" \
-H "X-Amz-Date: 20250824T120000Z" \
-H "Authorization: AWS4-HMAC-SHA256 ..."</code></pre>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Best Practices</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>Use SDKs to handle request signing and response parsing automatically.</li>
        <li>Verify IAM permissions: <code>ec2:StartInstances</code>, <code>ec2:StopInstances</code>, <code>ec2:TerminateInstances</code>.</li>
        <li>Always confirm instance IDs to avoid affecting unintended instances.</li>
        <li>Use tags and filters to manage multiple instances efficiently.</li>
      </ul>
    </div>
  </div>
</section>




<section id="aws-ec2-pagination" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      How to Handle Paginated Responses for EC2 Describe Calls
    </h2>

    <p class="text-gray-700 mb-6">
      When you have many EC2 instances or resources, AWS API responses may be paginated. The <strong>NextToken</strong> parameter is used to retrieve subsequent pages of results.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Understanding Pagination</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>A single <code>DescribeInstances</code> call may return only a subset of all instances.</li>
      <li>If there are more results, the response includes a <code>NextToken</code> value.</li>
      <li>To fetch the next page, include <code>NextToken</code> in the next request.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. Example: cURL Request with Pagination</h3>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code># First request
curl -X POST "https://ec2.us-east-1.amazonaws.com/" \
-d "Action=DescribeInstances&amp;Version=2016-11-15" \
-H "X-Amz-Date: 20250824T120000Z" \
-H "Authorization: AWS4-HMAC-SHA256 ..."

# Response contains NextToken if more pages exist
# Use NextToken in next request
curl -X POST "https://ec2.us-east-1.amazonaws.com/" \
-d "Action=DescribeInstances&amp;Version=2016-11-15&amp;NextToken=abc123" \
-H "X-Amz-Date: 20250824T120500Z" \
-H "Authorization: AWS4-HMAC-SHA256 ..."</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. Programmatic Handling with SDKs</h3>
    <p class="text-gray-700 mb-6">
      SDKs provide built-in pagination helpers. Example in Python using boto3:
    </p>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>import boto3

ec2 = boto3.client('ec2')
paginator = ec2.get_paginator('describe_instances')

for page in paginator.paginate():
    for reservation in page['Reservations']:
        for instance in reservation['Instances']:
            print(instance['InstanceId'], instance['State']['Name'])</code></pre>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Best Practices</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>Always check for <code>NextToken</code> in API responses to ensure complete data retrieval.</li>
        <li>Use SDK pagination helpers whenever possible to simplify code.</li>
        <li>Handle rate limits gracefully when iterating through many pages.</li>
        <li>Filter results to reduce the number of pages and improve efficiency.</li>
      </ul>
    </div>
  </div>
</section>




<section id="aws-iam-create-user" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      How to Create a New IAM User Programmatically
    </h2>

    <p class="text-gray-700 mb-6">
      AWS Identity and Access Management (IAM) allows you to create users programmatically using the <strong>CreateUser</strong> API action. This enables automated user provisioning without using the AWS Management Console.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Endpoint</h3>
    <p class="text-gray-700 mb-6">
      IAM is a global service; the endpoint is:
      <br>
      <code>https://iam.amazonaws.com/</code>
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. HTTP Method</h3>
    <p class="text-gray-700 mb-6">
      Use <strong>POST</strong> or <strong>GET</strong> for the API request.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. Required Parameters</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li><code>Action=CreateUser</code></li>
      <li><code>UserName</code>: The name of the new IAM user.</li>
      <li><code>Path</code> (optional): A path for grouping users.</li>
      <li>Authentication using <strong>AWS Signature Version 4</strong>.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">4. Example: cURL Request</h3>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>curl -X POST "https://iam.amazonaws.com/" \
-d "Action=CreateUser&amp;UserName=new-developer&amp;Version=2010-05-08" \
-H "X-Amz-Date: 20250824T120000Z" \
-H "Authorization: AWS4-HMAC-SHA256 ..."</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">5. Programmatic Creation Using SDK</h3>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code># Example: Python boto3
import boto3
iam = boto3.client('iam')

response = iam.create_user(
    UserName='new-developer',
    Path='/developers/'
)
print(response['User']['UserName'], response['User']['Arn'])</code></pre>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Best Practices</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>Always follow the principle of least privilege; attach only necessary policies.</li>
        <li>Consider using IAM roles for applications instead of long-term user credentials.</li>
        <li>Enable multi-factor authentication (MFA) for sensitive users.</li>
        <li>Use SDKs to simplify request signing, error handling, and parsing responses.</li>
      </ul>
    </div>
  </div>
</section>



<section id="aws-iam-attach-policy-api" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      How to Attach a Policy to an IAM User via API
    </h2>

    <p class="text-gray-700 mb-6">
      To grant permissions to an IAM user programmatically, you can attach a managed policy using the <strong>AttachUserPolicy</strong> API action. This links the policy to the user without modifying the policy itself.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Endpoint</h3>
    <p class="text-gray-700 mb-6">
      IAM is a global service; the endpoint is:
      <br>
      <code>https://iam.amazonaws.com/</code>
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. HTTP Method</h3>
    <p class="text-gray-700 mb-6">
      Use <strong>POST</strong> or <strong>GET</strong> for the API request.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. Required Parameters</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li><code>Action=AttachUserPolicy</code></li>
      <li><code>UserName</code>: Name of the IAM user.</li>
      <li><code>PolicyArn</code>: Amazon Resource Name (ARN) of the policy to attach.</li>
      <li>Authentication via <strong>AWS Signature Version 4</strong>.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">4. Example: cURL Request</h3>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>curl -X POST "https://iam.amazonaws.com/" \
-d "Action=AttachUserPolicy&amp;UserName=new-developer&amp;PolicyArn=arn:aws:iam::aws:policy/AdministratorAccess&amp;Version=2010-05-08" \
-H "X-Amz-Date: 20250824T120000Z" \
-H "Authorization: AWS4-HMAC-SHA256 ..."</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">5. Programmatic Example Using SDK</h3>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code># Python boto3 example
import boto3
iam = boto3.client('iam')

iam.attach_user_policy(
    UserName='new-developer',
    PolicyArn='arn:aws:iam::aws:policy/AdministratorAccess'
)
print("Policy attached successfully")</code></pre>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Best Practices</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>Prefer attaching least-privilege policies instead of broad ones like AdministratorAccess.</li>
        <li>Use IAM groups where possible to manage multiple users efficiently.</li>
        <li>Enable MFA and monitor policy changes for security auditing.</li>
        <li>SDKs simplify signing and error handling compared to manual API calls.</li>
      </ul>
    </div>
  </div>
</section>


<section id="aws-lambda-deploy" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      How to Deploy Code to AWS Lambda
    </h2>

    <p class="text-gray-700 mb-6">
      AWS Lambda allows you to run code without provisioning servers. Deploying code can be done via the AWS Management Console, CLI, SDKs, or infrastructure-as-code tools. Lambda supports multiple languages, including Python, Node.js, Java, Go, and more.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Deployment Methods</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li><strong>Console Upload:</strong> Directly upload a .zip file or use the inline code editor for small functions.</li>
      <li><strong>AWS CLI:</strong> Use <code>aws lambda create-function</code> or <code>update-function-code</code>.</li>
      <li><strong>SDKs:</strong> Programmatically deploy code using SDK methods.</li>
      <li><strong>Infrastructure as Code:</strong> Use CloudFormation, Terraform, or AWS SAM for automated deployments.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. Example: Deploy Using AWS CLI</h3>
    <p class="text-gray-700 mb-4">Create a Lambda function:</p>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>aws lambda create-function \
--function-name MyLambdaFunction \
--runtime python3.11 \
--role arn:aws:iam::123456789012:role/lambda-execution-role \
--handler lambda_function.lambda_handler \
--zip-file fileb://function.zip</code></pre>

    <p class="text-gray-700 mb-4">Update function code:</p>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>aws lambda update-function-code \
--function-name MyLambdaFunction \
--zip-file fileb://function.zip</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. Best Practices</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Use versioning and aliases to manage deployments and rollbacks safely.</li>
      <li>Keep the deployment package small for faster uploads and cold starts.</li>
      <li>Use environment variables to avoid hardcoding configuration.</li>
      <li>Leverage CI/CD pipelines for automated Lambda deployments.</li>
      <li>Monitor function execution and performance using CloudWatch metrics and logs.</li>
    </ul>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Summary</h3>
      <p class="text-gray-700">
        Deploying code to Lambda can be achieved through multiple methods, including the console, CLI, SDKs, and IaC tools. Following best practices like versioning, monitoring, and CI/CD ensures reliable and maintainable serverless applications.
      </p>
    </div>
  </div>
</section>



<section id="aws-lambda-env-vars" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      How to Handle Environment Variables in AWS Lambda
    </h2>

    <p class="text-gray-700 mb-6">
      Environment variables in Lambda allow you to configure your function without hardcoding sensitive information or configuration values. They can be used to store database connection strings, API keys, feature flags, or runtime settings.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Setting Environment Variables</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li><strong>Console:</strong> Add key-value pairs under the "Configuration → Environment variables" section.</li>
      <li><strong>AWS CLI:</strong> Use the <code>--environment</code> parameter when creating or updating a function.</li>
      <li><strong>SDKs:</strong> Specify environment variables programmatically via the <code>Environment</code> parameter.</li>
      <li><strong>IaC tools:</strong> Define environment variables in CloudFormation, Terraform, or SAM templates.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. Example: Using AWS CLI</h3>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code># Create a Lambda function with environment variables
aws lambda create-function \
--function-name MyLambdaFunction \
--runtime python3.11 \
--role arn:aws:iam::123456789012:role/lambda-execution-role \
--handler lambda_function.lambda_handler \
--zip-file fileb://function.zip \
--environment Variables="{DB_HOST=database.example.com,DB_USER=admin}"</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. Accessing Environment Variables in Code</h3>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code># Python example
import os

db_host = os.environ.get('DB_HOST')
db_user = os.environ.get('DB_USER')</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">4. Security Best Practices</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Use <strong>AWS KMS encryption</strong> to encrypt sensitive environment variables.</li>
      <li>Never hardcode secrets in the code; store them as encrypted environment variables or use AWS Secrets Manager.</li>
      <li>Restrict IAM permissions for Lambda to only access necessary KMS keys.</li>
      <li>Use environment variables for configuration rather than dynamic code changes for easier deployment.</li>
    </ul>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Summary</h3>
      <p class="text-gray-700">
        Environment variables provide a secure and flexible way to configure Lambda functions. Leveraging encrypted variables and best practices ensures sensitive data remains protected while keeping functions configurable.
      </p>
    </div>
  </div>
</section>



<section id="lambda-vs-ec2" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      Difference Between AWS Lambda and EC2 for Running Applications
    </h2>

    <p class="text-gray-700 mb-6">
      AWS Lambda and EC2 are two different ways to run applications in the cloud. Choosing between them depends on the workload, scalability needs, and operational preferences.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Compute Model</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li><strong>EC2:</strong> Virtual servers in the cloud. You manage the OS, runtime, and scaling.</li>
      <li><strong>Lambda:</strong> Serverless compute. AWS manages the infrastructure, scaling, and execution.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. Scaling</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li><strong>EC2:</strong> Manual or auto-scaling groups for handling traffic.</li>
      <li><strong>Lambda:</strong> Automatic scaling per request, up to concurrency limits.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. Billing</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li><strong>EC2:</strong> Pay for uptime (hourly or per-second billing).</li>
      <li><strong>Lambda:</strong> Pay per execution and duration (milliseconds), cost-effective for intermittent workloads.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">4. Operational Management</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li><strong>EC2:</strong> Full control over OS, patches, networking, and software stack.</li>
      <li><strong>Lambda:</strong> Minimal operational overhead; AWS handles runtime management.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">5. Use Cases</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li><strong>EC2:</strong> Long-running applications, custom environments, legacy applications, full OS access.</li>
      <li><strong>Lambda:</strong> Event-driven applications, microservices, real-time file processing, serverless APIs.</li>
    </ul>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Summary</h3>
      <p class="text-gray-700">
        EC2 provides full server control and flexibility, suitable for traditional workloads. Lambda offers a serverless model, ideal for event-driven, scalable, and low-maintenance applications. The choice depends on your application's runtime, control needs, and cost considerations.
      </p>
    </div>
  </div>
</section>



<section id="aws-lambda-triggers" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      How to Trigger AWS Lambda Functions
    </h2>

    <p class="text-gray-700 mb-6">
      AWS Lambda functions can be invoked automatically in response to various events from AWS services. Triggers enable event-driven architectures and reduce the need for manual invocation.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. S3 Bucket Events</h3>
    <p class="text-gray-700 mb-6">
      Lambda can be triggered when objects are created, deleted, or modified in S3 buckets.
    </p>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Example: Process uploaded CSV files automatically.</li>
      <li>Setup: Add S3 event notification and select the Lambda function as the target.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. API Gateway</h3>
    <p class="text-gray-700 mb-6">
      Lambda can handle HTTP requests via REST or WebSocket APIs using API Gateway.
    </p>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Example: Serverless APIs or microservices.</li>
      <li>Setup: Configure an API method to invoke the Lambda function.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. CloudWatch Events / EventBridge</h3>
    <p class="text-gray-700 mb-6">
      Lambda can be triggered on a schedule (cron jobs) or in response to specific system events.
    </p>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Example: Automated backups or system health checks.</li>
      <li>Setup: Create a CloudWatch Event rule with Lambda as the target.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">4. DynamoDB Streams</h3>
    <p class="text-gray-700 mb-6">
      Lambda can process real-time changes in DynamoDB tables using streams.
    </p>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Example: Update a search index whenever a DynamoDB table changes.</li>
      <li>Setup: Enable DynamoDB Streams and attach the Lambda function as the event processor.</li>
    </ul>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Summary</h3>
      <p class="text-gray-700">
        AWS Lambda supports multiple triggers across services like S3, API Gateway, CloudWatch, and DynamoDB Streams, enabling event-driven, serverless applications. Choosing the right trigger depends on the type of event your application needs to respond to.
      </p>
    </div>
  </div>
</section>



<section id="aws-lambda-dependencies" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      How to Package Dependencies for an AWS Lambda Function
    </h2>

    <p class="text-gray-700 mb-6">
      Lambda functions often require external libraries or dependencies. Packaging them correctly ensures the function runs without errors in the AWS Lambda execution environment.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Using a Deployment Package (ZIP)</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Include your code files and all dependencies in a single ZIP file.</li>
      <li>Python example:
        <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto my-2"><code>mkdir package
pip install requests -t package/
cp lambda_function.py package/
cd package
zip -r ../function.zip .</code></pre>
      </li>
      <li>Upload <code>function.zip</code> to Lambda via Console, CLI, or SDK.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. Using Lambda Layers</h3>
    <p class="text-gray-700 mb-6">
      Lambda Layers allow you to separate dependencies from your function code and reuse them across multiple functions.
    </p>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Create a layer ZIP with dependencies structured correctly (e.g., <code>python/lib/python3.11/site-packages/</code> for Python).</li>
      <li>Publish the layer and attach it to your Lambda function.</li>
      <li>Reduces deployment size and allows centralized management of shared libraries.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. Using Container Images</h3>
    <p class="text-gray-700 mb-6">
      For functions with large dependencies or custom runtimes, you can package your Lambda function as a Docker container image up to 10 GB.
    </p>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Write a Dockerfile with your code and dependencies.</li>
      <li>Build and push the image to Amazon ECR (Elastic Container Registry).</li>
      <li>Create a Lambda function using the container image as the deployment package.</li>
    </ul>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Best Practices</h3>
      <ul class="list-disc list-inside text-gray-700 space-y-1">
        <li>Keep deployment packages small to reduce cold start times.</li>
        <li>Use Lambda Layers for shared dependencies across multiple functions.</li>
        <li>Prefer container images for complex environments or large dependencies.</li>
        <li>Test the packaged function locally in a Lambda-like environment to ensure all dependencies are included.</li>
      </ul>
    </div>
  </div>
</section>



<section id="s3-multipart-upload" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      How to Handle Large File Uploads to S3 in Chunks (Multipart Upload)
    </h2>

    <p class="text-gray-700 mb-6">
      For large files (typically >5 GB), Amazon S3 supports <strong>multipart uploads</strong>. This allows you to upload a single object as multiple parts, improving reliability, parallelism, and resumability.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Steps in Multipart Upload</h3>
    <ol class="list-decimal list-inside text-gray-700 mb-6 space-y-2">
      <li><strong>Initiate Upload:</strong> Start a multipart upload and get an <code>UploadId</code>.</li>
      <li><strong>Upload Parts:</strong> Upload each part (between 5 MB and 5 GB) independently. Parts can be uploaded in parallel.</li>
      <li><strong>Complete Upload:</strong> After all parts are uploaded, call <code>CompleteMultipartUpload</code> to combine them into a single object.</li>
      <li><strong>Abort (Optional):</strong> If the upload fails, use <code>AbortMultipartUpload</code> to delete incomplete parts.</li>
    </ol>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. Example: AWS CLI</h3>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code># Initiate multipart upload
aws s3api create-multipart-upload --bucket my-bucket --key large-file.zip

# Upload parts (repeat for each part)
aws s3api upload-part --bucket my-bucket --key large-file.zip --part-number 1 --body part1.zip --upload-id <UploadId>

# Complete the multipart upload
aws s3api complete-multipart-upload --bucket my-bucket --key large-file.zip --upload-id <UploadId> --multipart-upload file://parts.json</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. Example: Using SDK (Python boto3)</h3>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>import boto3
s3 = boto3.client('s3')

# Upload a file using multipart upload
s3.upload_file(
    Filename='large-file.zip',
    Bucket='my-bucket',
    Key='large-file.zip'
)</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">4. Best Practices</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Use multipart upload for files >100 MB; required for >5 GB files.</li>
      <li>Upload parts in parallel to improve throughput.</li>
      <li>Use checksums or ETags to verify data integrity.</li>
      <li>Monitor incomplete uploads and abort them to avoid storage charges.</li>
      <li>Consider using AWS SDKs, as they handle retries and parallel uploads automatically.</li>
    </ul>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Summary</h3>
      <p class="text-gray-700">
        Multipart uploads allow reliable and efficient transfer of large files to S3 by splitting them into manageable parts. Leveraging parallel uploads, retries, and SDKs ensures high performance and fault tolerance.
      </p>
    </div>
  </div>
</section>



<section id="s3-lambda-processing" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      How to Automatically Process Files Uploaded to S3 Using Lambda
    </h2>

    <p class="text-gray-700 mb-6">
      AWS Lambda can be triggered automatically whenever a new object is uploaded to an S3 bucket. This enables real-time processing, such as image resizing, data transformation, or notifications, without manual intervention.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Configure S3 Event Notifications</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Go to the S3 bucket in the AWS Management Console.</li>
      <li>Select <strong>Properties → Event notifications → Create event notification</strong>.</li>
      <li>Specify a prefix or suffix filter (optional) to trigger only for certain files (e.g., <code>.csv</code> or <code>images/</code>).</li>
      <li>Select the Lambda function as the destination.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. Example Lambda Function (Python)</h3>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>import json
import boto3

def lambda_handler(event, context):
    s3 = boto3.client('s3')
    
    for record in event['Records']:
        bucket = record['s3']['bucket']['name']
        key = record['s3']['object']['key']
        
        # Example: Read the uploaded file
        response = s3.get_object(Bucket=bucket, Key=key)
        data = response['Body'].read().decode('utf-8')
        
        print(f"Processed file {key} from bucket {bucket}")</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. Best Practices</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Use filters (prefix/suffix) to trigger only on relevant files.</li>
      <li>Keep Lambda functions lightweight to avoid long execution times and high costs.</li>
      <li>Handle exceptions and retries gracefully; S3 events may trigger multiple times.</li>
      <li>Monitor executions and errors using CloudWatch Logs.</li>
      <li>Consider using SQS or SNS as an intermediate buffer for high-frequency uploads to avoid Lambda throttling.</li>
    </ul>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Summary</h3>
      <p class="text-gray-700">
        By connecting S3 event notifications to Lambda, you can build automated, serverless workflows that process files immediately upon upload. This approach simplifies real-time processing, reduces manual intervention, and scales automatically with the number of uploads.
      </p>
    </div>
  </div>
</section>




<section id="s3-stepfunction-trigger" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      How to Trigger a Step Functions Workflow When a CSV File is Uploaded to S3
    </h2>

    <p class="text-gray-700 mb-6">
      AWS Step Functions allow you to coordinate multiple AWS services into serverless workflows. You can automatically start a workflow whenever a CSV file is uploaded to an S3 bucket using event-driven triggers.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Configure S3 Event Notification</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Go to your S3 bucket in the AWS Management Console.</li>
      <li>Select <strong>Properties → Event notifications → Create event notification</strong>.</li>
      <li>Set a suffix filter for <code>.csv</code> files so the event triggers only for CSV uploads.</li>
      <li>Select <strong>Step Functions</strong> as the destination and choose the workflow ARN.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. Example Step Function Trigger via Lambda</h3>
    <p class="text-gray-700 mb-4">
      If you want more control (e.g., preprocessing the file before starting the workflow), you can trigger Step Functions via a Lambda function:
    </p>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>import json
import boto3

sfn = boto3.client('stepfunctions')

def lambda_handler(event, context):
    for record in event['Records']:
        bucket = record['s3']['bucket']['name']
        key = record['s3']['object']['key']
        
        if key.endswith('.csv'):
            response = sfn.start_execution(
                stateMachineArn='arn:aws:states:region:account-id:stateMachine:MyStateMachine',
                input=json.dumps({"bucket": bucket, "key": key})
            )
            print(f"Started Step Function execution: {response['executionArn']}")</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. Best Practices</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Use suffix filters to trigger workflows only for relevant CSV files.</li>
      <li>Handle errors in Lambda gracefully and enable retries.</li>
      <li>Monitor Step Functions executions via the console or CloudWatch.</li>
      <li>Consider batching multiple CSV uploads before triggering workflows to optimize processing.</li>
      <li>Ensure IAM roles have sufficient permissions for S3 read access and Step Functions execution.</li>
    </ul>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Summary</h3>
      <p class="text-gray-700">
        By configuring S3 event notifications or using a Lambda function, you can automatically trigger Step Functions workflows whenever CSV files are uploaded. This enables automated, serverless, and scalable processing pipelines for data ingestion and transformation.
      </p>
    </div>
  </div>
</section>



<section id="rest-api-apigateway-lambda-dynamodb" class="py-16 bg-gray-50">
  <div class="max-w-7xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      Building a REST API Using API Gateway + Lambda + DynamoDB
    </h2>

    <p class="text-gray-700 mb-6">
      You can build a fully serverless REST API on AWS by integrating API Gateway, Lambda, and DynamoDB. This architecture allows you to handle HTTP requests, process them with Lambda, and store/retrieve data in DynamoDB without managing any servers.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Architecture Overview</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li><strong>API Gateway:</strong> Exposes RESTful endpoints to clients.</li>
      <li><strong>Lambda:</strong> Handles the business logic for each endpoint.</li>
      <li><strong>DynamoDB:</strong> Serves as a NoSQL database for storing and retrieving data.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. Step-by-Step Implementation</h3>

    <h4 class="text-lg font-semibold text-gray-900 mb-2">Step 1: Create a DynamoDB Table</h4>
    <ul class="list-disc list-inside text-gray-700 mb-4">
      <li>Go to DynamoDB → Create Table.</li>
      <li>Define a primary key (e.g., <code>id</code> as string).</li>
      <li>Enable auto-scaling for read/write capacity or use on-demand mode.</li>
    </ul>

    <h4 class="text-lg font-semibold text-gray-900 mb-2">Step 2: Create Lambda Functions</h4>
    <p class="text-gray-700 mb-4">
      Create separate Lambda functions for each CRUD operation (Create, Read, Update, Delete).
    </p>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>import json
import boto3
import uuid

dynamodb = boto3.resource('dynamodb')
table = dynamodb.Table('MyTable')

def lambda_handler(event, context):
    method = event['httpMethod']
    
    if method == 'POST':
        body = json.loads(event['body'])
        item_id = str(uuid.uuid4())
        table.put_item(Item={'id': item_id, **body})
        return {"statusCode": 201, "body": json.dumps({"id": item_id})}
    
    elif method == 'GET':
        item_id = event['queryStringParameters']['id']
        response = table.get_item(Key={'id': item_id})
        return {"statusCode": 200, "body": json.dumps(response.get('Item', {}))}</code></pre>

    <h4 class="text-lg font-semibold text-gray-900 mb-2">Step 3: Create API Gateway REST API</h4>
    <ul class="list-disc list-inside text-gray-700 mb-4">
      <li>Go to API Gateway → Create API → REST API.</li>
      <li>Create resources (e.g., <code>/items</code>) and HTTP methods (GET, POST, PUT, DELETE).</li>
      <li>Integrate each method with the corresponding Lambda function.</li>
      <li>Enable CORS if the API is accessed from a web browser.</li>
    </ul>

    <h4 class="text-lg font-semibold text-gray-900 mb-2">Step 4: Deploy API</h4>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Create a deployment stage (e.g., <code>dev</code> or <code>prod</code>).</li>
      <li>Use the stage URL to test API endpoints with Postman or curl.</li>
    </ul>

    <h4 class="text-lg font-semibold text-gray-900 mb-2">Step 5: Security and Best Practices</h4>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Use IAM roles for Lambda to access DynamoDB securely.</li>
      <li>Enable API keys or Cognito authentication for API Gateway.</li>
      <li>Validate request payloads inside Lambda to prevent injection attacks.</li>
      <li>Enable CloudWatch logging for API Gateway and Lambda for debugging and monitoring.</li>
      <li>Consider using environment variables in Lambda for table names and configuration.</li>
    </ul>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Summary</h3>
      <p class="text-gray-700">
        By combining API Gateway, Lambda, and DynamoDB, you can create a fully serverless REST API that scales automatically, reduces operational overhead, and leverages managed AWS services. This setup is ideal for microservices, mobile backends, and event-driven architectures.
      </p>
    </div>
  </div>
</section>



<section id="lambda-cloudwatch-logging" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      Logging All API Requests and Responses in CloudWatch with Lambda
    </h2>

    <p class="text-gray-700 mb-6">
      AWS Lambda automatically integrates with CloudWatch Logs. You can log all incoming API requests and Lambda responses to monitor, debug, and audit your serverless applications.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Enable CloudWatch Logs</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Ensure your Lambda execution role has <code>AWSLambdaBasicExecutionRole</code> policy attached.</li>
      <li>CloudWatch logging is enabled by default for Lambda functions in the console.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. Logging Incoming Requests</h3>
    <p class="text-gray-700 mb-4">
      Capture the API Gateway event object to log incoming requests:
    </p>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>import json

def lambda_handler(event, context):
    # Log the incoming API request
    print("Received event:", json.dumps(event))
    
    response_body = {"message": "Hello World"}
    
    # Log the response
    print("Response:", json.dumps(response_body))
    
    return {
        "statusCode": 200,
        "body": json.dumps(response_body)
    }</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. Viewing Logs in CloudWatch</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Go to CloudWatch → Logs → Log Groups → <strong>/aws/lambda/YourFunctionName</strong>.</li>
      <li>Each Lambda invocation creates a log stream with timestamps.</li>
      <li>You can filter logs using patterns to analyze specific requests or responses.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">4. Best Practices</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Mask or remove sensitive information (like passwords or API keys) before logging.</li>
      <li>Use structured logging (JSON format) to simplify searching and analysis.</li>
      <li>Set up CloudWatch Metric Filters and Alarms for monitoring error rates.</li>
      <li>Consider using AWS X-Ray for end-to-end tracing of requests across Lambda and other services.</li>
    </ul>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Summary</h3>
      <p class="text-gray-700">
        Logging API requests and Lambda responses to CloudWatch provides observability into your serverless applications. By combining structured logging, proper IAM permissions, and optional tracing with X-Ray, you can monitor, debug, and analyze your APIs effectively.
      </p>
    </div>
  </div>
</section>




<section id="lambda-dynamodb-update" class="py-16 bg-gray-50">
  <div class="max-w-7xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      Updating a DynamoDB Table from Lambda Triggered by API Gateway POST Request
    </h2>

    <p class="text-gray-700 mb-6">
      You can create a serverless workflow where an API Gateway POST request triggers a Lambda function that updates items in a DynamoDB table. This is ideal for creating, modifying, or logging data via REST APIs.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Configure API Gateway POST Method</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Create a REST API in API Gateway.</li>
      <li>Add a resource (e.g., <code>/items</code>) and enable the POST method.</li>
      <li>Integrate the POST method with a Lambda function.</li>
      <li>Enable request validation if needed, including JSON schema for the payload.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. Example Lambda Function (Python)</h3>
    <p class="text-gray-700 mb-4">
      The Lambda function reads the POST request payload and updates or inserts an item in DynamoDB.
    </p>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>import json
import boto3
from boto3.dynamodb.conditions import Key

dynamodb = boto3.resource('dynamodb')
table = dynamodb.Table('MyTable')

def lambda_handler(event, context):
    # Parse incoming POST request body
    body = json.loads(event['body'])
    item_id = body.get('id')
    new_value = body.get('value')
    
    if not item_id or not new_value:
        return {
            "statusCode": 400,
            "body": json.dumps({"error": "Missing 'id' or 'value'"})
        }
    
    # Update item in DynamoDB
    response = table.update_item(
        Key={'id': item_id},
        UpdateExpression='SET #val = :v',
        ExpressionAttributeNames={'#val': 'value'},
        ExpressionAttributeValues={':v': new_value},
        ReturnValues='ALL_NEW'
    )
    
    return {
        "statusCode": 200,
        "body": json.dumps({"updatedItem": response['Attributes']})
    }</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. Best Practices</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Use IAM roles to give Lambda only the necessary permissions to update DynamoDB.</li>
      <li>Validate and sanitize incoming data to avoid injection attacks.</li>
      <li>Enable CloudWatch Logs to monitor Lambda executions and errors.</li>
      <li>Use conditional updates to prevent overwriting data unintentionally.</li>
      <li>Consider throttling or using API Gateway rate limits to prevent excessive writes.</li>
    </ul>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Summary</h3>
      <p class="text-gray-700">
        Integrating API Gateway, Lambda, and DynamoDB allows you to create a serverless REST API where POST requests directly update database records. This setup is scalable, fully managed, and ideal for building dynamic web and mobile applications.
      </p>
    </div>
  </div>
</section>



<section id="lambda-sqs-processing" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      Processing Messages from SQS Using Lambda
    </h2>

    <p class="text-gray-700 mb-6">
      AWS Lambda can be triggered automatically by Amazon SQS to process messages asynchronously. This enables scalable, event-driven architectures where messages are queued and handled reliably.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Configure SQS Queue</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Create a new SQS queue (standard or FIFO) in the AWS Management Console.</li>
      <li>Set visibility timeout and retention period according to your application needs.</li>
      <li>Note the queue ARN to connect it to Lambda.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. Configure Lambda Trigger</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Create a Lambda function with an execution role that has permissions to read from SQS.</li>
      <li>Add the SQS queue as an event source in the Lambda console.</li>
      <li>Set batch size (number of messages per Lambda invocation) for efficient processing.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. Example Lambda Function (Python)</h3>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>import json

def lambda_handler(event, context):
    for record in event['Records']:
        message_body = record['body']
        print(f"Processing message: {message_body}")
        
        # Example: parse JSON message
        try:
            data = json.loads(message_body)
            # Process the message data
            print(f"Processed data: {data}")
        except json.JSONDecodeError:
            print("Invalid JSON message")</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">4. Best Practices</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Set an appropriate batch size to balance throughput and Lambda execution time.</li>
      <li>Enable dead-letter queues (DLQs) for messages that fail processing.</li>
      <li>Handle exceptions and retries gracefully; Lambda automatically retries failed batches.</li>
      <li>Use CloudWatch Logs to monitor processed messages and errors.</li>
      <li>Consider message deduplication if using FIFO queues.</li>
    </ul>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Summary</h3>
      <p class="text-gray-700">
        Connecting SQS with Lambda allows for scalable and reliable message processing. By leveraging event sources, batch processing, and DLQs, you can build fault-tolerant serverless applications that handle high volumes of asynchronous messages.
      </p>
    </div>
  </div>
</section>




<section id="s3-sns-fanout" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      Fan Out S3 Events to Multiple Lambda Functions Using SNS
    </h2>

    <p class="text-gray-700 mb-6">
      You can use Amazon SNS (Simple Notification Service) to fan out events from an S3 bucket to multiple Lambda functions. This allows multiple independent processing workflows to respond to the same S3 event.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Create an SNS Topic</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Go to the SNS console → Create Topic → choose a name.</li>
      <li>Choose a type (Standard recommended for fan-out).</li>
      <li>Note the Topic ARN for S3 configuration.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. Subscribe Lambda Functions to SNS Topic</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Create or identify the Lambda functions you want to trigger.</li>
      <li>Go to SNS → Topic → Subscriptions → Create subscription.</li>
      <li>Set Protocol to <strong>Lambda</strong> and select the Lambda function.</li>
      <li>Repeat for all Lambda functions you want to fan out to.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. Configure S3 Event Notification</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Go to your S3 bucket → Properties → Event notifications → Create event notification.</li>
      <li>Choose the event type (e.g., <code>ObjectCreated:*</code>).</li>
      <li>Set the destination to the SNS topic ARN created earlier.</li>
      <li>Optionally add filters (prefix/suffix) to trigger only for specific files.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">4. Example Lambda Function (Python)</h3>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>import json

def lambda_handler(event, context):
    for record in event['Records']:
        sns_message = json.loads(record['Sns']['Message'])
        bucket = sns_message['Records'][0]['s3']['bucket']['name']
        key = sns_message['Records'][0]['s3']['object']['key']
        print(f"Processing file {key} from bucket {bucket}")</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">5. Best Practices</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Use filters on S3 events to reduce unnecessary Lambda invocations.</li>
      <li>Ensure each Lambda has appropriate IAM permissions for S3 read access.</li>
      <li>Monitor SNS delivery failures and Lambda execution errors via CloudWatch.</li>
      <li>Consider enabling DLQ (Dead Letter Queue) for SNS in case a Lambda fails repeatedly.</li>
      <li>Use JSON structured logging in Lambda for easier troubleshooting.</li>
    </ul>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Summary</h3>
      <p class="text-gray-700">
        By connecting S3 to SNS and subscribing multiple Lambda functions, you can fan out events to multiple processing workflows. This architecture supports scalable, decoupled, and parallel processing of S3 object events.
      </p>
    </div>
  </div>
</section>



<section id="sqs-exactly-once-lambda" class="py-16 bg-gray-50">
  <div class="max-w-6xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      Ensuring Exactly-Once Processing of SQS Messages with Lambda
    </h2>

    <p class="text-gray-700 mb-6">
      AWS Lambda can process messages from SQS queues, but SQS guarantees at-least-once delivery. To achieve exactly-once processing, you need to handle idempotency and message deduplication carefully.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Use FIFO Queues</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Create a FIFO SQS queue (<code>QueueName.fifo</code>).</li>
      <li>FIFO queues preserve message order and support <strong>deduplication IDs</strong> to prevent processing the same message multiple times.</li>
      <li>Enable content-based deduplication if messages have unique content.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. Enable Idempotent Lambda Processing</h3>
    <p class="text-gray-700 mb-4">
      Design your Lambda function to be idempotent so that repeated invocations do not produce side effects:
    </p>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>import json

processed_ids = set()

def lambda_handler(event, context):
    for record in event['Records']:
        message_id = record['messageId']
        
        if message_id in processed_ids:
            print(f"Skipping already processed message {message_id}")
            continue
        
        body = json.loads(record['body'])
        # Process the message safely here
        print(f"Processing: {body}")
        
        processed_ids.add(message_id)</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. Configure Lambda Event Source Settings</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Set a small <strong>batch size</strong> to reduce the number of messages retried on failure.</li>
      <li>Adjust the <strong>maximum retry attempts</strong> and <strong>visibility timeout</strong> to ensure messages are retried safely.</li>
      <li>Use Dead Letter Queues (DLQs) to capture messages that fail repeatedly.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">4. Best Practices</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Prefer FIFO queues for workflows that require strict exactly-once semantics.</li>
      <li>Store processed message IDs in a durable store (like DynamoDB) instead of in-memory for cross-invocation deduplication.</li>
      <li>Monitor Lambda metrics and DLQs to detect processing issues.</li>
      <li>Use idempotent processing logic for database writes or external API calls.</li>
    </ul>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Summary</h3>
      <p class="text-gray-700">
        To achieve exactly-once processing of SQS messages with Lambda, combine FIFO queues, message deduplication, and idempotent processing logic. Using DLQs and durable storage for processed IDs ensures safe, reliable, and consistent message handling.
      </p>
    </div>
  </div>
</section>



<section id="sns-sqs-lambda-architecture" class="py-16 bg-gray-50">
  <div class="max-w-7xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      Building an Event-Driven Architecture with SNS, SQS, and Lambda
    </h2>

    <p class="text-gray-700 mb-6">
      An event-driven architecture decouples producers and consumers of events, allowing scalable, fault-tolerant systems. Using SNS, SQS, and Lambda together lets you reliably publish, queue, and process events asynchronously.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Architecture Overview</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li><strong>SNS (Simple Notification Service):</strong> Publishes events from producers (e.g., S3 uploads, application events).</li>
      <li><strong>SQS (Simple Queue Service):</strong> Acts as a buffer to decouple event producers and consumers.</li>
      <li><strong>Lambda:</strong> Processes events asynchronously from SQS queues or directly from SNS subscriptions.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. Step-by-Step Setup</h3>

    <h4 class="text-lg font-semibold text-gray-900 mb-2">Step 1: Create an SNS Topic</h4>
    <ul class="list-disc list-inside text-gray-700 mb-4">
      <li>Go to SNS → Create Topic → choose a name.</li>
      <li>Use a Standard topic for fan-out scenarios.</li>
    </ul>

    <h4 class="text-lg font-semibold text-gray-900 mb-2">Step 2: Create SQS Queues</h4>
    <ul class="list-disc list-inside text-gray-700 mb-4">
      <li>Create one or more SQS queues that will subscribe to the SNS topic.</li>
      <li>Choose Standard or FIFO queues depending on ordering requirements.</li>
    </ul>

    <h4 class="text-lg font-semibold text-gray-900 mb-2">Step 3: Subscribe SQS Queues to SNS</h4>
    <ul class="list-disc list-inside text-gray-700 mb-4">
      <li>In SNS, create subscriptions with Protocol = <strong>SQS</strong>.</li>
      <li>Provide the ARN of each SQS queue.</li>
      <li>Enable raw message delivery if you want to receive the original message format.</li>
    </ul>

    <h4 class="text-lg font-semibold text-gray-900 mb-2">Step 4: Create Lambda Functions</h4>
    <ul class="list-disc list-inside text-gray-700 mb-4">
      <li>Create Lambda functions that will process messages from SQS queues.</li>
      <li>Assign IAM roles allowing read access to SQS and other resources.</li>
    </ul>

    <h4 class="text-lg font-semibold text-gray-900 mb-2">Step 5: Configure Lambda Event Sources</h4>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Go to each Lambda → Add Trigger → SQS → select the queue.</li>
      <li>Set batch size and enable the trigger.</li>
      <li>Lambda will automatically poll the queue and process messages asynchronously.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. Example Lambda Function (Python)</h3>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>import json

def lambda_handler(event, context):
    for record in event['Records']:
        message = record['body']
        print(f"Processing event: {message}")
        # Add business logic here</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">4. Best Practices</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Use FIFO queues if message ordering and deduplication are required.</li>
      <li>Enable DLQs for SQS queues and Lambda to handle failed messages.</li>
      <li>Monitor SNS, SQS, and Lambda metrics in CloudWatch.</li>
      <li>Ensure idempotent Lambda processing to handle retries safely.</li>
      <li>Use environment variables for configuration like queue URLs and SNS topic ARNs.</li>
    </ul>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Summary</h3>
      <p class="text-gray-700">
        By integrating SNS, SQS, and Lambda, you can build an event-driven architecture that is decoupled, scalable, and fault-tolerant. SNS publishes events, SQS buffers messages, and Lambda processes them asynchronously, providing a reliable serverless workflow.
      </p>
    </div>
  </div>
</section>



<section id="lambda-cloudwatch-monitoring" class="py-16 bg-gray-50">
  <div class="max-w-7xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      Monitoring Lambda Execution Time and Sending Alerts with CloudWatch + SNS
    </h2>

    <p class="text-gray-700 mb-6">
      AWS Lambda automatically emits execution metrics to CloudWatch. You can monitor function duration and create alerts to notify you if execution exceeds thresholds, ensuring timely detection of performance issues.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Monitor Lambda Duration Metric</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Go to CloudWatch → Metrics → Lambda → By Function Name.</li>
      <li>Look for the <strong>Duration</strong> metric to track execution time per invocation.</li>
      <li>Optionally, filter by function version or alias.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. Create a CloudWatch Alarm</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Go to CloudWatch → Alarms → Create Alarm.</li>
      <li>Select the Lambda Duration metric.</li>
      <li>Set a threshold (e.g., > 3000 ms) for alerting.</li>
      <li>Choose evaluation periods and conditions to reduce false positives.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. Configure SNS Topic for Notifications</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Create an SNS topic (e.g., <code>lambda-alerts</code>).</li>
      <li>Add subscriptions such as email, SMS, or Lambda for notifications.</li>
      <li>Note the Topic ARN for use in the CloudWatch alarm.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">4. Attach SNS Topic to CloudWatch Alarm</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>In the alarm configuration, select <strong>Send notification to</strong> and choose your SNS topic.</li>
      <li>Save the alarm; CloudWatch will notify subscribers when the threshold is breached.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">5. Optional: Create a Dashboard</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Create a CloudWatch Dashboard to visualize Lambda metrics like duration, errors, invocations, and throttles.</li>
      <li>Add widgets for multiple Lambda functions to monitor all critical functions in one place.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">6. Best Practices</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Set alarms based on percentile metrics (e.g., p90 duration) for better accuracy.</li>
      <li>Enable Lambda function logging to CloudWatch Logs for detailed analysis.</li>
      <li>Combine duration alarms with error rate alarms for comprehensive monitoring.</li>
      <li>Automate responses using Lambda functions triggered by SNS alerts if needed.</li>
    </ul>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Summary</h3>
      <p class="text-gray-700">
        Monitoring Lambda execution time using CloudWatch metrics and sending alerts via SNS helps ensure your serverless applications perform reliably. By combining alarms, dashboards, and notifications, you can proactively detect and respond to performance issues.
      </p>
    </div>
  </div>
</section>



<section id="apigateway-cloudwatch-lambda" class="py-16 bg-gray-50">
  <div class="max-w-7xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      Analyzing API Gateway Logs in CloudWatch and Triggering Lambda for Anomaly Detection
    </h2>

    <p class="text-gray-700 mb-6">
      API Gateway can log all API requests and responses to CloudWatch. By analyzing these logs, you can detect anomalies such as unusual traffic patterns, errors, or latency spikes. Lambda can be used to automate this detection.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Enable API Gateway Logging</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Go to API Gateway → Stages → Logs/Tracing.</li>
      <li>Enable <strong>CloudWatch Logs</strong> for the stage.</li>
      <li>Enable <strong>Log full requests/responses</strong> if detailed data is required.</li>
      <li>Ensure the API Gateway execution role has <code>CloudWatchLogsFullAccess</code>.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. View Logs in CloudWatch</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Go to CloudWatch → Logs → Log Groups → <code>API-Gateway-Execution-Logs_YourAPI</code>.</li>
      <li>Each stage and method has its log streams.</li>
      <li>Use filters to detect anomalies, e.g., high error rates or latency > threshold.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. Trigger Lambda on New Log Events</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Create a CloudWatch Logs subscription filter for the log group.</li>
      <li>Set the destination to a Lambda function.</li>
      <li>The Lambda function will receive log events in near real-time.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">4. Example Lambda Function (Python)</h3>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>import gzip
import json
import base64

def lambda_handler(event, context):
    # Decode and decompress log data
    compressed_payload = base64.b64decode(event['awslogs']['data'])
    uncompressed_payload = gzip.decompress(compressed_payload)
    log_event = json.loads(uncompressed_payload)
    
    for record in log_event['logEvents']:
        message = record['message']
        # Example anomaly detection: detect HTTP 5xx responses
        if '"status":500' in message:
            print(f"Anomaly detected: {message}")
            # Optional: trigger alert via SNS or another service</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">5. Best Practices</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Filter logs at the subscription level to reduce Lambda invocation costs.</li>
      <li>Use structured JSON logging for easier parsing and anomaly detection.</li>
      <li>Send alerts via SNS, email, or Slack when anomalies are detected.</li>
      <li>Aggregate metrics in CloudWatch dashboards for monitoring trends over time.</li>
      <li>Ensure Lambda has minimal processing time to avoid throttling.</li>
    </ul>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Summary</h3>
      <p class="text-gray-700">
        By enabling API Gateway logs, creating CloudWatch subscription filters, and using Lambda for automated anomaly detection, you can monitor your APIs in real-time and respond proactively to errors, latency spikes, or suspicious activity.
      </p>
    </div>
  </div>
</section>




<section id="enforce-encryption" class="py-16 bg-gray-50">
  <div class="max-w-7xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      Enforcing Encryption for S3, RDS, and DynamoDB Programmatically
    </h2>

    <p class="text-gray-700 mb-6">
      Encrypting data at rest is critical for security and compliance. AWS allows you to enable encryption programmatically for S3 buckets, RDS databases, and DynamoDB tables using SDKs or APIs.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. S3 Encryption</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Enable server-side encryption (SSE) using S3-managed keys (SSE-S3), KMS-managed keys (SSE-KMS), or customer-provided keys (SSE-C).</li>
      <li>Example using AWS SDK for Python (boto3):</li>
    </ul>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>import boto3

s3 = boto3.client('s3')

s3.put_bucket_encryption(
    Bucket='my-bucket',
    ServerSideEncryptionConfiguration={
        'Rules': [{
            'ApplyServerSideEncryptionByDefault': {
                'SSEAlgorithm': 'AES256'  # or 'aws:kms'
            }
        }]
    }
)</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. RDS Encryption</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Enable encryption at the time of database creation using AWS KMS keys.</li>
      <li>Example using AWS SDK for Python (boto3):</li>
    </ul>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>import boto3

rds = boto3.client('rds')

rds.create_db_instance(
    DBInstanceIdentifier='mydb',
    AllocatedStorage=20,
    DBInstanceClass='db.t3.micro',
    Engine='mysql',
    MasterUsername='admin',
    MasterUserPassword='password',
    StorageEncrypted=True,
    KmsKeyId='arn:aws:kms:region:account-id:key/key-id'
)</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. DynamoDB Encryption</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>DynamoDB tables can use AWS owned keys (default) or customer-managed KMS keys for encryption at rest.</li>
      <li>Example using AWS SDK for Python (boto3):</li>
    </ul>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>import boto3

dynamodb = boto3.client('dynamodb')

dynamodb.create_table(
    TableName='MyTable',
    KeySchema=[{'AttributeName': 'id', 'KeyType': 'HASH'}],
    AttributeDefinitions=[{'AttributeName': 'id', 'AttributeType': 'S'}],
    BillingMode='PAY_PER_REQUEST',
    SSESpecification={
        'Enabled': True,
        'SSEType': 'KMS',  # or 'AES256'
        'KMSMasterKeyId': 'arn:aws:kms:region:account-id:key/key-id'
    }
)</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">4. Best Practices</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Use AWS KMS for centralized key management and auditing.</li>
      <li>Enable encryption at resource creation; retroactive encryption may require additional steps.</li>
      <li>Restrict IAM roles and users to allow only authorized access to KMS keys.</li>
      <li>Audit encryption status regularly via AWS Config or custom scripts.</li>
    </ul>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Summary</h3>
      <p class="text-gray-700">
        Programmatically enforcing encryption for S3, RDS, and DynamoDB ensures data is secure at rest. By leveraging AWS SDKs and KMS-managed keys, you can automate encryption setup and maintain compliance with security best practices.
      </p>
    </div>
  </div>
</section>




<section id="realtime-chat-app" class="py-16 bg-gray-50">
  <div class="max-w-7xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      Building a Real-Time Chat App Using API Gateway, Lambda, DynamoDB, and WebSockets
    </h2>

    <p class="text-gray-700 mb-6">
      You can build a scalable, serverless real-time chat application using AWS WebSocket API Gateway, Lambda for processing messages, and DynamoDB for storing connection IDs and chat history.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Set Up a WebSocket API in API Gateway</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Create a WebSocket API in API Gateway.</li>
      <li>Define routes such as <code>$connect</code>, <code>$disconnect</code>, and <code>sendMessage</code>.</li>
      <li>Enable logging and throttling to handle traffic spikes.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. Create DynamoDB Tables</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li><strong>Connections Table:</strong> Store <code>connectionId</code> and user metadata.</li>
      <li><strong>Messages Table:</strong> Optionally store chat history with <code>messageId</code>, <code>senderId</code>, <code>recipientId</code>, and timestamp.</li>
      <li>Use DynamoDB's fast lookups to efficiently send messages to connected clients.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. Implement Lambda Functions</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li><strong>$connect Lambda:</strong> Store <code>connectionId</code> in DynamoDB when a client connects.</li>
      <li><strong>$disconnect Lambda:</strong> Remove <code>connectionId</code> when the client disconnects.</li>
      <li><strong>sendMessage Lambda:</strong> Read the message payload, retrieve recipient <code>connectionId</code> from DynamoDB, and post message via API Gateway Management API.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">4. Example sendMessage Lambda (Python)</h3>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>import boto3
import json
import os

dynamodb = boto3.resource('dynamodb')
connections_table = dynamodb.Table('Connections')
apigw_client = boto3.client('apigatewaymanagementapi',
                            endpoint_url=os.environ['APIGW_ENDPOINT'])

def lambda_handler(event, context):
    body = json.loads(event['body'])
    recipient_id = body['recipientId']
    message = body['message']

    # Fetch recipient connectionId
    response = connections_table.get_item(Key={'userId': recipient_id})
    if 'Item' not in response:
        return {'statusCode': 404, 'body': 'Recipient not connected'}

    connection_id = response['Item']['connectionId']

    # Send message via WebSocket
    apigw_client.post_to_connection(ConnectionId=connection_id, Data=json.dumps({'message': message}))
    return {'statusCode': 200, 'body': 'Message sent'} </code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">5. Client Integration</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Use JavaScript WebSocket API to connect: <code>new WebSocket('wss://your-api-id.execute-api.region.amazonaws.com/prod')</code>.</li>
      <li>Handle <code>onmessage</code>, <code>onopen</code>, and <code>onclose</code> events to manage chat UI.</li>
      <li>Send messages using <code>websocket.send(JSON.stringify({recipientId, message}))</code>.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">6. Best Practices</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Use DynamoDB TTL to remove stale connections automatically.</li>
      <li>Enable CloudWatch logging for Lambda functions to debug message flow.</li>
      <li>Scale API Gateway WebSocket and Lambda functions with concurrent connections in mind.</li>
      <li>Implement authentication and authorization (e.g., JWT) for secure chat.</li>
      <li>Batch messages if multiple recipients to reduce API Gateway calls.</li>
    </ul>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Summary</h3>
      <p class="text-gray-700">
        By combining WebSocket API Gateway, Lambda, and DynamoDB, you can build a fully serverless real-time chat application. Connections are tracked in DynamoDB, messages are routed via Lambda, and clients receive messages instantly through WebSocket connections.
      </p>
    </div>
  </div>
</section>




<section id="iot-realtime-processing" class="py-16 bg-gray-50">
  <div class="max-w-7xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      Real-Time IoT Device Data Processing Using IoT Core, Kinesis, Lambda, and DynamoDB
    </h2>

    <p class="text-gray-700 mb-6">
      IoT applications often generate massive streams of data that need real-time processing. AWS IoT Core can ingest device data, Kinesis streams provide a scalable pipeline, Lambda processes events, and DynamoDB stores processed results for fast access.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Ingest Data with AWS IoT Core</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Register IoT devices (things) in AWS IoT Core.</li>
      <li>Define IoT Core topics (e.g., <code>devices/{deviceId}/data</code>).</li>
      <li>Configure devices to publish telemetry data (JSON) to the IoT Core MQTT topics.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. Route IoT Data to Kinesis</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Create a Kinesis Data Stream to handle high-throughput device data.</li>
      <li>In IoT Core, define a <strong>Rule</strong> that forwards incoming messages to the Kinesis Data Stream.</li>
      <li>IoT Rule example:</li>
    </ul>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>SELECT deviceId, temperature, humidity, timestamp 
FROM 'devices/+/data'
WHERE temperature IS NOT NULL</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. Process Data with Lambda</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Create a Lambda function triggered by the Kinesis stream.</li>
      <li>Parse incoming IoT messages and perform computations, aggregations, or anomaly detection.</li>
      <li>Example Lambda function in Python:</li>
    </ul>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>import json
import boto3

dynamodb = boto3.resource('dynamodb')
table = dynamodb.Table('DeviceData')

def lambda_handler(event, context):
    for record in event['Records']:
        payload = json.loads(record['kinesis']['data'].decode('utf-8'))
        device_id = payload['deviceId']
        temp = payload['temperature']
        humidity = payload['humidity']
        timestamp = payload['timestamp']

        # Store processed data in DynamoDB
        table.put_item(
            Item={
                'deviceId': device_id,
                'timestamp': timestamp,
                'temperature': temp,
                'humidity': humidity
            }
        )</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">4. Store and Query Data in DynamoDB</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Design the DynamoDB table with <code>deviceId</code> as the partition key and <code>timestamp</code> as the sort key for time-series data.</li>
      <li>Optionally create Global Secondary Indexes (GSIs) to query by different attributes.</li>
      <li>DynamoDB provides fast, scalable storage with near real-time access for dashboards or analytics.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">5. Optional Enhancements</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Use Kinesis Data Analytics or Lambda for aggregations, e.g., compute average temperature per minute.</li>
      <li>Enable CloudWatch alarms on Lambda errors or Kinesis stream metrics to detect processing issues.</li>
      <li>Integrate with SNS to send alerts when thresholds (e.g., high temperature) are exceeded.</li>
      <li>Use S3 or Redshift for long-term archival of raw IoT data.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">6. Best Practices</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Batch Kinesis records in Lambda to reduce invocation costs.</li>
      <li>Enable error handling with Dead Letter Queues (DLQ) for Lambda.</li>
      <li>Set appropriate retention period for Kinesis streams based on processing latency requirements.</li>
      <li>Use IAM roles with least privilege for Lambda access to DynamoDB and Kinesis.</li>
    </ul>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Summary</h3>
      <p class="text-gray-700">
        By combining AWS IoT Core, Kinesis, Lambda, and DynamoDB, you can build a fully serverless pipeline for real-time IoT data ingestion, processing, and storage. This architecture scales automatically, provides low-latency processing, and supports analytics and monitoring.
      </p>
    </div>
  </div>
</section>



<section id="low-stock-notifications" class="py-16 bg-gray-50">
  <div class="max-w-7xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      Triggering Notifications for Low Stock Levels Using DynamoDB Streams, Lambda, and SNS
    </h2>

    <p class="text-gray-700 mb-6">
      You can automatically notify stakeholders when product stock levels fall below a threshold by combining DynamoDB Streams, Lambda, and SNS. Changes in the inventory table trigger Lambda, which evaluates stock levels and publishes alerts via SNS.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Enable DynamoDB Streams</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Go to the DynamoDB table storing inventory data.</li>
      <li>Enable <strong>DynamoDB Streams</strong> and choose <code>NEW_IMAGE</code> or <code>NEW_AND_OLD_IMAGES</code> depending on your use case.</li>
      <li>This allows you to capture item updates and deletions in near real-time.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. Create an SNS Topic</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Create an SNS topic (e.g., <code>low-stock-alerts</code>).</li>
      <li>Add subscribers such as email, SMS, or other Lambda functions.</li>
      <li>Note the SNS Topic ARN to use in the Lambda function.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. Create a Lambda Function</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Create a Lambda function triggered by the DynamoDB Stream.</li>
      <li>Lambda receives a batch of records; inspect each for stock levels below the defined threshold.</li>
      <li>Publish a notification to SNS if stock is low.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">4. Example Lambda Function (Python)</h3>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>import boto3
import os

sns = boto3.client('sns')
SNS_TOPIC_ARN = os.environ['SNS_TOPIC_ARN']
LOW_STOCK_THRESHOLD = 10

def lambda_handler(event, context):
    for record in event['Records']:
        if record['eventName'] not in ['INSERT', 'MODIFY']:
            continue

        new_image = record['dynamodb']['NewImage']
        product_name = new_image['productName']['S']
        stock_count = int(new_image['stock']['N'])

        if stock_count < LOW_STOCK_THRESHOLD:
            message = f"Low stock alert: {product_name} has only {stock_count} items left."
            sns.publish(
                TopicArn=SNS_TOPIC_ARN,
                Message=message,
                Subject="Low Stock Alert"
            )
            print(f"Alert sent for {product_name}")</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">5. Configure Environment Variables</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Set <code>SNS_TOPIC_ARN</code> as an environment variable in Lambda.</li>
      <li>Optionally, configure <code>LOW_STOCK_THRESHOLD</code> as an environment variable for flexibility.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">6. Best Practices</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Use batch processing to reduce Lambda invocations.</li>
      <li>Enable DLQ (Dead Letter Queue) to handle failed invocations.</li>
      <li>Secure SNS topic access with IAM policies to prevent unauthorized publishing.</li>
      <li>Monitor Lambda and DynamoDB Streams metrics via CloudWatch for reliability.</li>
      <li>Consider alerting thresholds per product category or priority level.</li>
    </ul>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Summary</h3>
      <p class="text-gray-700">
        By using DynamoDB Streams to capture inventory changes, Lambda to evaluate stock levels, and SNS to send notifications, you can automate low-stock alerts in real-time. This serverless approach scales seamlessly and ensures stakeholders are notified promptly.
      </p>
    </div>
  </div>
</section>




<section id="image-resize-notifications" class="py-16 bg-gray-50">
  <div class="max-w-7xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      Automatically Resizing Uploaded Images and Sending Real-Time Notifications Using S3, Lambda, SNS, and SQS
    </h2>

    <p class="text-gray-700 mb-6">
      You can build a serverless workflow to automatically process images uploaded to S3. Lambda resizes images, stores them back in S3, and uses SNS and SQS to notify users or downstream systems in real-time.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. S3 Bucket Setup</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Create an S3 bucket to receive uploaded images (e.g., <code>uploads-bucket</code>).</li>
      <li>Optionally, create a separate bucket for resized images (e.g., <code>resized-bucket</code>).</li>
      <li>Enable S3 event notifications on <strong>PUT</strong> operations and trigger a Lambda function.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. Lambda Function to Resize Images</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Create a Lambda function triggered by S3 PUT events.</li>
      <li>Use libraries like <code>Pillow</code> in Python or <code>Sharp</code> in Node.js to resize images.</li>
      <li>Save resized images back to the S3 bucket (optionally in a different prefix or bucket).</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. Notify Users via SNS</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Create an SNS topic (e.g., <code>image-processing-notifications</code>).</li>
      <li>Publish a message from the Lambda function after processing each image.</li>
      <li>Subscribers can include email addresses, mobile devices, or other Lambda functions for further processing.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">4. Optional SQS for Asynchronous Processing</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Use an SQS queue as an intermediate buffer if image processing volume is high.</li>
      <li>S3 triggers Lambda to send messages to SQS; another Lambda function processes messages in batches.</li>
      <li>This ensures reliability and prevents Lambda throttling during traffic spikes.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">5. Example Lambda Function (Python)</h3>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>import boto3
from PIL import Image
import io
import os

s3 = boto3.client('s3')
sns = boto3.client('sns')
SNS_TOPIC_ARN = os.environ['SNS_TOPIC_ARN']
RESIZED_BUCKET = os.environ['RESIZED_BUCKET']

def lambda_handler(event, context):
    for record in event['Records']:
        bucket = record['s3']['bucket']['name']
        key = record['s3']['object']['key']

        # Download image from S3
        response = s3.get_object(Bucket=bucket, Key=key)
        image_data = response['Body'].read()
        image = Image.open(io.BytesIO(image_data))

        # Resize image
        image.thumbnail((800, 800))

        # Save resized image to in-memory file
        buffer = io.BytesIO()
        image.save(buffer, format=image.format)
        buffer.seek(0)

        # Upload resized image to target bucket
        s3.put_object(Bucket=RESIZED_BUCKET, Key=key, Body=buffer, ContentType=response['ContentType'])

        # Notify via SNS
        message = f"Image '{key}' has been resized and uploaded to '{RESIZED_BUCKET}'."
        sns.publish(TopicArn=SNS_TOPIC_ARN, Message=message)
        print(message)</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">6. Best Practices</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Use environment variables to configure bucket names, SNS topics, and resize dimensions.</li>
      <li>Handle errors with retries or Dead Letter Queues (DLQ) for Lambda and SQS.</li>
      <li>Set appropriate memory and timeout settings for Lambda based on image size.</li>
      <li>Optimize image processing libraries for performance and low latency.</li>
      <li>Use versioning in S3 to avoid overwriting originals if needed.</li>
    </ul>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Summary</h3>
      <p class="text-gray-700">
        By combining S3 event triggers, Lambda for image processing, SNS for notifications, and optionally SQS for buffering, you can create a fully serverless, real-time image processing pipeline that is scalable, reliable, and notifies users immediately when processing is complete.
      </p>
    </div>
  </div>
</section>




<section id="csv-summary-email" class="py-16 bg-gray-50">
  <div class="max-w-7xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      Generating a CSV Summary of Uploaded Files and Emailing Admins Using S3, Lambda, and SES
    </h2>

    <p class="text-gray-700 mb-6">
      You can automate the generation of a CSV summary of files uploaded to an S3 bucket and send it to administrators using AWS Lambda and Simple Email Service (SES). This approach ensures timely reporting without manual intervention.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. S3 Bucket Setup</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Create an S3 bucket where users upload files (e.g., <code>uploads-bucket</code>).</li>
      <li>Enable event notifications for <strong>PUT</strong> operations if you want to trigger CSV generation immediately after uploads.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. Lambda Function for CSV Generation</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Create a Lambda function that reads the list of objects from S3.</li>
      <li>Generate a CSV summary with details like <code>filename</code>, <code>size</code>, <code>upload date</code>.</li>
      <li>Optionally store the CSV in S3 before sending via email.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. Send Email Using SES</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Verify sender and recipient email addresses in SES (required in sandbox mode).</li>
      <li>Use SES API to send the generated CSV as an attachment to administrators.</li>
      <li>Set up IAM permissions for Lambda to access S3 and SES.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">4. Example Lambda Function (Python)</h3>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>import boto3
import csv
import io
import os
from botocore.exceptions import ClientError

s3 = boto3.client('s3')
ses = boto3.client('ses')
UPLOAD_BUCKET = os.environ['UPLOAD_BUCKET']
ADMIN_EMAIL = os.environ['ADMIN_EMAIL']

def lambda_handler(event, context):
    # List objects in S3 bucket
    response = s3.list_objects_v2(Bucket=UPLOAD_BUCKET)
    files = response.get('Contents', [])

    # Generate CSV in-memory
    output = io.StringIO()
    writer = csv.writer(output)
    writer.writerow(['Filename', 'Size (Bytes)', 'LastModified'])

    for obj in files:
        writer.writerow([obj['Key'], obj['Size'], obj['LastModified']])

    csv_data = output.getvalue()
    output.close()

    # Send email with CSV as attachment
    try:
        ses.send_email(
            Source=ADMIN_EMAIL,
            Destination={'ToAddresses': [ADMIN_EMAIL]},
            Message={
                'Subject': {'Data': 'S3 Upload Summary'},
                'Body': {
                    'Text': {'Data': 'Please find attached the summary of uploaded files.'}
                }
            },
            ReplyToAddresses=[ADMIN_EMAIL]
        )
        print("Email sent successfully")
    except ClientError as e:
        print(f"Error sending email: {e}")</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">5. Best Practices</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Use environment variables for bucket names and email addresses.</li>
      <li>Consider batching the CSV generation (e.g., daily summary) using CloudWatch Events.</li>
      <li>Monitor Lambda and SES usage with CloudWatch metrics and alarms.</li>
      <li>Handle large numbers of files using pagination with <code>list_objects_v2</code>.</li>
      <li>Use S3 pre-signed URLs in the email for large CSVs instead of attachments.</li>
    </ul>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Summary</h3>
      <p class="text-gray-700">
        This architecture uses S3 for file storage, Lambda for generating a CSV summary, and SES to email administrators automatically. It provides a serverless, automated workflow for monitoring uploads and keeping stakeholders informed in real-time.
      </p>
    </div>
  </div>
</section>



<section id="serverless-crud-api" class="py-16 bg-gray-50">
  <div class="max-w-7xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      Building a Serverless REST API for a CRUD Application Using API Gateway, Lambda, and DynamoDB
    </h2>

    <p class="text-gray-700 mb-6">
      You can implement a fully serverless CRUD application using API Gateway to expose REST endpoints, Lambda to handle business logic, and DynamoDB as the database. This architecture scales automatically and eliminates server management.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Design DynamoDB Table</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Create a table (e.g., <code>Items</code>) with a primary key <code>itemId</code> (string).</li>
      <li>Optionally add a sort key or Global Secondary Indexes (GSIs) for querying by other attributes.</li>
      <li>DynamoDB provides fast, scalable storage and supports high-concurrency CRUD operations.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. Create Lambda Functions for CRUD Operations</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li><strong>Create Item:</strong> Inserts a new item into DynamoDB.</li>
      <li><strong>Read Item:</strong> Retrieves an item by <code>itemId</code>.</li>
      <li><strong>Update Item:</strong> Modifies attributes of an existing item.</li>
      <li><strong>Delete Item:</strong> Removes an item by <code>itemId</code>.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. Configure API Gateway REST API</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Create an API in API Gateway with routes like:
        <ul class="list-disc list-inside ml-6">
          <li><code>POST /items</code> → Create item</li>
          <li><code>GET /items/{id}</code> → Read item</li>
          <li><code>PUT /items/{id}</code> → Update item</li>
          <li><code>DELETE /items/{id}</code> → Delete item</li>
        </ul>
      </li>
      <li>Integrate each route with the corresponding Lambda function.</li>
      <li>Enable request/response validation, CORS, and throttling if needed.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">4. Example Lambda Function (Python – Create Item)</h3>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>import boto3
import json
import uuid
import os

dynamodb = boto3.resource('dynamodb')
TABLE_NAME = os.environ['TABLE_NAME']
table = dynamodb.Table(TABLE_NAME)

def lambda_handler(event, context):
    body = json.loads(event['body'])
    item_id = str(uuid.uuid4())
    
    item = {
        'itemId': item_id,
        'name': body.get('name'),
        'description': body.get('description'),
        'createdAt': body.get('createdAt')
    }
    
    table.put_item(Item=item)
    
    return {
        'statusCode': 201,
        'body': json.dumps(item)
    }</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">5. Example Read Lambda Function (Python)</h3>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>import boto3
import json
import os

dynamodb = boto3.resource('dynamodb')
TABLE_NAME = os.environ['TABLE_NAME']
table = dynamodb.Table(TABLE_NAME)

def lambda_handler(event, context):
    item_id = event['pathParameters']['id']
    response = table.get_item(Key={'itemId': item_id})
    
    if 'Item' in response:
        return {'statusCode': 200, 'body': json.dumps(response['Item'])}
    else:
        return {'statusCode': 404, 'body': json.dumps({'message': 'Item not found'})}</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">6. Best Practices</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Use environment variables for table names and other configuration.</li>
      <li>Enable IAM roles with least privilege for Lambda functions to access DynamoDB.</li>
      <li>Enable CloudWatch logging for API Gateway and Lambda for debugging and monitoring.</li>
      <li>Consider using API Gateway request validation and mapping templates for input validation.</li>
      <li>Batch writes and use DynamoDB conditional updates for consistency and efficiency.</li>
      <li>Optionally, use Lambda Layers for shared code and dependencies across multiple functions.</li>
    </ul>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Summary</h3>
      <p class="text-gray-700">
        By combining API Gateway, Lambda, and DynamoDB, you can build a fully serverless REST API for a CRUD application. This setup scales automatically, is cost-efficient, and reduces operational overhead while allowing for high concurrency and rapid feature development.
      </p>
    </div>
  </div>
</section>




<section id="dynamodb-batch-write" class="py-16 bg-gray-50">
  <div class="max-w-7xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      Batch Writing to DynamoDB Using API Gateway, Lambda, and DynamoDB
    </h2>

    <p class="text-gray-700 mb-6">
      When dealing with multiple items to insert or update in DynamoDB, you can use batch write operations to optimize performance. API Gateway can receive bulk requests, Lambda processes them, and DynamoDB handles the batch writes efficiently.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. DynamoDB Table Setup</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Create a DynamoDB table (e.g., <code>Orders</code>) with a primary key <code>orderId</code>.</li>
      <li>Ensure table throughput or on-demand mode can handle batch write volume.</li>
      <li>Optionally configure Global Secondary Indexes (GSIs) for additional query patterns.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. API Gateway Setup for Batch Requests</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Create a POST endpoint, e.g., <code>/batchWrite</code>.</li>
      <li>API Gateway passes the JSON array of items to Lambda.</li>
      <li>Enable request validation to ensure the payload is a valid JSON array.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. Lambda Function to Handle Batch Write</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Use the <code>boto3</code> <code>batch_write_item</code> API in Python to insert multiple items.</li>
      <li>Handle partial failures by retrying unprocessed items.</li>
      <li>Split payload into batches of 25 items (DynamoDB limit per batch write).</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">4. Example Lambda Function (Python)</h3>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>import boto3
import json
import os
from itertools import islice

dynamodb = boto3.resource('dynamodb')
TABLE_NAME = os.environ['TABLE_NAME']
table = dynamodb.Table(TABLE_NAME)

def chunked(iterable, size):
    """Yield successive chunks of a given size."""
    it = iter(iterable)
    while True:
        chunk = list(islice(it, size))
        if not chunk:
            break
        yield chunk

def lambda_handler(event, context):
    items = json.loads(event['body'])  # Expecting list of items
    responses = []

    for batch in chunked(items, 25):  # DynamoDB batch write limit
        with table.batch_writer() as batch_writer:
            for item in batch:
                batch_writer.put_item(Item=item)
        responses.append({'batchSize': len(batch), 'status': 'success'})

    return {
        'statusCode': 200,
        'body': json.dumps({
            'message': 'Batch write completed',
            'batchesProcessed': len(responses),
            'details': responses
        })
    }</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">5. Best Practices</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Limit each batch to 25 items due to DynamoDB API constraints.</li>
      <li>Use <code>batch_writer()</code> to automatically handle retries for unprocessed items.</li>
      <li>Validate payload size to prevent Lambda timeouts or payload size errors.</li>
      <li>Monitor CloudWatch metrics for Lambda execution and DynamoDB throttling.</li>
      <li>Consider using API Gateway request mapping templates to preprocess data before Lambda.</li>
      <li>For very large datasets, consider breaking requests into multiple Lambda invocations or using SQS as a buffer.</li>
    </ul>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Summary</h3>
      <p class="text-gray-700">
        By using API Gateway to receive bulk items, Lambda to process them in batches, and DynamoDB's batch write API, you can efficiently insert or update large datasets with minimal network calls and improved throughput. Proper chunking, retries, and monitoring ensure reliability at scale.
      </p>
    </div>
  </div>
</section>



<section id="async-order-processing" class="py-16 bg-gray-50">
  <div class="max-w-7xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      Asynchronous Order Processing in an E-commerce System Using SQS, Lambda, and RDS/S3
    </h2>

    <p class="text-gray-700 mb-6">
      In high-volume e-commerce systems, orders should be processed asynchronously to improve responsiveness and scalability. Amazon SQS decouples order submission from processing, Lambda handles business logic, and RDS/S3 stores order details and attachments.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Order Submission Flow</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>The front-end or API Gateway receives a new order request.</li>
      <li>Order details (JSON payload) are placed into an SQS queue (<code>orders-queue</code>).</li>
      <li>Respond immediately to the user with order confirmation to improve perceived latency.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. Lambda Function for Order Processing</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Lambda is triggered automatically when messages are available in SQS.</li>
      <li>Lambda performs business logic:
        <ul class="list-disc list-inside ml-6">
          <li>Validate order details</li>
          <li>Check inventory in RDS or DynamoDB</li>
          <li>Apply discounts or promotions</li>
        </ul>
      </li>
      <li>Store order summary in RDS (e.g., PostgreSQL/MySQL).</li>
      <li>Store attachments, invoices, or receipts in S3.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. Example Lambda Function (Python)</h3>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>import boto3
import json
import os
import pymysql

s3 = boto3.client('s3')
rds_host = os.environ['RDS_HOST']
rds_user = os.environ['RDS_USER']
rds_pass = os.environ['RDS_PASS']
rds_db = os.environ['RDS_DB']
s3_bucket = os.environ['S3_BUCKET']

def lambda_handler(event, context):
    # Connect to RDS
    conn = pymysql.connect(host=rds_host, user=rds_user, password=rds_pass, db=rds_db)
    cursor = conn.cursor()

    for record in event['Records']:
        order = json.loads(record['body'])
        order_id = order['orderId']
        customer = order['customer']
        items = order['items']

        # Store order in RDS
        cursor.execute("INSERT INTO orders (order_id, customer) VALUES (%s, %s)", (order_id, customer))
        conn.commit()

        # Optionally store invoice in S3
        invoice_key = f"invoices/{order_id}.json"
        s3.put_object(Bucket=s3_bucket, Key=invoice_key, Body=json.dumps(order))

        print(f"Processed order {order_id}")

    cursor.close()
    conn.close()</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">4. Benefits of Asynchronous Processing</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Improved user experience – front-end returns quickly while processing happens in the background.</li>
      <li>Automatic scaling – SQS handles message buffering and Lambda scales to process messages concurrently.</li>
      <li>Reliable retry mechanism – failed messages can be sent to a Dead Letter Queue (DLQ) for reprocessing.</li>
      <li>Decoupled architecture – reduces tight coupling between front-end and backend processing systems.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">5. Best Practices</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Use DLQs to handle failed messages.</li>
      <li>Set batch size for Lambda to control concurrency and avoid database overload.</li>
      <li>Implement idempotency in Lambda to safely retry processing without duplicating orders.</li>
      <li>Secure SQS, Lambda, and S3 with IAM roles to follow least privilege principles.</li>
      <li>Monitor processing metrics in CloudWatch and set alerts for failures or delays.</li>
    </ul>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Summary</h3>
      <p class="text-gray-700">
        By combining SQS for asynchronous queuing, Lambda for serverless processing, and RDS/S3 for data storage, you can build a robust, scalable, and decoupled order processing system. This architecture ensures reliability, fault tolerance, and high throughput in e-commerce applications.
      </p>
    </div>
  </div>
</section>



<section id="real-time-analytics-s3" class="py-16 bg-gray-50">
  <div class="max-w-7xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      Running Real-Time Analytics on Streaming Data Stored in S3 Using Kinesis, Lambda, and Athena
    </h2>

    <p class="text-gray-700 mb-6">
      To perform real-time analytics on streaming data, you can use Amazon Kinesis to ingest and buffer data, Lambda to process and transform it, S3 for durable storage, and Athena for querying and reporting. This architecture enables rapid insights from streaming data without provisioning servers.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Data Ingestion with Kinesis</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Set up a Kinesis Data Stream to receive streaming data from sources such as IoT devices, web applications, or logs.</li>
      <li>Each record is captured in the stream and retained for a configurable period (default 24 hours, up to 7 days).</li>
      <li>Kinesis automatically shards the stream to handle high throughput and parallel processing.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. Real-Time Processing with Lambda</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Configure a Lambda function as an event source for the Kinesis stream.</li>
      <li>Lambda processes each batch of records, performs transformations, enrichments, or filtering.</li>
      <li>Processed records are then stored in S3 for durable, cost-effective storage.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. Storing Data in S3</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Create an S3 bucket with a logical folder structure (e.g., <code>year=2025/month=08/day=24/</code>) for partitioned storage.</li>
      <li>Store transformed streaming records in columnar formats like Parquet or ORC for optimized querying.</li>
      <li>Use S3 Lifecycle policies to manage storage costs (move older data to Glacier or delete after retention).</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">4. Querying and Analytics with Athena</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Create an Athena table pointing to the S3 bucket location with proper partitions.</li>
      <li>Use SQL queries to analyze streaming data, generate reports, and visualize trends.</li>
      <li>Integrate Athena with QuickSight for dashboards or automate queries using Lambda.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">5. Example Lambda Function for Processing Kinesis Records</h3>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>import boto3
import json
import base64
import os
from datetime import datetime

s3 = boto3.client('s3')
S3_BUCKET = os.environ['S3_BUCKET']

def lambda_handler(event, context):
    for record in event['Records']:
        # Decode Kinesis data
        payload = base64.b64decode(record['kinesis']['data'])
        data = json.loads(payload)

        # Perform transformation (example: add timestamp)
        data['processedAt'] = datetime.utcnow().isoformat()

        # Define S3 key using partitioned folders
        s3_key = f"year={datetime.utcnow().year}/month={datetime.utcnow().month}/day={datetime.utcnow().day}/{data['id']}.json"
        s3.put_object(Bucket=S3_BUCKET, Key=s3_key, Body=json.dumps(data))

    return {'statusCode': 200, 'body': 'Processed batch successfully'}</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">6. Best Practices</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Use multiple Kinesis shards to parallelize high-throughput data ingestion.</li>
      <li>Batch Lambda invocations to improve cost efficiency and reduce processing overhead.</li>
      <li>Store data in columnar formats like Parquet or ORC to reduce Athena query costs and improve performance.</li>
      <li>Partition S3 data by date or other relevant keys to optimize query performance in Athena.</li>
      <li>Use CloudWatch to monitor Lambda, Kinesis, and S3 metrics for errors and latency.</li>
      <li>Enable server-side encryption for sensitive data stored in S3.</li>
    </ul>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Summary</h3>
      <p class="text-gray-700">
        By combining Kinesis for real-time ingestion, Lambda for serverless processing, S3 for storage, and Athena for querying, you can build a scalable and cost-effective real-time analytics pipeline. This setup allows immediate insights from streaming data while leveraging serverless architecture for minimal operational overhead.
      </p>
    </div>
  </div>
</section>



<section id="serverless-checkout-workflow" class="py-16 bg-gray-50">
  <div class="max-w-7xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      Building a Serverless E-commerce Checkout Workflow Using API Gateway, Lambda, SQS, DynamoDB, and SES
    </h2>

    <p class="text-gray-700 mb-6">
      A serverless checkout workflow ensures scalability, reliability, and low latency. Using API Gateway, Lambda, SQS, DynamoDB, and SES, you can handle checkout requests asynchronously while sending notifications to customers and updating order records in a database.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Checkout Request Submission via API Gateway</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Create a POST endpoint (e.g., <code>/checkout</code>) in API Gateway.</li>
      <li>The request payload includes items, quantities, payment info, and customer details.</li>
      <li>API Gateway triggers a Lambda function to validate and enqueue the order for processing.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. Queue Orders Using SQS</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Lambda enqueues validated orders into an SQS queue (e.g., <code>checkout-orders-queue</code>).</li>
      <li>SQS decouples the API request from order processing, improving scalability and fault tolerance.</li>
      <li>Set a Dead Letter Queue (DLQ) for handling failed messages.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. Process Orders Using Lambda</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Another Lambda function is triggered by SQS messages.</li>
      <li>Steps performed in Lambda:
        <ul class="list-disc list-inside ml-6">
          <li>Validate inventory and payment status</li>
          <li>Update order records in DynamoDB</li>
          <li>Send confirmation emails using SES</li>
          <li>Log order processing metrics for monitoring</li>
        </ul>
      </li>
      <li>Lambda automatically retries failed messages and unprocessed ones are sent to DLQ.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">4. DynamoDB for Order Storage</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Create an <code>Orders</code> table with <code>orderId</code> as primary key.</li>
      <li>Store order metadata, customer info, item details, payment status, and timestamps.</li>
      <li>Use DynamoDB's conditional writes to ensure idempotent order updates.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">5. Sending Notifications Using SES</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Use AWS SES to send order confirmation or failure notifications to customers.</li>
      <li>SES can be invoked directly from Lambda.</li>
      <li>Include order summary, delivery estimates, or invoice as attachments if required.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">6. Example Lambda Function for SQS Order Processing (Python)</h3>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>import json
import boto3
import os
import uuid
from datetime import datetime

dynamodb = boto3.resource('dynamodb')
ses = boto3.client('ses')
table = dynamodb.Table(os.environ['ORDERS_TABLE'])
SENDER_EMAIL = os.environ['SENDER_EMAIL']

def lambda_handler(event, context):
    for record in event['Records']:
        order = json.loads(record['body'])
        order_id = str(uuid.uuid4())
        customer_email = order['customerEmail']

        # Store order in DynamoDB
        table.put_item(Item={
            'orderId': order_id,
            'customerEmail': customer_email,
            'items': order['items'],
            'total': order['total'],
            'status': 'PROCESSING',
            'createdAt': datetime.utcnow().isoformat()
        })

        # Send confirmation email
        ses.send_email(
            Source=SENDER_EMAIL,
            Destination={'ToAddresses': [customer_email]},
            Message={
                'Subject': {'Data': f'Order Confirmation: {order_id}'},
                'Body': {'Text': {'Data': f'Thank you for your order! Your order ID is {order_id}.'}}
            }
        )

    return {'statusCode': 200, 'body': 'Orders processed successfully'}</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">7. Best Practices</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Enable SQS DLQ to capture messages that cannot be processed after retries.</li>
      <li>Use idempotent operations in Lambda to prevent duplicate order creation.</li>
      <li>Validate payload in API Gateway to prevent malformed requests.</li>
      <li>Monitor Lambda, SQS, and DynamoDB metrics in CloudWatch for failures or high latencies.</li>
      <li>Encrypt sensitive data in DynamoDB and SES email content for security compliance.</li>
    </ul>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Summary</h3>
      <p class="text-gray-700">
        By combining API Gateway, SQS, Lambda, DynamoDB, and SES, you can create a fully serverless e-commerce checkout workflow. This architecture ensures asynchronous, scalable, and reliable order processing while providing real-time notifications and a responsive user experience.
      </p>
    </div>
  </div>
</section>



<section id="document-approval-system" class="py-16 bg-gray-50">
  <div class="max-w-7xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      Building a Document Approval System Using S3, Lambda, DynamoDB, SNS, and Step Functions
    </h2>

    <p class="text-gray-700 mb-6">
      A document approval system allows users to submit documents, have them reviewed by approvers, and track their approval status. Using S3 for storage, Lambda for processing, DynamoDB for metadata, SNS for notifications, and Step Functions for workflow orchestration enables a scalable and serverless solution.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Uploading Documents to S3</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Users upload documents to a dedicated S3 bucket (e.g., <code>documents-bucket</code>).</li>
      <li>S3 triggers a Lambda function upon object creation to initiate the approval workflow.</li>
      <li>Lambda stores metadata in DynamoDB, including document ID, uploader, timestamp, and initial status (<code>PENDING</code>).</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. Workflow Orchestration with Step Functions</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Step Functions orchestrates the approval process with multiple steps:
        <ul class="list-disc list-inside ml-6">
          <li>Notify the first approver via SNS</li>
          <li>Wait for approval/rejection response (Lambda can poll or receive API callbacks)</li>
          <li>If approved, notify the next approver or finalize approval</li>
          <li>If rejected, update DynamoDB and notify the uploader</li>
        </ul>
      </li>
      <li>Step Functions ensures sequential or parallel approval flows and handles retries on failures.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. Notifications with SNS</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>SNS topics are used to notify approvers and document owners.</li>
      <li>Email, SMS, or mobile push notifications can be configured.</li>
      <li>Lambda functions can send detailed messages including S3 document links and approval instructions.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">4. Storing Metadata in DynamoDB</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Each document has an entry in a DynamoDB table with:
        <ul class="list-disc list-inside ml-6">
          <li>Document ID (primary key)</li>
          <li>Status: PENDING, APPROVED, REJECTED</li>
          <li>Uploader and approvers</li>
          <li>Timestamps for submission and approval actions</li>
        </ul>
      </li>
      <li>DynamoDB ensures low-latency reads and writes for real-time status updates.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">5. Example Lambda Function Triggered by S3</h3>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>import json
import boto3
import os
import uuid
from datetime import datetime

dynamodb = boto3.resource('dynamodb')
stepfunctions = boto3.client('stepfunctions')
table = dynamodb.Table(os.environ['DOCUMENTS_TABLE'])
state_machine_arn = os.environ['STATE_MACHINE_ARN']

def lambda_handler(event, context):
    for record in event['Records']:
        s3_bucket = record['s3']['bucket']['name']
        s3_key = record['s3']['object']['key']
        document_id = str(uuid.uuid4())

        # Store document metadata in DynamoDB
        table.put_item(Item={
            'documentId': document_id,
            's3Bucket': s3_bucket,
            's3Key': s3_key,
            'status': 'PENDING',
            'uploadedAt': datetime.utcnow().isoformat()
        })

        # Start Step Function workflow
        stepfunctions.start_execution(
            stateMachineArn=state_machine_arn,
            input=json.dumps({'documentId': document_id})
        )

    return {'statusCode': 200, 'body': 'Document workflow started successfully'}</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">6. Best Practices</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Enable versioning on S3 to track document changes.</li>
      <li>Use IAM roles with least privilege for Lambda, Step Functions, and DynamoDB.</li>
      <li>Set up SNS subscriptions for approvers and document owners.</li>
      <li>Implement idempotency in Lambda and Step Functions to handle retries safely.</li>
      <li>Monitor workflow execution and failures using CloudWatch metrics and alarms.</li>
      <li>Use S3 server-side encryption for sensitive documents.</li>
    </ul>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Summary</h3>
      <p class="text-gray-700">
        By combining S3, Lambda, DynamoDB, SNS, and Step Functions, you can build a scalable, serverless document approval system. This architecture ensures reliable document storage, asynchronous notifications, sequential or parallel approval workflows, and real-time status tracking.
      </p>
    </div>
  </div>
</section>




<section id="multi-tenant-saas" class="py-16 bg-gray-50">
  <div class="max-w-7xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      Implementing Multi-Tenant SaaS Architecture with Shared Storage and Isolated Data Using S3, DynamoDB, Cognito, and Lambda
    </h2>

    <p class="text-gray-700 mb-6">
      A multi-tenant SaaS application allows multiple customers (tenants) to share the same infrastructure while keeping their data isolated. Using S3 for storage, DynamoDB for structured data, Cognito for authentication, and Lambda for serverless business logic enables a scalable and secure multi-tenant design.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Authentication and Tenant Identification with Cognito</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Use Amazon Cognito User Pools for user authentication and identity management.</li>
      <li>Include <code>tenantId</code> as a custom attribute in Cognito to associate each user with a specific tenant.</li>
      <li>Lambda functions can extract <code>tenantId</code> from JWT tokens to enforce tenant-level data isolation.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. Shared Storage with S3</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Use a single S3 bucket for all tenants.</li>
      <li>Isolate tenant data using prefixes/folders, e.g., <code>tenant-123/documents/</code> and <code>tenant-456/documents/</code>.</li>
      <li>Configure Lambda functions or API endpoints to enforce access control by only allowing operations within the user's <code>tenantId</code> prefix.</li>
      <li>Enable server-side encryption (SSE-KMS) to protect sensitive tenant data.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. Multi-Tenant Data Storage in DynamoDB</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Create a DynamoDB table with a composite key: <code>tenantId</code> as the partition key and <code>itemId</code> as the sort key.</li>
      <li>This ensures data is logically isolated per tenant while sharing the same table.</li>
      <li>Use fine-grained access control in Lambda by filtering queries and updates by <code>tenantId</code>.</li>
      <li>Enable DynamoDB Streams for real-time triggers or replication per tenant if needed.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">4. Business Logic in Lambda</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Lambda functions act as the API layer, handling requests from API Gateway or direct SDK calls.</li>
      <li>Extract <code>tenantId</code> from Cognito JWT or request headers to enforce data isolation.</li>
      <li>Perform CRUD operations in DynamoDB and S3 under the tenant-specific partition or prefix.</li>
      <li>Ensure idempotency and proper error handling to support multiple tenants reliably.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">5. Example Lambda Snippet for Multi-Tenant Access</h3>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>import boto3
import os

dynamodb = boto3.resource('dynamodb')
s3 = boto3.client('s3')
table = dynamodb.Table(os.environ['TENANT_TABLE'])
bucket = os.environ['TENANT_BUCKET']

def lambda_handler(event, context):
    # Extract tenantId from Cognito JWT token or API Gateway authorizer
    tenant_id = event['requestContext']['authorizer']['claims']['custom:tenantId']
    item_id = event['pathParameters']['itemId']

    # Retrieve item for this tenant only
    response = table.get_item(Key={'tenantId': tenant_id, 'itemId': item_id})
    item = response.get('Item')

    # Example S3 object access for tenant
    s3_key = f"{tenant_id}/documents/{item_id}.pdf"
    s3_url = s3.generate_presigned_url('get_object', Params={'Bucket': bucket, 'Key': s3_key}, ExpiresIn=3600)

    return {'statusCode': 200, 'body': {'item': item, 'downloadUrl': s3_url}}</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">6. Best Practices</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Use Cognito and Lambda authorizers to securely identify tenants and enforce access control.</li>
      <li>Isolate S3 data using tenant-specific prefixes or separate buckets if required by compliance.</li>
      <li>Partition DynamoDB by <code>tenantId</code> to maintain low-latency queries and avoid cross-tenant access.</li>
      <li>Encrypt sensitive tenant data both in S3 (SSE-KMS) and DynamoDB (at rest and in transit).</li>
      <li>Monitor usage per tenant using CloudWatch metrics and set alarms for unusual access patterns.</li>
    </ul>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Summary</h3>
      <p class="text-gray-700">
        Implementing a multi-tenant SaaS architecture with S3, DynamoDB, Cognito, and Lambda allows tenants to share infrastructure while keeping their data isolated. Using tenant-specific prefixes, partition keys, and identity-based access control ensures security, scalability, and cost efficiency.
      </p>
    </div>
  </div>
</section>




<section id="process-large-csv-s3-dynamodb" class="py-16 bg-gray-50">
  <div class="max-w-7xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      Processing Large CSV Files Uploaded to S3 and Storing Results in DynamoDB
    </h2>

    <p class="text-gray-700 mb-6">
      To handle large CSV files efficiently, use a serverless pipeline with S3 for storage, Lambda for processing, and DynamoDB for storing results. This approach supports large-scale, event-driven data processing without provisioning servers.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Upload CSV Files to S3</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Create a dedicated S3 bucket (e.g., <code>csv-uploads-bucket</code>).</li>
      <li>Organize files using a folder structure, such as <code>uploads/year=2025/month=08/</code>.</li>
      <li>Enable S3 event notifications to trigger a Lambda function on <code>s3:ObjectCreated</code> events.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. Lambda for Processing CSV in Chunks</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>For large files (>10 MB), use S3 Select or split files using Lambda + S3 multi-part streaming to avoid Lambda memory/time limits.</li>
      <li>Each Lambda invocation reads a chunk of CSV rows, parses data, and transforms it into the desired format for DynamoDB.</li>
      <li>Use batch writes to DynamoDB to improve throughput and reduce write costs.</li>
      <li>Handle errors gracefully and implement retries or Dead Letter Queues (DLQ) for failed processing.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. DynamoDB Table Design</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Define a table with <code>fileId</code> as the partition key and <code>rowId</code> or a unique attribute as the sort key.</li>
      <li>Store CSV row data as attributes or nested JSON depending on the structure.</li>
      <li>Optionally include metadata like <code>uploadedAt</code>, <code>processedAt</code>, and <code>status</code> for tracking.</li>
      <li>Enable DynamoDB Streams if downstream processing or notifications are needed.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">4. Example Lambda Function Using Python</h3>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>import boto3
import csv
import io
import os
import uuid
from datetime import datetime

s3 = boto3.client('s3')
dynamodb = boto3.resource('dynamodb')
table = dynamodb.Table(os.environ['DYNAMODB_TABLE'])

def lambda_handler(event, context):
    for record in event['Records']:
        bucket = record['s3']['bucket']['name']
        key = record['s3']['object']['key']
        file_obj = s3.get_object(Bucket=bucket, Key=key)
        file_content = file_obj['Body'].read().decode('utf-8')

        csv_reader = csv.DictReader(io.StringIO(file_content))
        with table.batch_writer() as batch:
            for idx, row in enumerate(csv_reader):
                batch.put_item(Item={
                    'fileId': key,
                    'rowId': str(idx),
                    'data': row,
                    'processedAt': datetime.utcnow().isoformat()
                })

    return {'statusCode': 200, 'body': 'CSV processed successfully'}</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">5. Optimizations and Best Practices</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Use S3 Select to read only necessary columns from large CSV files to reduce Lambda memory and execution time.</li>
      <li>Enable parallel Lambda processing by splitting files or using multiple S3 triggers.</li>
      <li>Batch writes to DynamoDB to reduce request units and improve throughput.</li>
      <li>Use CloudWatch metrics and alarms to monitor Lambda execution errors, duration, and DynamoDB write throttling.</li>
      <li>Consider storing original CSV in S3 and processed data in DynamoDB for audit and replay purposes.</li>
      <li>Encrypt sensitive data at rest in S3 and DynamoDB (SSE-KMS).</li>
    </ul>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Summary</h3>
      <p class="text-gray-700">
        By combining S3, Lambda, and DynamoDB, you can build a serverless pipeline to efficiently process large CSV files. This architecture ensures scalable, event-driven processing with low operational overhead, while maintaining data integrity and performance.
      </p>
    </div>
  </div>
</section>



<section id="serverless-todo-app" class="py-16 bg-gray-50">
  <div class="max-w-7xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      Building a Serverless Todo App Using API Gateway, Lambda, and DynamoDB
    </h2>

    <p class="text-gray-700 mb-6">
      A serverless todo app allows users to create, read, update, and delete tasks without managing servers. By using API Gateway for HTTP endpoints, Lambda for business logic, and DynamoDB for persistent storage, you can build a fully scalable and secure application.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Authentication</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Use Amazon Cognito User Pools to manage user authentication and registration.</li>
      <li>Secure endpoints by validating JWT tokens issued by Cognito in API Gateway (Lambda authorizer or IAM authorizer).</li>
      <li>Each user has a unique <code>userId</code> to isolate tasks.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. API Endpoint Structure</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li><code>POST /todos</code> - Create a new todo item</li>
      <li><code>GET /todos</code> - List all todos for the authenticated user</li>
      <li><code>GET /todos/{id}</code> - Retrieve a specific todo item</li>
      <li><code>PUT /todos/{id}</code> - Update a todo item</li>
      <li><code>DELETE /todos/{id}</code> - Delete a todo item</li>
      <li>All requests include a JWT token for authentication; Lambda extracts <code>userId</code> from the token.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. DynamoDB Table Design</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Table: <code>Todos</code></li>
      <li>Partition key: <code>userId</code> – ensures data isolation per user</li>
      <li>Sort key: <code>todoId</code> – uniquely identifies each todo</li>
      <li>Attributes: <code>title</code>, <code>description</code>, <code>status</code>, <code>createdAt</code>, <code>updatedAt</code></li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">4. Example Lambda Function for Creating a Todo (Python)</h3>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>import json
import boto3
import uuid
from datetime import datetime

dynamodb = boto3.resource('dynamodb')
table = dynamodb.Table('Todos')

def lambda_handler(event, context):
    user_id = event['requestContext']['authorizer']['claims']['sub']
    body = json.loads(event['body'])
    todo_id = str(uuid.uuid4())
    
    item = {
        'userId': user_id,
        'todoId': todo_id,
        'title': body.get('title'),
        'description': body.get('description', ''),
        'status': 'PENDING',
        'createdAt': datetime.utcnow().isoformat(),
        'updatedAt': datetime.utcnow().isoformat()
    }

    table.put_item(Item=item)

    return {
        'statusCode': 201,
        'body': json.dumps({'todoId': todo_id, 'message': 'Todo created successfully'})
    }</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">5. Lambda for Other Operations</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>List todos: Query DynamoDB using <code>userId</code> as partition key.</li>
      <li>Get todo: Query with <code>userId</code> + <code>todoId</code>.</li>
      <li>Update todo: Use <code>UpdateItem</code> with conditional expressions to prevent unauthorized access.</li>
      <li>Delete todo: <code>DeleteItem</code> with <code>userId</code> + <code>todoId</code> key.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">6. Best Practices</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Use API Gateway request validation to ensure required fields are present.</li>
      <li>Enable DynamoDB Streams for audit logging or notifications.</li>
      <li>Use Cognito groups or roles for advanced access control if needed.</li>
      <li>Monitor Lambda execution metrics, DynamoDB throttling, and API Gateway latency via CloudWatch.</li>
      <li>Enable encryption at rest for DynamoDB and API Gateway HTTPS endpoints.</li>
    </ul>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Summary</h3>
      <p class="text-gray-700">
        Using API Gateway, Lambda, and DynamoDB, you can build a fully serverless todo app with secure, user-isolated storage and standard CRUD operations. Cognito ensures authentication and authorization, while the serverless architecture scales automatically with user demand.
      </p>
    </div>
  </div>
</section>



<section id="scaling-lambda-dynamodb" class="py-16 bg-gray-50">
  <div class="max-w-7xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      Scaling Lambda and DynamoDB for High-Traffic Bursts
    </h2>

    <p class="text-gray-700 mb-6">
      When APIs experience sudden traffic spikes, serverless services like Lambda and DynamoDB can scale automatically, but proper configuration is required to handle bursts efficiently and avoid throttling or latency issues.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Lambda Scaling Strategies</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Lambda automatically scales horizontally by creating additional concurrent executions.</li>
      <li>Set <strong>reserved concurrency</strong> for critical functions to guarantee availability and prevent other functions from exhausting account limits.</li>
      <li>Enable <strong>provisioned concurrency</strong> for functions with cold-start sensitivity, ensuring a minimum number of pre-warmed instances.</li>
      <li>Use <strong>Event Source Mapping batch size</strong> wisely for SQS/Kinesis triggers to balance throughput and processing time.</li>
      <li>Monitor <strong>concurrent executions</strong> and <strong>throttles</strong> using CloudWatch metrics to adjust limits dynamically.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. DynamoDB Scaling Strategies</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Use <strong>on-demand capacity mode</strong> for unpredictable or bursty workloads; DynamoDB automatically scales read/write throughput.</li>
      <li>For provisioned capacity, enable <strong>auto scaling</strong> to adjust read/write capacity units based on utilization.</li>
      <li>Design table partitions effectively with a well-distributed partition key to avoid hot partitions.</li>
      <li>Use <strong>batch operations</strong> (BatchGetItem, BatchWriteItem) to optimize throughput and reduce request overhead.</li>
      <li>Enable <strong>DAX (DynamoDB Accelerator)</strong> for read-heavy workloads to offload frequently accessed items from the table.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. Event Handling and Throttling</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Buffer incoming requests using <strong>SQS</strong> to smooth traffic bursts before Lambda processes them.</li>
      <li>Use <strong>dead-letter queues (DLQs)</strong> to capture failed messages and retry later without losing data.</li>
      <li>Implement <strong>exponential backoff</strong> and retries in client-side calls to DynamoDB to handle throttling gracefully.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">4. Monitoring and Alerting</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Use CloudWatch metrics for Lambda: <code>Invocations</code>, <code>Duration</code>, <code>Throttles</code>, <code>Errors</code>.</li>
      <li>Use CloudWatch metrics for DynamoDB: <code>ConsumedReadCapacityUnits</code>, <code>ConsumedWriteCapacityUnits</code>, <code>ThrottledRequests</code>.</li>
      <li>Set alarms to trigger notifications or automated scaling adjustments.</li>
    </ul>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Summary</h3>
      <p class="text-gray-700">
        Efficient scaling of Lambda and DynamoDB during high-traffic bursts requires careful configuration of concurrency, capacity, partitioning, and buffering strategies. By combining auto scaling, provisioned concurrency, on-demand DynamoDB, SQS buffering, and monitoring, you can maintain high throughput, low latency, and fault-tolerance for serverless applications.
      </p>
    </div>
  </div>
</section>



<section id="async-order-processing" class="py-16 bg-gray-50">
  <div class="max-w-7xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      Asynchronous Order Processing for E-Commerce Using SQS, Lambda, and RDS
    </h2>

    <p class="text-gray-700 mb-6">
      Processing e-commerce orders asynchronously improves performance, reduces latency for customers, and ensures reliable order handling. By using SQS as a queue, Lambda for processing, and RDS for persistent storage, the system can scale efficiently while handling bursts of orders.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Order Submission Flow</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>When a customer places an order via the website, the order details are validated and pushed to an <strong>SQS queue</strong> (e.g., <code>OrdersQueue</code>).</li>
      <li>The API returns an immediate acknowledgment to the user, decoupling order submission from order processing.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. Asynchronous Processing with Lambda</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Configure a <strong>Lambda function</strong> as an SQS event source to process orders as they arrive in the queue.</li>
      <li>Lambda reads order messages from SQS, validates business rules, updates inventory, calculates totals, and writes order details to <strong>RDS</strong>.</li>
      <li>Use <strong>batch processing</strong> in Lambda to improve throughput for high-volume order bursts.</li>
      <li>Handle transient errors by enabling retries and configuring a <strong>Dead Letter Queue (DLQ)</strong> for failed messages.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. RDS Table Design</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Orders table: <code>orderId</code> (PK), <code>userId</code>, <code>status</code>, <code>totalAmount</code>, <code>createdAt</code>, <code>updatedAt</code>.</li>
      <li>Order items table: <code>orderItemId</code> (PK), <code>orderId</code> (FK), <code>productId</code>, <code>quantity</code>, <code>price</code>.</li>
      <li>Inventory table (optional): track product stock and update atomically using transactions to prevent overselling.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">4. Example Lambda Pseudocode (Python)</h3>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>import boto3
import json
import pymysql
import os

rds_host = os.environ['RDS_HOST']
rds_user = os.environ['RDS_USER']
rds_pass = os.environ['RDS_PASSWORD']
rds_db   = os.environ['RDS_DB']

def lambda_handler(event, context):
    conn = pymysql.connect(host=rds_host, user=rds_user, password=rds_pass, database=rds_db)
    
    for record in event['Records']:
        order = json.loads(record['body'])
        with conn.cursor() as cursor:
            cursor.execute("INSERT INTO Orders (orderId, userId, status, totalAmount, createdAt) VALUES (%s, %s, %s, %s, NOW())",
                           (order['orderId'], order['userId'], 'PROCESSING', order['totalAmount']))
            for item in order['items']:
                cursor.execute("INSERT INTO OrderItems (orderItemId, orderId, productId, quantity, price) VALUES (%s, %s, %s, %s, %s)",
                               (item['itemId'], order['orderId'], item['productId'], item['quantity'], item['price']))
        conn.commit()
    
    conn.close()
    return {'statusCode': 200, 'body': 'Orders processed successfully'}</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">5. Best Practices</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Use SQS FIFO queues if order sequence matters.</li>
      <li>Enable <strong>Lambda reserved concurrency</strong> to control processing rate during traffic spikes.</li>
      <li>Use RDS transactions to maintain consistency when inserting orders and order items.</li>
      <li>Monitor CloudWatch metrics for Lambda errors, SQS queue depth, and RDS performance.</li>
      <li>Enable encryption at rest for both SQS messages and RDS data to ensure security.</li>
    </ul>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Summary</h3>
      <p class="text-gray-700">
        By decoupling order submission and processing using SQS and Lambda, you can handle high-volume, asynchronous e-commerce orders efficiently. This design ensures reliability, fault tolerance, and scalable order processing while persisting order details securely in RDS.
      </p>
    </div>
  </div>
</section>



<section id="sqs-failed-messages" class="py-16 bg-gray-50">
  <div class="max-w-7xl mx-auto px-6 lg:px-12">
    <h2 class="text-3xl font-bold text-gray-900 mb-6">
      Capturing Failed Messages for Later Retry in SQS
    </h2>

    <p class="text-gray-700 mb-6">
      In distributed systems, message processing can fail due to transient errors or unexpected conditions. To avoid losing data, AWS SQS provides mechanisms to capture failed messages for later inspection or retry.
    </p>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">1. Dead-Letter Queue (DLQ)</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Create a separate SQS queue to act as a <strong>Dead-Letter Queue (DLQ)</strong>.</li>
      <li>Associate the DLQ with your main SQS queue by setting a <strong>Maximum Receives</strong> threshold. If a message fails processing more than this number of times, it is moved to the DLQ automatically.</li>
      <li>DLQ allows developers to inspect, analyze, and replay failed messages without blocking the main queue.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">2. Lambda Retry Behavior</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>When Lambda processes messages from SQS and fails, it automatically retries until <strong>Maximum Receives</strong> is reached.</li>
      <li>After exceeding retries, the message is sent to the DLQ if configured.</li>
      <li>Monitor <strong>Lambda errors</strong> and <strong>DLQ message count</strong> in CloudWatch for proactive alerting.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">3. Handling Failed Messages</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Set up a separate Lambda to consume messages from the DLQ for manual inspection or automated retry.</li>
      <li>Optionally, apply exponential backoff or delay queues for retry attempts to prevent overwhelming downstream services.</li>
      <li>Log all failed messages and context information to CloudWatch or S3 for auditing.</li>
    </ul>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">4. Example DLQ Configuration</h3>
    <pre class="bg-gray-900 text-green-200 text-sm rounded-lg p-4 overflow-x-auto mb-6"><code>AWS Console / CLI Example:

aws sqs create-queue --queue-name OrdersDLQ

aws sqs set-queue-attributes \
    --queue-url https://sqs.us-east-1.amazonaws.com/123456789012/OrdersQueue \
    --attributes '{"RedrivePolicy":"{\"maxReceiveCount\":\"5\", \"deadLetterTargetArn\":\"arn:aws:sqs:us-east-1:123456789012:OrdersDLQ\"}"}'</code></pre>

    <h3 class="text-xl font-semibold text-gray-900 mb-4">5. Best Practices</h3>
    <ul class="list-disc list-inside text-gray-700 mb-6">
      <li>Use separate DLQs for different queues or services to simplify troubleshooting.</li>
      <li>Set <strong>maxReceiveCount</strong> to balance between transient error retries and moving problematic messages quickly to DLQ.</li>
      <li>Encrypt messages in both main queue and DLQ using SSE-SQS for sensitive data.</li>
      <li>Monitor DLQ depth and set CloudWatch alarms for timely intervention.</li>
    </ul>

    <div class="p-6 bg-blue-50 border-l-4 border-blue-400 rounded-2xl shadow-sm">
      <h3 class="text-xl font-semibold text-gray-900 mb-2">Summary</h3>
      <p class="text-gray-700">
        Using SQS Dead-Letter Queues ensures that failed messages are not lost and can be analyzed or retried later. Combined with Lambda retries and monitoring, DLQs provide a robust mechanism for fault-tolerant message processing in asynchronous systems.
      </p>
    </div>
  </div>
</section>


























   
  </main>

  <!-- Footer -->
  <footer class="bg-gray-100 text-gray-600 mt-10 p-6 text-center">
    <p>&copy; 2025 My Tutorials. All rights reserved.</p>
  </footer>

 
</body>
</html>
